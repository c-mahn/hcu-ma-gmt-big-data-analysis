{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FRbft71zpovU"
   },
   "outputs": [],
   "source": [
    "# Exercise_2\n",
    "# main simple regression WHO data\n",
    "# TODO**\n",
    "# Names of group members: Fabian Bloch and Christopher Mahn\n",
    "# Date: April 24th, 2023\n",
    "# TODO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "V55Tqr8_pove"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path of this exercise: /hdd/repository/hcu-ma-gmt-big-data-analysis/data/ex2\n"
     ]
    }
   ],
   "source": [
    "#%% Load modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import csv\n",
    "\n",
    "# torch modules\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# plot module\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# module for interoperable file-operations\n",
    "import os\n",
    "path = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "print(f'Path of this exercise: {path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ApFO2bmNpovl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: NVIDIA GeForce RTX 3080 Ti\n",
      "Device: cuda -- Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "# %% CUDA for PyTorch\n",
    "# Right at the beginning: check if a cuda compatible GPU is available in your computer. \n",
    "# If so, set device = cuda:0 which means that later all calculations will be performed on the graphics card. \n",
    "# If no GPU is available, the calculations will run on the CPU, which is also absolutely sufficient for the examples in these exercises.\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "# cudnn.benchmark = True\n",
    "if(use_cuda):\n",
    "    print(f'Found: {torch.cuda.get_device_name()}')\n",
    "if device.type == 'cpu':\n",
    "    device_num = 0\n",
    "    print('No GPU available.')\n",
    "else:\n",
    "    device_num = torch.cuda.device_count()\n",
    "    print('Device:', device, '-- Number of devices:', device_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tEq8B2lJqeZ_"
   },
   "outputs": [],
   "source": [
    "# Mounting Google Drive locally \n",
    "# from google.colab import drive\n",
    "#drive.mount(\"/content/drive\", force_remount=True)\n",
    "# drive.mount('/content/drive')\n",
    "# you can also choose one of the other options to load data\n",
    "# therefore see https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qDuUbHGwpovs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the dataset: (1649, 22)\n"
     ]
    }
   ],
   "source": [
    "# %% read data\n",
    "# path to WHO data\n",
    "data_path = os.path.join(path, 'data/life-expectancy-who/Life Expectancy Data.csv')\n",
    "\n",
    "# read csv sheet with pandas\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# drop each row where is nan data\n",
    "df = df.dropna()\n",
    "# drop each row where is not at least 21 not nan data\n",
    "# df = df.dropna(thresh=21) # there are many nan in row 4 12 14, which can cause errors\n",
    "\n",
    "# get numpy out of pandas dataframe\n",
    "data = df.values\n",
    "# data=df.to_numpy()\n",
    "\n",
    "# get column names to see, which columns we have to extract as x and y\n",
    "column_names = np.array(df.columns[:], dtype=np.str_)\n",
    "\n",
    "# TODO**\n",
    "print(f'Dimension of the dataset: {np.shape(data)}')\n",
    "# TODO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QxMKROTGpovx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (1649,)\n",
      "y shape: (1649,)\n",
      "x_1 = 19.1 = 19.1\n",
      "y_1 = 65.0 = 65.0\n"
     ]
    }
   ],
   "source": [
    "# %% split in X and Y\n",
    "# extract any feature you want as X \n",
    "# extract target values as Y\n",
    "# TODO**\n",
    "x = np.array(data[:,10], dtype=np.float32)\n",
    "y = np.array(data[:,3], dtype=np.float32)\n",
    "# TODO**\n",
    "print('x shape:', x.shape)\n",
    "print('y shape:', y.shape)\n",
    "print(f'x_1 = {x[0]:.1f} = 19.1')\n",
    "print(f'y_1 = {y[0]:.1f} = 65.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ArJIaoXdpov3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale_x: 77.1\n",
      "Scale_y: 89.0\n"
     ]
    }
   ],
   "source": [
    "# %% normalize X and Y between (0,1). If multiple features in X are selected, each feature is normalized individually\n",
    "scale_x = np.max(x, axis=0)\n",
    "scale_y = np.max(y, axis=0)\n",
    "x = x/scale_x\n",
    "y = y/scale_y\n",
    "print('Scale_x:',scale_x)\n",
    "print('Scale_y:',scale_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "akHb4sLlpov9"
   },
   "outputs": [],
   "source": [
    "# %% convert to torch tensors\n",
    "# if tensors have only one dimension, an artificial dimension is created with unsqueeze (e.g. [10]->[10,1], so 1D->2D)\n",
    "Y = torch.from_numpy(y)\n",
    "Y = Y.float()\n",
    "if len(Y.shape)==1:\n",
    "    Y = Y.unsqueeze(dim=1)\n",
    "\n",
    "X = torch.from_numpy(x)\n",
    "X = X.float()\n",
    "if len(X.shape)==1:\n",
    "    X = X.unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "h_jswetZpowA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input of first ten train Sample: tensor([[0.1012],\n",
      "        [0.8392],\n",
      "        [0.7704],\n",
      "        [0.7652],\n",
      "        [0.2335],\n",
      "        [0.8366],\n",
      "        [0.0324],\n",
      "        [0.5966],\n",
      "        [0.7147],\n",
      "        [0.7769]])\n",
      "Target of first ten train Sample: tensor([[0.8146],\n",
      "        [0.9157],\n",
      "        [0.9135],\n",
      "        [0.8640],\n",
      "        [0.6079],\n",
      "        [0.8449],\n",
      "        [0.6348],\n",
      "        [0.8067],\n",
      "        [0.8326],\n",
      "        [0.8202]])\n"
     ]
    }
   ],
   "source": [
    "# %% Split dataset in training, validation and test tensors\n",
    "# TODO**\n",
    "prop_train = 0.5\n",
    "prop_val = 0.25\n",
    "prop_test = 0.25\n",
    "# TODO**\n",
    "\n",
    "sample_num = {'all': X.shape[0], \n",
    "              'train': round(prop_train*X.shape[0]),\n",
    "              'val': round(prop_val*X.shape[0]),\n",
    "              'test': round(prop_test*X.shape[0])}\n",
    "\n",
    "# idx shuffle\n",
    "idx = np.random.choice(sample_num['all'], sample_num['all'], replace=False)\n",
    "# assign idx to each sample\n",
    "sample_idx = {'all': idx[:], \n",
    "              'train': idx[0:sample_num['train']],\n",
    "              'val': idx[sample_num['train']:sample_num['train']+sample_num['val']],\n",
    "              'test': idx[sample_num['train']+sample_num['val']:]}\n",
    "\n",
    "# Create train data\n",
    "X_train = X[sample_idx['train']]\n",
    "Y_train = Y[sample_idx['train']]\n",
    "\n",
    "# Create validation data\n",
    "X_val = X[sample_idx['val']]\n",
    "Y_val = Y[sample_idx['val']]\n",
    "\n",
    "# Create test data\n",
    "X_test = X[sample_idx['test']]\n",
    "Y_test = Y[sample_idx['test']]\n",
    "\n",
    "\n",
    "# %% Show data point\n",
    "print('Input of first ten train Sample:', X_train[0:10])\n",
    "print('Target of first ten train Sample:', Y_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "MBIUKIz5powE"
   },
   "outputs": [],
   "source": [
    "#%% class of neural network 'RegressNet'\n",
    "# set up layer and architecture of network in constructor __init__\n",
    "# define operations on layer in forward pass method\n",
    "class RegressNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(RegressNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(inputSize, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, outputSize)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # max pooling over (2, 2) window\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HNkvuIWrpowJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegressNet(\n",
      "  (fc1): Linear(in_features=1, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#%% Specify network hyperparameter and create instance of RegressNet\n",
    "# TODO**        \n",
    "inputDim = 1\n",
    "outputDim = 1\n",
    "\n",
    "# Create instance of RegressNet\n",
    "net = RegressNet(inputDim, outputDim)\n",
    "# TODO**\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ej8iLTTQpowN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RegressNet(\n",
       "  (fc1): Linear(in_features=1, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.version.cuda)\n",
    "\n",
    "#%% Send tensors and networks to GPU (if you have one which supports cuda) for faster computations\n",
    "X_train, Y_train = X_train.to(device), Y_train.to(device)\n",
    "X_val, Y_val = X_val.to(device), Y_val.to(device)\n",
    "X_test, Y_test = X_test.to(device), Y_test.to(device)\n",
    "\n",
    "# The network itself must also be sent to the GPU. Either you write net = RegressNet() and then later net.to(device) or directly net = RegressNet().to(device)\n",
    "# The latter option may have the advantage that the instance net is created directly on the GPU, whereas in variant 1 it must first be sent to the GPU.\n",
    "if device_num>1:\n",
    "    print(\"Let's use\", device_num, \"GPU's\")\n",
    "    net = nn.DataParallel(net)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wEB7solvpowR"
   },
   "outputs": [],
   "source": [
    "#%% Specify hyperparameter\n",
    "# hyperparemter: num_epoch, num_lr, loss_func, optimizer\n",
    "# how many epochs do we want to train?\n",
    "# TODO** \n",
    "num_epoch = 10000\n",
    "learn_rate = 1e-3\n",
    "# TODO**\n",
    "# Loss and optimizer\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fGpL1sQ_powV"
   },
   "outputs": [],
   "source": [
    "#%% Loss before training\n",
    "# Compute loss of test data before training the network (with random weights)\n",
    "Y_pred_train_before = net(X_train)\n",
    "loss_train_before = loss_func(Y_pred_train_before, Y_train)\n",
    "Y_pred_val_before = net(X_val)\n",
    "loss_val_before = loss_func(Y_pred_val_before, Y_val)\n",
    "Y_pred_test_before = net(X_test)\n",
    "loss_test_before = loss_func(Y_pred_test_before, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "s6Uo7R0xpowZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1/10000 (0%)\ttrain_Loss: 0.768727\tval_Loss: 0.637763\n",
      "Train Epoch: 2/10000 (0%)\ttrain_Loss: 0.637459\tval_Loss: 0.521257\n",
      "Train Epoch: 3/10000 (0%)\ttrain_Loss: 0.521027\tval_Loss: 0.421367\n",
      "Train Epoch: 4/10000 (0%)\ttrain_Loss: 0.421414\tval_Loss: 0.341460\n",
      "Train Epoch: 5/10000 (0%)\ttrain_Loss: 0.341874\tval_Loss: 0.277057\n",
      "Train Epoch: 6/10000 (0%)\ttrain_Loss: 0.277517\tval_Loss: 0.222436\n",
      "Train Epoch: 7/10000 (0%)\ttrain_Loss: 0.222891\tval_Loss: 0.176282\n",
      "Train Epoch: 8/10000 (0%)\ttrain_Loss: 0.176837\tval_Loss: 0.137101\n",
      "Train Epoch: 9/10000 (0%)\ttrain_Loss: 0.137623\tval_Loss: 0.103785\n",
      "Train Epoch: 10/10000 (0%)\ttrain_Loss: 0.104288\tval_Loss: 0.076910\n",
      "Train Epoch: 11/10000 (0%)\ttrain_Loss: 0.077390\tval_Loss: 0.056300\n",
      "Train Epoch: 12/10000 (0%)\ttrain_Loss: 0.056757\tval_Loss: 0.039924\n",
      "Train Epoch: 13/10000 (0%)\ttrain_Loss: 0.040357\tval_Loss: 0.027437\n",
      "Train Epoch: 14/10000 (0%)\ttrain_Loss: 0.027820\tval_Loss: 0.018631\n",
      "Train Epoch: 15/10000 (0%)\ttrain_Loss: 0.018963\tval_Loss: 0.012611\n",
      "Train Epoch: 16/10000 (0%)\ttrain_Loss: 0.012906\tval_Loss: 0.009024\n",
      "Train Epoch: 17/10000 (0%)\ttrain_Loss: 0.009278\tval_Loss: 0.007560\n",
      "Train Epoch: 18/10000 (0%)\ttrain_Loss: 0.007770\tval_Loss: 0.007849\n",
      "Train Epoch: 19/10000 (0%)\ttrain_Loss: 0.008014\tval_Loss: 0.009476\n",
      "Train Epoch: 20/10000 (0%)\ttrain_Loss: 0.009596\tval_Loss: 0.011996\n",
      "Train Epoch: 21/10000 (0%)\ttrain_Loss: 0.012073\tval_Loss: 0.014964\n",
      "Train Epoch: 22/10000 (0%)\ttrain_Loss: 0.015001\tval_Loss: 0.017968\n",
      "Train Epoch: 23/10000 (0%)\ttrain_Loss: 0.017970\tval_Loss: 0.020658\n",
      "Train Epoch: 24/10000 (0%)\ttrain_Loss: 0.020630\tval_Loss: 0.022772\n",
      "Train Epoch: 25/10000 (0%)\ttrain_Loss: 0.022722\tval_Loss: 0.024148\n",
      "Train Epoch: 26/10000 (0%)\ttrain_Loss: 0.024081\tval_Loss: 0.024720\n",
      "Train Epoch: 27/10000 (0%)\ttrain_Loss: 0.024643\tval_Loss: 0.024511\n",
      "Train Epoch: 28/10000 (0%)\ttrain_Loss: 0.024430\tval_Loss: 0.023611\n",
      "Train Epoch: 29/10000 (0%)\ttrain_Loss: 0.023533\tval_Loss: 0.022158\n",
      "Train Epoch: 30/10000 (0%)\ttrain_Loss: 0.022087\tval_Loss: 0.020313\n",
      "Train Epoch: 31/10000 (0%)\ttrain_Loss: 0.020253\tval_Loss: 0.018245\n",
      "Train Epoch: 32/10000 (0%)\ttrain_Loss: 0.018200\tval_Loss: 0.016112\n",
      "Train Epoch: 33/10000 (0%)\ttrain_Loss: 0.016083\tval_Loss: 0.014050\n",
      "Train Epoch: 34/10000 (0%)\ttrain_Loss: 0.014040\tval_Loss: 0.012167\n",
      "Train Epoch: 35/10000 (0%)\ttrain_Loss: 0.012176\tval_Loss: 0.010542\n",
      "Train Epoch: 36/10000 (0%)\ttrain_Loss: 0.010570\tval_Loss: 0.009218\n",
      "Train Epoch: 37/10000 (0%)\ttrain_Loss: 0.009265\tval_Loss: 0.008213\n",
      "Train Epoch: 38/10000 (0%)\ttrain_Loss: 0.008278\tval_Loss: 0.007518\n",
      "Train Epoch: 39/10000 (0%)\ttrain_Loss: 0.007600\tval_Loss: 0.007105\n",
      "Train Epoch: 40/10000 (0%)\ttrain_Loss: 0.007201\tval_Loss: 0.006931\n",
      "Train Epoch: 41/10000 (0%)\ttrain_Loss: 0.007041\tval_Loss: 0.006946\n",
      "Train Epoch: 42/10000 (0%)\ttrain_Loss: 0.007067\tval_Loss: 0.007096\n",
      "Train Epoch: 43/10000 (0%)\ttrain_Loss: 0.007227\tval_Loss: 0.007330\n",
      "Train Epoch: 44/10000 (0%)\ttrain_Loss: 0.007470\tval_Loss: 0.007601\n",
      "Train Epoch: 45/10000 (0%)\ttrain_Loss: 0.007746\tval_Loss: 0.007868\n",
      "Train Epoch: 46/10000 (0%)\ttrain_Loss: 0.008017\tval_Loss: 0.008099\n",
      "Train Epoch: 47/10000 (0%)\ttrain_Loss: 0.008251\tval_Loss: 0.008272\n",
      "Train Epoch: 48/10000 (0%)\ttrain_Loss: 0.008425\tval_Loss: 0.008375\n",
      "Train Epoch: 49/10000 (0%)\ttrain_Loss: 0.008527\tval_Loss: 0.008403\n",
      "Train Epoch: 50/10000 (0%)\ttrain_Loss: 0.008553\tval_Loss: 0.008358\n",
      "Train Epoch: 51/10000 (0%)\ttrain_Loss: 0.008504\tval_Loss: 0.008248\n",
      "Train Epoch: 52/10000 (1%)\ttrain_Loss: 0.008389\tval_Loss: 0.008087\n",
      "Train Epoch: 53/10000 (1%)\ttrain_Loss: 0.008221\tval_Loss: 0.007889\n",
      "Train Epoch: 54/10000 (1%)\ttrain_Loss: 0.008016\tval_Loss: 0.007671\n",
      "Train Epoch: 55/10000 (1%)\ttrain_Loss: 0.007789\tval_Loss: 0.007448\n",
      "Train Epoch: 56/10000 (1%)\ttrain_Loss: 0.007557\tval_Loss: 0.007236\n",
      "Train Epoch: 57/10000 (1%)\ttrain_Loss: 0.007334\tval_Loss: 0.007044\n",
      "Train Epoch: 58/10000 (1%)\ttrain_Loss: 0.007132\tval_Loss: 0.006883\n",
      "Train Epoch: 59/10000 (1%)\ttrain_Loss: 0.006960\tval_Loss: 0.006756\n",
      "Train Epoch: 60/10000 (1%)\ttrain_Loss: 0.006822\tval_Loss: 0.006666\n",
      "Train Epoch: 61/10000 (1%)\ttrain_Loss: 0.006722\tval_Loss: 0.006612\n",
      "Train Epoch: 62/10000 (1%)\ttrain_Loss: 0.006656\tval_Loss: 0.006588\n",
      "Train Epoch: 63/10000 (1%)\ttrain_Loss: 0.006622\tval_Loss: 0.006590\n",
      "Train Epoch: 64/10000 (1%)\ttrain_Loss: 0.006614\tval_Loss: 0.006611\n",
      "Train Epoch: 65/10000 (1%)\ttrain_Loss: 0.006625\tval_Loss: 0.006641\n",
      "Train Epoch: 66/10000 (1%)\ttrain_Loss: 0.006647\tval_Loss: 0.006676\n",
      "Train Epoch: 67/10000 (1%)\ttrain_Loss: 0.006674\tval_Loss: 0.006708\n",
      "Train Epoch: 68/10000 (1%)\ttrain_Loss: 0.006699\tval_Loss: 0.006733\n",
      "Train Epoch: 69/10000 (1%)\ttrain_Loss: 0.006718\tval_Loss: 0.006747\n",
      "Train Epoch: 70/10000 (1%)\ttrain_Loss: 0.006727\tval_Loss: 0.006749\n",
      "Train Epoch: 71/10000 (1%)\ttrain_Loss: 0.006726\tval_Loss: 0.006739\n",
      "Train Epoch: 72/10000 (1%)\ttrain_Loss: 0.006712\tval_Loss: 0.006718\n",
      "Train Epoch: 73/10000 (1%)\ttrain_Loss: 0.006689\tval_Loss: 0.006689\n",
      "Train Epoch: 74/10000 (1%)\ttrain_Loss: 0.006658\tval_Loss: 0.006654\n",
      "Train Epoch: 75/10000 (1%)\ttrain_Loss: 0.006622\tval_Loss: 0.006616\n",
      "Train Epoch: 76/10000 (1%)\ttrain_Loss: 0.006584\tval_Loss: 0.006578\n",
      "Train Epoch: 77/10000 (1%)\ttrain_Loss: 0.006546\tval_Loss: 0.006542\n",
      "Train Epoch: 78/10000 (1%)\ttrain_Loss: 0.006510\tval_Loss: 0.006510\n",
      "Train Epoch: 79/10000 (1%)\ttrain_Loss: 0.006479\tval_Loss: 0.006484\n",
      "Train Epoch: 80/10000 (1%)\ttrain_Loss: 0.006453\tval_Loss: 0.006464\n",
      "Train Epoch: 81/10000 (1%)\ttrain_Loss: 0.006433\tval_Loss: 0.006449\n",
      "Train Epoch: 82/10000 (1%)\ttrain_Loss: 0.006419\tval_Loss: 0.006439\n",
      "Train Epoch: 83/10000 (1%)\ttrain_Loss: 0.006409\tval_Loss: 0.006433\n",
      "Train Epoch: 84/10000 (1%)\ttrain_Loss: 0.006403\tval_Loss: 0.006430\n",
      "Train Epoch: 85/10000 (1%)\ttrain_Loss: 0.006400\tval_Loss: 0.006429\n",
      "Train Epoch: 86/10000 (1%)\ttrain_Loss: 0.006398\tval_Loss: 0.006429\n",
      "Train Epoch: 87/10000 (1%)\ttrain_Loss: 0.006397\tval_Loss: 0.006428\n",
      "Train Epoch: 88/10000 (1%)\ttrain_Loss: 0.006395\tval_Loss: 0.006427\n",
      "Train Epoch: 89/10000 (1%)\ttrain_Loss: 0.006392\tval_Loss: 0.006424\n",
      "Train Epoch: 90/10000 (1%)\ttrain_Loss: 0.006387\tval_Loss: 0.006420\n",
      "Train Epoch: 91/10000 (1%)\ttrain_Loss: 0.006381\tval_Loss: 0.006415\n",
      "Train Epoch: 92/10000 (1%)\ttrain_Loss: 0.006373\tval_Loss: 0.006409\n",
      "Train Epoch: 93/10000 (1%)\ttrain_Loss: 0.006364\tval_Loss: 0.006402\n",
      "Train Epoch: 94/10000 (1%)\ttrain_Loss: 0.006354\tval_Loss: 0.006396\n",
      "Train Epoch: 95/10000 (1%)\ttrain_Loss: 0.006344\tval_Loss: 0.006389\n",
      "Train Epoch: 96/10000 (1%)\ttrain_Loss: 0.006334\tval_Loss: 0.006383\n",
      "Train Epoch: 97/10000 (1%)\ttrain_Loss: 0.006324\tval_Loss: 0.006378\n",
      "Train Epoch: 98/10000 (1%)\ttrain_Loss: 0.006316\tval_Loss: 0.006374\n",
      "Train Epoch: 99/10000 (1%)\ttrain_Loss: 0.006308\tval_Loss: 0.006371\n",
      "Train Epoch: 100/10000 (1%)\ttrain_Loss: 0.006301\tval_Loss: 0.006368\n",
      "Train Epoch: 101/10000 (1%)\ttrain_Loss: 0.006295\tval_Loss: 0.006367\n",
      "Train Epoch: 102/10000 (1%)\ttrain_Loss: 0.006290\tval_Loss: 0.006365\n",
      "Train Epoch: 103/10000 (1%)\ttrain_Loss: 0.006286\tval_Loss: 0.006364\n",
      "Train Epoch: 104/10000 (1%)\ttrain_Loss: 0.006282\tval_Loss: 0.006363\n",
      "Train Epoch: 105/10000 (1%)\ttrain_Loss: 0.006278\tval_Loss: 0.006362\n",
      "Train Epoch: 106/10000 (1%)\ttrain_Loss: 0.006274\tval_Loss: 0.006360\n",
      "Train Epoch: 107/10000 (1%)\ttrain_Loss: 0.006270\tval_Loss: 0.006358\n",
      "Train Epoch: 108/10000 (1%)\ttrain_Loss: 0.006265\tval_Loss: 0.006355\n",
      "Train Epoch: 109/10000 (1%)\ttrain_Loss: 0.006261\tval_Loss: 0.006352\n",
      "Train Epoch: 110/10000 (1%)\ttrain_Loss: 0.006256\tval_Loss: 0.006348\n",
      "Train Epoch: 111/10000 (1%)\ttrain_Loss: 0.006251\tval_Loss: 0.006344\n",
      "Train Epoch: 112/10000 (1%)\ttrain_Loss: 0.006246\tval_Loss: 0.006340\n",
      "Train Epoch: 113/10000 (1%)\ttrain_Loss: 0.006241\tval_Loss: 0.006336\n",
      "Train Epoch: 114/10000 (1%)\ttrain_Loss: 0.006236\tval_Loss: 0.006332\n",
      "Train Epoch: 115/10000 (1%)\ttrain_Loss: 0.006230\tval_Loss: 0.006328\n",
      "Train Epoch: 116/10000 (1%)\ttrain_Loss: 0.006225\tval_Loss: 0.006324\n",
      "Train Epoch: 117/10000 (1%)\ttrain_Loss: 0.006221\tval_Loss: 0.006321\n",
      "Train Epoch: 118/10000 (1%)\ttrain_Loss: 0.006216\tval_Loss: 0.006317\n",
      "Train Epoch: 119/10000 (1%)\ttrain_Loss: 0.006212\tval_Loss: 0.006313\n",
      "Train Epoch: 120/10000 (1%)\ttrain_Loss: 0.006207\tval_Loss: 0.006310\n",
      "Train Epoch: 121/10000 (1%)\ttrain_Loss: 0.006203\tval_Loss: 0.006307\n",
      "Train Epoch: 122/10000 (1%)\ttrain_Loss: 0.006199\tval_Loss: 0.006304\n",
      "Train Epoch: 123/10000 (1%)\ttrain_Loss: 0.006194\tval_Loss: 0.006301\n",
      "Train Epoch: 124/10000 (1%)\ttrain_Loss: 0.006190\tval_Loss: 0.006297\n",
      "Train Epoch: 125/10000 (1%)\ttrain_Loss: 0.006186\tval_Loss: 0.006294\n",
      "Train Epoch: 126/10000 (1%)\ttrain_Loss: 0.006181\tval_Loss: 0.006291\n",
      "Train Epoch: 127/10000 (1%)\ttrain_Loss: 0.006177\tval_Loss: 0.006288\n",
      "Train Epoch: 128/10000 (1%)\ttrain_Loss: 0.006172\tval_Loss: 0.006285\n",
      "Train Epoch: 129/10000 (1%)\ttrain_Loss: 0.006168\tval_Loss: 0.006281\n",
      "Train Epoch: 130/10000 (1%)\ttrain_Loss: 0.006163\tval_Loss: 0.006278\n",
      "Train Epoch: 131/10000 (1%)\ttrain_Loss: 0.006159\tval_Loss: 0.006275\n",
      "Train Epoch: 132/10000 (1%)\ttrain_Loss: 0.006154\tval_Loss: 0.006272\n",
      "Train Epoch: 133/10000 (1%)\ttrain_Loss: 0.006150\tval_Loss: 0.006269\n",
      "Train Epoch: 134/10000 (1%)\ttrain_Loss: 0.006145\tval_Loss: 0.006265\n",
      "Train Epoch: 135/10000 (1%)\ttrain_Loss: 0.006141\tval_Loss: 0.006262\n",
      "Train Epoch: 136/10000 (1%)\ttrain_Loss: 0.006136\tval_Loss: 0.006259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 137/10000 (1%)\ttrain_Loss: 0.006132\tval_Loss: 0.006256\n",
      "Train Epoch: 138/10000 (1%)\ttrain_Loss: 0.006127\tval_Loss: 0.006252\n",
      "Train Epoch: 139/10000 (1%)\ttrain_Loss: 0.006123\tval_Loss: 0.006249\n",
      "Train Epoch: 140/10000 (1%)\ttrain_Loss: 0.006118\tval_Loss: 0.006245\n",
      "Train Epoch: 141/10000 (1%)\ttrain_Loss: 0.006114\tval_Loss: 0.006242\n",
      "Train Epoch: 142/10000 (1%)\ttrain_Loss: 0.006109\tval_Loss: 0.006238\n",
      "Train Epoch: 143/10000 (1%)\ttrain_Loss: 0.006105\tval_Loss: 0.006235\n",
      "Train Epoch: 144/10000 (1%)\ttrain_Loss: 0.006100\tval_Loss: 0.006231\n",
      "Train Epoch: 145/10000 (1%)\ttrain_Loss: 0.006096\tval_Loss: 0.006227\n",
      "Train Epoch: 146/10000 (1%)\ttrain_Loss: 0.006091\tval_Loss: 0.006223\n",
      "Train Epoch: 147/10000 (1%)\ttrain_Loss: 0.006087\tval_Loss: 0.006219\n",
      "Train Epoch: 148/10000 (1%)\ttrain_Loss: 0.006082\tval_Loss: 0.006215\n",
      "Train Epoch: 149/10000 (1%)\ttrain_Loss: 0.006078\tval_Loss: 0.006211\n",
      "Train Epoch: 150/10000 (1%)\ttrain_Loss: 0.006073\tval_Loss: 0.006207\n",
      "Train Epoch: 151/10000 (2%)\ttrain_Loss: 0.006069\tval_Loss: 0.006203\n",
      "Train Epoch: 152/10000 (2%)\ttrain_Loss: 0.006064\tval_Loss: 0.006199\n",
      "Train Epoch: 153/10000 (2%)\ttrain_Loss: 0.006060\tval_Loss: 0.006195\n",
      "Train Epoch: 154/10000 (2%)\ttrain_Loss: 0.006056\tval_Loss: 0.006191\n",
      "Train Epoch: 155/10000 (2%)\ttrain_Loss: 0.006051\tval_Loss: 0.006187\n",
      "Train Epoch: 156/10000 (2%)\ttrain_Loss: 0.006047\tval_Loss: 0.006183\n",
      "Train Epoch: 157/10000 (2%)\ttrain_Loss: 0.006042\tval_Loss: 0.006179\n",
      "Train Epoch: 158/10000 (2%)\ttrain_Loss: 0.006038\tval_Loss: 0.006175\n",
      "Train Epoch: 159/10000 (2%)\ttrain_Loss: 0.006034\tval_Loss: 0.006171\n",
      "Train Epoch: 160/10000 (2%)\ttrain_Loss: 0.006029\tval_Loss: 0.006167\n",
      "Train Epoch: 161/10000 (2%)\ttrain_Loss: 0.006025\tval_Loss: 0.006163\n",
      "Train Epoch: 162/10000 (2%)\ttrain_Loss: 0.006021\tval_Loss: 0.006159\n",
      "Train Epoch: 163/10000 (2%)\ttrain_Loss: 0.006016\tval_Loss: 0.006155\n",
      "Train Epoch: 164/10000 (2%)\ttrain_Loss: 0.006012\tval_Loss: 0.006151\n",
      "Train Epoch: 165/10000 (2%)\ttrain_Loss: 0.006008\tval_Loss: 0.006147\n",
      "Train Epoch: 166/10000 (2%)\ttrain_Loss: 0.006004\tval_Loss: 0.006143\n",
      "Train Epoch: 167/10000 (2%)\ttrain_Loss: 0.005999\tval_Loss: 0.006139\n",
      "Train Epoch: 168/10000 (2%)\ttrain_Loss: 0.005995\tval_Loss: 0.006136\n",
      "Train Epoch: 169/10000 (2%)\ttrain_Loss: 0.005991\tval_Loss: 0.006132\n",
      "Train Epoch: 170/10000 (2%)\ttrain_Loss: 0.005987\tval_Loss: 0.006128\n",
      "Train Epoch: 171/10000 (2%)\ttrain_Loss: 0.005983\tval_Loss: 0.006124\n",
      "Train Epoch: 172/10000 (2%)\ttrain_Loss: 0.005979\tval_Loss: 0.006120\n",
      "Train Epoch: 173/10000 (2%)\ttrain_Loss: 0.005975\tval_Loss: 0.006116\n",
      "Train Epoch: 174/10000 (2%)\ttrain_Loss: 0.005971\tval_Loss: 0.006112\n",
      "Train Epoch: 175/10000 (2%)\ttrain_Loss: 0.005967\tval_Loss: 0.006108\n",
      "Train Epoch: 176/10000 (2%)\ttrain_Loss: 0.005963\tval_Loss: 0.006105\n",
      "Train Epoch: 177/10000 (2%)\ttrain_Loss: 0.005959\tval_Loss: 0.006101\n",
      "Train Epoch: 178/10000 (2%)\ttrain_Loss: 0.005955\tval_Loss: 0.006097\n",
      "Train Epoch: 179/10000 (2%)\ttrain_Loss: 0.005951\tval_Loss: 0.006093\n",
      "Train Epoch: 180/10000 (2%)\ttrain_Loss: 0.005947\tval_Loss: 0.006090\n",
      "Train Epoch: 181/10000 (2%)\ttrain_Loss: 0.005943\tval_Loss: 0.006086\n",
      "Train Epoch: 182/10000 (2%)\ttrain_Loss: 0.005939\tval_Loss: 0.006082\n",
      "Train Epoch: 183/10000 (2%)\ttrain_Loss: 0.005935\tval_Loss: 0.006079\n",
      "Train Epoch: 184/10000 (2%)\ttrain_Loss: 0.005931\tval_Loss: 0.006075\n",
      "Train Epoch: 185/10000 (2%)\ttrain_Loss: 0.005928\tval_Loss: 0.006071\n",
      "Train Epoch: 186/10000 (2%)\ttrain_Loss: 0.005924\tval_Loss: 0.006068\n",
      "Train Epoch: 187/10000 (2%)\ttrain_Loss: 0.005920\tval_Loss: 0.006064\n",
      "Train Epoch: 188/10000 (2%)\ttrain_Loss: 0.005916\tval_Loss: 0.006061\n",
      "Train Epoch: 189/10000 (2%)\ttrain_Loss: 0.005912\tval_Loss: 0.006057\n",
      "Train Epoch: 190/10000 (2%)\ttrain_Loss: 0.005908\tval_Loss: 0.006054\n",
      "Train Epoch: 191/10000 (2%)\ttrain_Loss: 0.005905\tval_Loss: 0.006050\n",
      "Train Epoch: 192/10000 (2%)\ttrain_Loss: 0.005901\tval_Loss: 0.006047\n",
      "Train Epoch: 193/10000 (2%)\ttrain_Loss: 0.005897\tval_Loss: 0.006044\n",
      "Train Epoch: 194/10000 (2%)\ttrain_Loss: 0.005893\tval_Loss: 0.006040\n",
      "Train Epoch: 195/10000 (2%)\ttrain_Loss: 0.005890\tval_Loss: 0.006037\n",
      "Train Epoch: 196/10000 (2%)\ttrain_Loss: 0.005886\tval_Loss: 0.006034\n",
      "Train Epoch: 197/10000 (2%)\ttrain_Loss: 0.005882\tval_Loss: 0.006030\n",
      "Train Epoch: 198/10000 (2%)\ttrain_Loss: 0.005879\tval_Loss: 0.006027\n",
      "Train Epoch: 199/10000 (2%)\ttrain_Loss: 0.005875\tval_Loss: 0.006024\n",
      "Train Epoch: 200/10000 (2%)\ttrain_Loss: 0.005871\tval_Loss: 0.006020\n",
      "Train Epoch: 201/10000 (2%)\ttrain_Loss: 0.005868\tval_Loss: 0.006017\n",
      "Train Epoch: 202/10000 (2%)\ttrain_Loss: 0.005864\tval_Loss: 0.006014\n",
      "Train Epoch: 203/10000 (2%)\ttrain_Loss: 0.005861\tval_Loss: 0.006011\n",
      "Train Epoch: 204/10000 (2%)\ttrain_Loss: 0.005857\tval_Loss: 0.006007\n",
      "Train Epoch: 205/10000 (2%)\ttrain_Loss: 0.005853\tval_Loss: 0.006004\n",
      "Train Epoch: 206/10000 (2%)\ttrain_Loss: 0.005850\tval_Loss: 0.006001\n",
      "Train Epoch: 207/10000 (2%)\ttrain_Loss: 0.005846\tval_Loss: 0.005998\n",
      "Train Epoch: 208/10000 (2%)\ttrain_Loss: 0.005843\tval_Loss: 0.005995\n",
      "Train Epoch: 209/10000 (2%)\ttrain_Loss: 0.005839\tval_Loss: 0.005992\n",
      "Train Epoch: 210/10000 (2%)\ttrain_Loss: 0.005836\tval_Loss: 0.005989\n",
      "Train Epoch: 211/10000 (2%)\ttrain_Loss: 0.005833\tval_Loss: 0.005986\n",
      "Train Epoch: 212/10000 (2%)\ttrain_Loss: 0.005829\tval_Loss: 0.005983\n",
      "Train Epoch: 213/10000 (2%)\ttrain_Loss: 0.005826\tval_Loss: 0.005980\n",
      "Train Epoch: 214/10000 (2%)\ttrain_Loss: 0.005822\tval_Loss: 0.005977\n",
      "Train Epoch: 215/10000 (2%)\ttrain_Loss: 0.005819\tval_Loss: 0.005974\n",
      "Train Epoch: 216/10000 (2%)\ttrain_Loss: 0.005815\tval_Loss: 0.005971\n",
      "Train Epoch: 217/10000 (2%)\ttrain_Loss: 0.005812\tval_Loss: 0.005968\n",
      "Train Epoch: 218/10000 (2%)\ttrain_Loss: 0.005809\tval_Loss: 0.005965\n",
      "Train Epoch: 219/10000 (2%)\ttrain_Loss: 0.005805\tval_Loss: 0.005962\n",
      "Train Epoch: 220/10000 (2%)\ttrain_Loss: 0.005802\tval_Loss: 0.005959\n",
      "Train Epoch: 221/10000 (2%)\ttrain_Loss: 0.005799\tval_Loss: 0.005956\n",
      "Train Epoch: 222/10000 (2%)\ttrain_Loss: 0.005795\tval_Loss: 0.005953\n",
      "Train Epoch: 223/10000 (2%)\ttrain_Loss: 0.005792\tval_Loss: 0.005950\n",
      "Train Epoch: 224/10000 (2%)\ttrain_Loss: 0.005789\tval_Loss: 0.005947\n",
      "Train Epoch: 225/10000 (2%)\ttrain_Loss: 0.005786\tval_Loss: 0.005944\n",
      "Train Epoch: 226/10000 (2%)\ttrain_Loss: 0.005782\tval_Loss: 0.005942\n",
      "Train Epoch: 227/10000 (2%)\ttrain_Loss: 0.005779\tval_Loss: 0.005939\n",
      "Train Epoch: 228/10000 (2%)\ttrain_Loss: 0.005776\tval_Loss: 0.005936\n",
      "Train Epoch: 229/10000 (2%)\ttrain_Loss: 0.005773\tval_Loss: 0.005933\n",
      "Train Epoch: 230/10000 (2%)\ttrain_Loss: 0.005770\tval_Loss: 0.005930\n",
      "Train Epoch: 231/10000 (2%)\ttrain_Loss: 0.005767\tval_Loss: 0.005928\n",
      "Train Epoch: 232/10000 (2%)\ttrain_Loss: 0.005764\tval_Loss: 0.005925\n",
      "Train Epoch: 233/10000 (2%)\ttrain_Loss: 0.005760\tval_Loss: 0.005922\n",
      "Train Epoch: 234/10000 (2%)\ttrain_Loss: 0.005757\tval_Loss: 0.005919\n",
      "Train Epoch: 235/10000 (2%)\ttrain_Loss: 0.005754\tval_Loss: 0.005917\n",
      "Train Epoch: 236/10000 (2%)\ttrain_Loss: 0.005751\tval_Loss: 0.005914\n",
      "Train Epoch: 237/10000 (2%)\ttrain_Loss: 0.005748\tval_Loss: 0.005911\n",
      "Train Epoch: 238/10000 (2%)\ttrain_Loss: 0.005745\tval_Loss: 0.005909\n",
      "Train Epoch: 239/10000 (2%)\ttrain_Loss: 0.005742\tval_Loss: 0.005906\n",
      "Train Epoch: 240/10000 (2%)\ttrain_Loss: 0.005739\tval_Loss: 0.005903\n",
      "Train Epoch: 241/10000 (2%)\ttrain_Loss: 0.005736\tval_Loss: 0.005901\n",
      "Train Epoch: 242/10000 (2%)\ttrain_Loss: 0.005733\tval_Loss: 0.005898\n",
      "Train Epoch: 243/10000 (2%)\ttrain_Loss: 0.005730\tval_Loss: 0.005895\n",
      "Train Epoch: 244/10000 (2%)\ttrain_Loss: 0.005728\tval_Loss: 0.005893\n",
      "Train Epoch: 245/10000 (2%)\ttrain_Loss: 0.005725\tval_Loss: 0.005890\n",
      "Train Epoch: 246/10000 (2%)\ttrain_Loss: 0.005722\tval_Loss: 0.005887\n",
      "Train Epoch: 247/10000 (2%)\ttrain_Loss: 0.005719\tval_Loss: 0.005885\n",
      "Train Epoch: 248/10000 (2%)\ttrain_Loss: 0.005716\tval_Loss: 0.005882\n",
      "Train Epoch: 249/10000 (2%)\ttrain_Loss: 0.005713\tval_Loss: 0.005880\n",
      "Train Epoch: 250/10000 (2%)\ttrain_Loss: 0.005710\tval_Loss: 0.005877\n",
      "Train Epoch: 251/10000 (2%)\ttrain_Loss: 0.005708\tval_Loss: 0.005875\n",
      "Train Epoch: 252/10000 (3%)\ttrain_Loss: 0.005705\tval_Loss: 0.005872\n",
      "Train Epoch: 253/10000 (3%)\ttrain_Loss: 0.005702\tval_Loss: 0.005869\n",
      "Train Epoch: 254/10000 (3%)\ttrain_Loss: 0.005699\tval_Loss: 0.005867\n",
      "Train Epoch: 255/10000 (3%)\ttrain_Loss: 0.005697\tval_Loss: 0.005864\n",
      "Train Epoch: 256/10000 (3%)\ttrain_Loss: 0.005694\tval_Loss: 0.005862\n",
      "Train Epoch: 257/10000 (3%)\ttrain_Loss: 0.005691\tval_Loss: 0.005859\n",
      "Train Epoch: 258/10000 (3%)\ttrain_Loss: 0.005689\tval_Loss: 0.005857\n",
      "Train Epoch: 259/10000 (3%)\ttrain_Loss: 0.005686\tval_Loss: 0.005855\n",
      "Train Epoch: 260/10000 (3%)\ttrain_Loss: 0.005683\tval_Loss: 0.005852\n",
      "Train Epoch: 261/10000 (3%)\ttrain_Loss: 0.005681\tval_Loss: 0.005850\n",
      "Train Epoch: 262/10000 (3%)\ttrain_Loss: 0.005678\tval_Loss: 0.005847\n",
      "Train Epoch: 263/10000 (3%)\ttrain_Loss: 0.005676\tval_Loss: 0.005845\n",
      "Train Epoch: 264/10000 (3%)\ttrain_Loss: 0.005673\tval_Loss: 0.005843\n",
      "Train Epoch: 265/10000 (3%)\ttrain_Loss: 0.005671\tval_Loss: 0.005840\n",
      "Train Epoch: 266/10000 (3%)\ttrain_Loss: 0.005668\tval_Loss: 0.005838\n",
      "Train Epoch: 267/10000 (3%)\ttrain_Loss: 0.005666\tval_Loss: 0.005836\n",
      "Train Epoch: 268/10000 (3%)\ttrain_Loss: 0.005663\tval_Loss: 0.005833\n",
      "Train Epoch: 269/10000 (3%)\ttrain_Loss: 0.005661\tval_Loss: 0.005831\n",
      "Train Epoch: 270/10000 (3%)\ttrain_Loss: 0.005658\tval_Loss: 0.005829\n",
      "Train Epoch: 271/10000 (3%)\ttrain_Loss: 0.005656\tval_Loss: 0.005826\n",
      "Train Epoch: 272/10000 (3%)\ttrain_Loss: 0.005653\tval_Loss: 0.005824\n",
      "Train Epoch: 273/10000 (3%)\ttrain_Loss: 0.005651\tval_Loss: 0.005822\n",
      "Train Epoch: 274/10000 (3%)\ttrain_Loss: 0.005648\tval_Loss: 0.005820\n",
      "Train Epoch: 275/10000 (3%)\ttrain_Loss: 0.005646\tval_Loss: 0.005818\n",
      "Train Epoch: 276/10000 (3%)\ttrain_Loss: 0.005643\tval_Loss: 0.005815\n",
      "Train Epoch: 277/10000 (3%)\ttrain_Loss: 0.005641\tval_Loss: 0.005813\n",
      "Train Epoch: 278/10000 (3%)\ttrain_Loss: 0.005639\tval_Loss: 0.005811\n",
      "Train Epoch: 279/10000 (3%)\ttrain_Loss: 0.005636\tval_Loss: 0.005809\n",
      "Train Epoch: 280/10000 (3%)\ttrain_Loss: 0.005634\tval_Loss: 0.005807\n",
      "Train Epoch: 281/10000 (3%)\ttrain_Loss: 0.005632\tval_Loss: 0.005805\n",
      "Train Epoch: 282/10000 (3%)\ttrain_Loss: 0.005629\tval_Loss: 0.005802\n",
      "Train Epoch: 283/10000 (3%)\ttrain_Loss: 0.005627\tval_Loss: 0.005800\n",
      "Train Epoch: 284/10000 (3%)\ttrain_Loss: 0.005625\tval_Loss: 0.005798\n",
      "Train Epoch: 285/10000 (3%)\ttrain_Loss: 0.005623\tval_Loss: 0.005796\n",
      "Train Epoch: 286/10000 (3%)\ttrain_Loss: 0.005620\tval_Loss: 0.005794\n",
      "Train Epoch: 287/10000 (3%)\ttrain_Loss: 0.005618\tval_Loss: 0.005792\n",
      "Train Epoch: 288/10000 (3%)\ttrain_Loss: 0.005616\tval_Loss: 0.005790\n",
      "Train Epoch: 289/10000 (3%)\ttrain_Loss: 0.005614\tval_Loss: 0.005788\n",
      "Train Epoch: 290/10000 (3%)\ttrain_Loss: 0.005611\tval_Loss: 0.005786\n",
      "Train Epoch: 291/10000 (3%)\ttrain_Loss: 0.005609\tval_Loss: 0.005784\n",
      "Train Epoch: 292/10000 (3%)\ttrain_Loss: 0.005607\tval_Loss: 0.005782\n",
      "Train Epoch: 293/10000 (3%)\ttrain_Loss: 0.005605\tval_Loss: 0.005780\n",
      "Train Epoch: 294/10000 (3%)\ttrain_Loss: 0.005603\tval_Loss: 0.005778\n",
      "Train Epoch: 295/10000 (3%)\ttrain_Loss: 0.005601\tval_Loss: 0.005776\n",
      "Train Epoch: 296/10000 (3%)\ttrain_Loss: 0.005598\tval_Loss: 0.005774\n",
      "Train Epoch: 297/10000 (3%)\ttrain_Loss: 0.005596\tval_Loss: 0.005773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 298/10000 (3%)\ttrain_Loss: 0.005594\tval_Loss: 0.005771\n",
      "Train Epoch: 299/10000 (3%)\ttrain_Loss: 0.005592\tval_Loss: 0.005769\n",
      "Train Epoch: 300/10000 (3%)\ttrain_Loss: 0.005590\tval_Loss: 0.005767\n",
      "Train Epoch: 301/10000 (3%)\ttrain_Loss: 0.005588\tval_Loss: 0.005765\n",
      "Train Epoch: 302/10000 (3%)\ttrain_Loss: 0.005586\tval_Loss: 0.005763\n",
      "Train Epoch: 303/10000 (3%)\ttrain_Loss: 0.005584\tval_Loss: 0.005761\n",
      "Train Epoch: 304/10000 (3%)\ttrain_Loss: 0.005581\tval_Loss: 0.005759\n",
      "Train Epoch: 305/10000 (3%)\ttrain_Loss: 0.005579\tval_Loss: 0.005757\n",
      "Train Epoch: 306/10000 (3%)\ttrain_Loss: 0.005577\tval_Loss: 0.005756\n",
      "Train Epoch: 307/10000 (3%)\ttrain_Loss: 0.005575\tval_Loss: 0.005754\n",
      "Train Epoch: 308/10000 (3%)\ttrain_Loss: 0.005573\tval_Loss: 0.005752\n",
      "Train Epoch: 309/10000 (3%)\ttrain_Loss: 0.005571\tval_Loss: 0.005750\n",
      "Train Epoch: 310/10000 (3%)\ttrain_Loss: 0.005569\tval_Loss: 0.005748\n",
      "Train Epoch: 311/10000 (3%)\ttrain_Loss: 0.005567\tval_Loss: 0.005746\n",
      "Train Epoch: 312/10000 (3%)\ttrain_Loss: 0.005565\tval_Loss: 0.005744\n",
      "Train Epoch: 313/10000 (3%)\ttrain_Loss: 0.005563\tval_Loss: 0.005743\n",
      "Train Epoch: 314/10000 (3%)\ttrain_Loss: 0.005561\tval_Loss: 0.005741\n",
      "Train Epoch: 315/10000 (3%)\ttrain_Loss: 0.005559\tval_Loss: 0.005739\n",
      "Train Epoch: 316/10000 (3%)\ttrain_Loss: 0.005557\tval_Loss: 0.005737\n",
      "Train Epoch: 317/10000 (3%)\ttrain_Loss: 0.005555\tval_Loss: 0.005735\n",
      "Train Epoch: 318/10000 (3%)\ttrain_Loss: 0.005553\tval_Loss: 0.005734\n",
      "Train Epoch: 319/10000 (3%)\ttrain_Loss: 0.005551\tval_Loss: 0.005732\n",
      "Train Epoch: 320/10000 (3%)\ttrain_Loss: 0.005549\tval_Loss: 0.005730\n",
      "Train Epoch: 321/10000 (3%)\ttrain_Loss: 0.005547\tval_Loss: 0.005729\n",
      "Train Epoch: 322/10000 (3%)\ttrain_Loss: 0.005545\tval_Loss: 0.005727\n",
      "Train Epoch: 323/10000 (3%)\ttrain_Loss: 0.005543\tval_Loss: 0.005725\n",
      "Train Epoch: 324/10000 (3%)\ttrain_Loss: 0.005541\tval_Loss: 0.005724\n",
      "Train Epoch: 325/10000 (3%)\ttrain_Loss: 0.005539\tval_Loss: 0.005722\n",
      "Train Epoch: 326/10000 (3%)\ttrain_Loss: 0.005537\tval_Loss: 0.005720\n",
      "Train Epoch: 327/10000 (3%)\ttrain_Loss: 0.005535\tval_Loss: 0.005718\n",
      "Train Epoch: 328/10000 (3%)\ttrain_Loss: 0.005533\tval_Loss: 0.005717\n",
      "Train Epoch: 329/10000 (3%)\ttrain_Loss: 0.005531\tval_Loss: 0.005715\n",
      "Train Epoch: 330/10000 (3%)\ttrain_Loss: 0.005529\tval_Loss: 0.005713\n",
      "Train Epoch: 331/10000 (3%)\ttrain_Loss: 0.005527\tval_Loss: 0.005712\n",
      "Train Epoch: 332/10000 (3%)\ttrain_Loss: 0.005525\tval_Loss: 0.005710\n",
      "Train Epoch: 333/10000 (3%)\ttrain_Loss: 0.005523\tval_Loss: 0.005708\n",
      "Train Epoch: 334/10000 (3%)\ttrain_Loss: 0.005521\tval_Loss: 0.005707\n",
      "Train Epoch: 335/10000 (3%)\ttrain_Loss: 0.005520\tval_Loss: 0.005705\n",
      "Train Epoch: 336/10000 (3%)\ttrain_Loss: 0.005518\tval_Loss: 0.005703\n",
      "Train Epoch: 337/10000 (3%)\ttrain_Loss: 0.005516\tval_Loss: 0.005701\n",
      "Train Epoch: 338/10000 (3%)\ttrain_Loss: 0.005514\tval_Loss: 0.005700\n",
      "Train Epoch: 339/10000 (3%)\ttrain_Loss: 0.005512\tval_Loss: 0.005698\n",
      "Train Epoch: 340/10000 (3%)\ttrain_Loss: 0.005510\tval_Loss: 0.005696\n",
      "Train Epoch: 341/10000 (3%)\ttrain_Loss: 0.005508\tval_Loss: 0.005694\n",
      "Train Epoch: 342/10000 (3%)\ttrain_Loss: 0.005506\tval_Loss: 0.005693\n",
      "Train Epoch: 343/10000 (3%)\ttrain_Loss: 0.005504\tval_Loss: 0.005691\n",
      "Train Epoch: 344/10000 (3%)\ttrain_Loss: 0.005503\tval_Loss: 0.005689\n",
      "Train Epoch: 345/10000 (3%)\ttrain_Loss: 0.005501\tval_Loss: 0.005688\n",
      "Train Epoch: 346/10000 (3%)\ttrain_Loss: 0.005499\tval_Loss: 0.005686\n",
      "Train Epoch: 347/10000 (3%)\ttrain_Loss: 0.005497\tval_Loss: 0.005685\n",
      "Train Epoch: 348/10000 (3%)\ttrain_Loss: 0.005495\tval_Loss: 0.005683\n",
      "Train Epoch: 349/10000 (3%)\ttrain_Loss: 0.005493\tval_Loss: 0.005681\n",
      "Train Epoch: 350/10000 (3%)\ttrain_Loss: 0.005492\tval_Loss: 0.005680\n",
      "Train Epoch: 351/10000 (4%)\ttrain_Loss: 0.005490\tval_Loss: 0.005678\n",
      "Train Epoch: 352/10000 (4%)\ttrain_Loss: 0.005488\tval_Loss: 0.005676\n",
      "Train Epoch: 353/10000 (4%)\ttrain_Loss: 0.005486\tval_Loss: 0.005675\n",
      "Train Epoch: 354/10000 (4%)\ttrain_Loss: 0.005484\tval_Loss: 0.005673\n",
      "Train Epoch: 355/10000 (4%)\ttrain_Loss: 0.005482\tval_Loss: 0.005672\n",
      "Train Epoch: 356/10000 (4%)\ttrain_Loss: 0.005480\tval_Loss: 0.005670\n",
      "Train Epoch: 357/10000 (4%)\ttrain_Loss: 0.005479\tval_Loss: 0.005669\n",
      "Train Epoch: 358/10000 (4%)\ttrain_Loss: 0.005477\tval_Loss: 0.005667\n",
      "Train Epoch: 359/10000 (4%)\ttrain_Loss: 0.005475\tval_Loss: 0.005666\n",
      "Train Epoch: 360/10000 (4%)\ttrain_Loss: 0.005473\tval_Loss: 0.005664\n",
      "Train Epoch: 361/10000 (4%)\ttrain_Loss: 0.005471\tval_Loss: 0.005663\n",
      "Train Epoch: 362/10000 (4%)\ttrain_Loss: 0.005470\tval_Loss: 0.005661\n",
      "Train Epoch: 363/10000 (4%)\ttrain_Loss: 0.005468\tval_Loss: 0.005660\n",
      "Train Epoch: 364/10000 (4%)\ttrain_Loss: 0.005466\tval_Loss: 0.005658\n",
      "Train Epoch: 365/10000 (4%)\ttrain_Loss: 0.005464\tval_Loss: 0.005657\n",
      "Train Epoch: 366/10000 (4%)\ttrain_Loss: 0.005463\tval_Loss: 0.005655\n",
      "Train Epoch: 367/10000 (4%)\ttrain_Loss: 0.005461\tval_Loss: 0.005654\n",
      "Train Epoch: 368/10000 (4%)\ttrain_Loss: 0.005459\tval_Loss: 0.005652\n",
      "Train Epoch: 369/10000 (4%)\ttrain_Loss: 0.005457\tval_Loss: 0.005651\n",
      "Train Epoch: 370/10000 (4%)\ttrain_Loss: 0.005456\tval_Loss: 0.005649\n",
      "Train Epoch: 371/10000 (4%)\ttrain_Loss: 0.005454\tval_Loss: 0.005648\n",
      "Train Epoch: 372/10000 (4%)\ttrain_Loss: 0.005452\tval_Loss: 0.005646\n",
      "Train Epoch: 373/10000 (4%)\ttrain_Loss: 0.005450\tval_Loss: 0.005645\n",
      "Train Epoch: 374/10000 (4%)\ttrain_Loss: 0.005449\tval_Loss: 0.005643\n",
      "Train Epoch: 375/10000 (4%)\ttrain_Loss: 0.005447\tval_Loss: 0.005642\n",
      "Train Epoch: 376/10000 (4%)\ttrain_Loss: 0.005445\tval_Loss: 0.005640\n",
      "Train Epoch: 377/10000 (4%)\ttrain_Loss: 0.005443\tval_Loss: 0.005639\n",
      "Train Epoch: 378/10000 (4%)\ttrain_Loss: 0.005442\tval_Loss: 0.005637\n",
      "Train Epoch: 379/10000 (4%)\ttrain_Loss: 0.005440\tval_Loss: 0.005636\n",
      "Train Epoch: 380/10000 (4%)\ttrain_Loss: 0.005438\tval_Loss: 0.005634\n",
      "Train Epoch: 381/10000 (4%)\ttrain_Loss: 0.005437\tval_Loss: 0.005633\n",
      "Train Epoch: 382/10000 (4%)\ttrain_Loss: 0.005435\tval_Loss: 0.005632\n",
      "Train Epoch: 383/10000 (4%)\ttrain_Loss: 0.005433\tval_Loss: 0.005630\n",
      "Train Epoch: 384/10000 (4%)\ttrain_Loss: 0.005431\tval_Loss: 0.005629\n",
      "Train Epoch: 385/10000 (4%)\ttrain_Loss: 0.005430\tval_Loss: 0.005627\n",
      "Train Epoch: 386/10000 (4%)\ttrain_Loss: 0.005428\tval_Loss: 0.005625\n",
      "Train Epoch: 387/10000 (4%)\ttrain_Loss: 0.005426\tval_Loss: 0.005624\n",
      "Train Epoch: 388/10000 (4%)\ttrain_Loss: 0.005425\tval_Loss: 0.005622\n",
      "Train Epoch: 389/10000 (4%)\ttrain_Loss: 0.005423\tval_Loss: 0.005621\n",
      "Train Epoch: 390/10000 (4%)\ttrain_Loss: 0.005421\tval_Loss: 0.005619\n",
      "Train Epoch: 391/10000 (4%)\ttrain_Loss: 0.005419\tval_Loss: 0.005618\n",
      "Train Epoch: 392/10000 (4%)\ttrain_Loss: 0.005418\tval_Loss: 0.005616\n",
      "Train Epoch: 393/10000 (4%)\ttrain_Loss: 0.005416\tval_Loss: 0.005615\n",
      "Train Epoch: 394/10000 (4%)\ttrain_Loss: 0.005414\tval_Loss: 0.005614\n",
      "Train Epoch: 395/10000 (4%)\ttrain_Loss: 0.005413\tval_Loss: 0.005612\n",
      "Train Epoch: 396/10000 (4%)\ttrain_Loss: 0.005411\tval_Loss: 0.005611\n",
      "Train Epoch: 397/10000 (4%)\ttrain_Loss: 0.005409\tval_Loss: 0.005609\n",
      "Train Epoch: 398/10000 (4%)\ttrain_Loss: 0.005408\tval_Loss: 0.005608\n",
      "Train Epoch: 399/10000 (4%)\ttrain_Loss: 0.005406\tval_Loss: 0.005607\n",
      "Train Epoch: 400/10000 (4%)\ttrain_Loss: 0.005404\tval_Loss: 0.005605\n",
      "Train Epoch: 401/10000 (4%)\ttrain_Loss: 0.005402\tval_Loss: 0.005604\n",
      "Train Epoch: 402/10000 (4%)\ttrain_Loss: 0.005401\tval_Loss: 0.005603\n",
      "Train Epoch: 403/10000 (4%)\ttrain_Loss: 0.005399\tval_Loss: 0.005601\n",
      "Train Epoch: 404/10000 (4%)\ttrain_Loss: 0.005397\tval_Loss: 0.005600\n",
      "Train Epoch: 405/10000 (4%)\ttrain_Loss: 0.005396\tval_Loss: 0.005599\n",
      "Train Epoch: 406/10000 (4%)\ttrain_Loss: 0.005394\tval_Loss: 0.005597\n",
      "Train Epoch: 407/10000 (4%)\ttrain_Loss: 0.005392\tval_Loss: 0.005596\n",
      "Train Epoch: 408/10000 (4%)\ttrain_Loss: 0.005391\tval_Loss: 0.005595\n",
      "Train Epoch: 409/10000 (4%)\ttrain_Loss: 0.005389\tval_Loss: 0.005593\n",
      "Train Epoch: 410/10000 (4%)\ttrain_Loss: 0.005387\tval_Loss: 0.005592\n",
      "Train Epoch: 411/10000 (4%)\ttrain_Loss: 0.005386\tval_Loss: 0.005591\n",
      "Train Epoch: 412/10000 (4%)\ttrain_Loss: 0.005384\tval_Loss: 0.005590\n",
      "Train Epoch: 413/10000 (4%)\ttrain_Loss: 0.005382\tval_Loss: 0.005588\n",
      "Train Epoch: 414/10000 (4%)\ttrain_Loss: 0.005380\tval_Loss: 0.005587\n",
      "Train Epoch: 415/10000 (4%)\ttrain_Loss: 0.005379\tval_Loss: 0.005586\n",
      "Train Epoch: 416/10000 (4%)\ttrain_Loss: 0.005377\tval_Loss: 0.005585\n",
      "Train Epoch: 417/10000 (4%)\ttrain_Loss: 0.005375\tval_Loss: 0.005584\n",
      "Train Epoch: 418/10000 (4%)\ttrain_Loss: 0.005374\tval_Loss: 0.005582\n",
      "Train Epoch: 419/10000 (4%)\ttrain_Loss: 0.005372\tval_Loss: 0.005581\n",
      "Train Epoch: 420/10000 (4%)\ttrain_Loss: 0.005370\tval_Loss: 0.005580\n",
      "Train Epoch: 421/10000 (4%)\ttrain_Loss: 0.005369\tval_Loss: 0.005578\n",
      "Train Epoch: 422/10000 (4%)\ttrain_Loss: 0.005367\tval_Loss: 0.005577\n",
      "Train Epoch: 423/10000 (4%)\ttrain_Loss: 0.005365\tval_Loss: 0.005576\n",
      "Train Epoch: 424/10000 (4%)\ttrain_Loss: 0.005364\tval_Loss: 0.005574\n",
      "Train Epoch: 425/10000 (4%)\ttrain_Loss: 0.005362\tval_Loss: 0.005573\n",
      "Train Epoch: 426/10000 (4%)\ttrain_Loss: 0.005361\tval_Loss: 0.005571\n",
      "Train Epoch: 427/10000 (4%)\ttrain_Loss: 0.005359\tval_Loss: 0.005570\n",
      "Train Epoch: 428/10000 (4%)\ttrain_Loss: 0.005357\tval_Loss: 0.005569\n",
      "Train Epoch: 429/10000 (4%)\ttrain_Loss: 0.005356\tval_Loss: 0.005567\n",
      "Train Epoch: 430/10000 (4%)\ttrain_Loss: 0.005354\tval_Loss: 0.005566\n",
      "Train Epoch: 431/10000 (4%)\ttrain_Loss: 0.005352\tval_Loss: 0.005565\n",
      "Train Epoch: 432/10000 (4%)\ttrain_Loss: 0.005351\tval_Loss: 0.005563\n",
      "Train Epoch: 433/10000 (4%)\ttrain_Loss: 0.005349\tval_Loss: 0.005562\n",
      "Train Epoch: 434/10000 (4%)\ttrain_Loss: 0.005347\tval_Loss: 0.005561\n",
      "Train Epoch: 435/10000 (4%)\ttrain_Loss: 0.005346\tval_Loss: 0.005559\n",
      "Train Epoch: 436/10000 (4%)\ttrain_Loss: 0.005344\tval_Loss: 0.005558\n",
      "Train Epoch: 437/10000 (4%)\ttrain_Loss: 0.005342\tval_Loss: 0.005557\n",
      "Train Epoch: 438/10000 (4%)\ttrain_Loss: 0.005341\tval_Loss: 0.005555\n",
      "Train Epoch: 439/10000 (4%)\ttrain_Loss: 0.005339\tval_Loss: 0.005554\n",
      "Train Epoch: 440/10000 (4%)\ttrain_Loss: 0.005337\tval_Loss: 0.005553\n",
      "Train Epoch: 441/10000 (4%)\ttrain_Loss: 0.005336\tval_Loss: 0.005552\n",
      "Train Epoch: 442/10000 (4%)\ttrain_Loss: 0.005334\tval_Loss: 0.005550\n",
      "Train Epoch: 443/10000 (4%)\ttrain_Loss: 0.005332\tval_Loss: 0.005549\n",
      "Train Epoch: 444/10000 (4%)\ttrain_Loss: 0.005331\tval_Loss: 0.005548\n",
      "Train Epoch: 445/10000 (4%)\ttrain_Loss: 0.005329\tval_Loss: 0.005546\n",
      "Train Epoch: 446/10000 (4%)\ttrain_Loss: 0.005327\tval_Loss: 0.005545\n",
      "Train Epoch: 447/10000 (4%)\ttrain_Loss: 0.005326\tval_Loss: 0.005544\n",
      "Train Epoch: 448/10000 (4%)\ttrain_Loss: 0.005324\tval_Loss: 0.005543\n",
      "Train Epoch: 449/10000 (4%)\ttrain_Loss: 0.005322\tval_Loss: 0.005542\n",
      "Train Epoch: 450/10000 (4%)\ttrain_Loss: 0.005321\tval_Loss: 0.005541\n",
      "Train Epoch: 451/10000 (4%)\ttrain_Loss: 0.005319\tval_Loss: 0.005540\n",
      "Train Epoch: 452/10000 (5%)\ttrain_Loss: 0.005317\tval_Loss: 0.005538\n",
      "Train Epoch: 453/10000 (5%)\ttrain_Loss: 0.005316\tval_Loss: 0.005537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 454/10000 (5%)\ttrain_Loss: 0.005314\tval_Loss: 0.005536\n",
      "Train Epoch: 455/10000 (5%)\ttrain_Loss: 0.005312\tval_Loss: 0.005535\n",
      "Train Epoch: 456/10000 (5%)\ttrain_Loss: 0.005310\tval_Loss: 0.005534\n",
      "Train Epoch: 457/10000 (5%)\ttrain_Loss: 0.005309\tval_Loss: 0.005532\n",
      "Train Epoch: 458/10000 (5%)\ttrain_Loss: 0.005307\tval_Loss: 0.005531\n",
      "Train Epoch: 459/10000 (5%)\ttrain_Loss: 0.005305\tval_Loss: 0.005529\n",
      "Train Epoch: 460/10000 (5%)\ttrain_Loss: 0.005304\tval_Loss: 0.005528\n",
      "Train Epoch: 461/10000 (5%)\ttrain_Loss: 0.005302\tval_Loss: 0.005527\n",
      "Train Epoch: 462/10000 (5%)\ttrain_Loss: 0.005300\tval_Loss: 0.005526\n",
      "Train Epoch: 463/10000 (5%)\ttrain_Loss: 0.005299\tval_Loss: 0.005524\n",
      "Train Epoch: 464/10000 (5%)\ttrain_Loss: 0.005297\tval_Loss: 0.005523\n",
      "Train Epoch: 465/10000 (5%)\ttrain_Loss: 0.005295\tval_Loss: 0.005522\n",
      "Train Epoch: 466/10000 (5%)\ttrain_Loss: 0.005294\tval_Loss: 0.005520\n",
      "Train Epoch: 467/10000 (5%)\ttrain_Loss: 0.005292\tval_Loss: 0.005518\n",
      "Train Epoch: 468/10000 (5%)\ttrain_Loss: 0.005290\tval_Loss: 0.005517\n",
      "Train Epoch: 469/10000 (5%)\ttrain_Loss: 0.005289\tval_Loss: 0.005516\n",
      "Train Epoch: 470/10000 (5%)\ttrain_Loss: 0.005287\tval_Loss: 0.005514\n",
      "Train Epoch: 471/10000 (5%)\ttrain_Loss: 0.005285\tval_Loss: 0.005513\n",
      "Train Epoch: 472/10000 (5%)\ttrain_Loss: 0.005284\tval_Loss: 0.005511\n",
      "Train Epoch: 473/10000 (5%)\ttrain_Loss: 0.005282\tval_Loss: 0.005509\n",
      "Train Epoch: 474/10000 (5%)\ttrain_Loss: 0.005280\tval_Loss: 0.005508\n",
      "Train Epoch: 475/10000 (5%)\ttrain_Loss: 0.005279\tval_Loss: 0.005506\n",
      "Train Epoch: 476/10000 (5%)\ttrain_Loss: 0.005277\tval_Loss: 0.005505\n",
      "Train Epoch: 477/10000 (5%)\ttrain_Loss: 0.005275\tval_Loss: 0.005503\n",
      "Train Epoch: 478/10000 (5%)\ttrain_Loss: 0.005274\tval_Loss: 0.005502\n",
      "Train Epoch: 479/10000 (5%)\ttrain_Loss: 0.005272\tval_Loss: 0.005500\n",
      "Train Epoch: 480/10000 (5%)\ttrain_Loss: 0.005270\tval_Loss: 0.005499\n",
      "Train Epoch: 481/10000 (5%)\ttrain_Loss: 0.005268\tval_Loss: 0.005497\n",
      "Train Epoch: 482/10000 (5%)\ttrain_Loss: 0.005267\tval_Loss: 0.005495\n",
      "Train Epoch: 483/10000 (5%)\ttrain_Loss: 0.005265\tval_Loss: 0.005494\n",
      "Train Epoch: 484/10000 (5%)\ttrain_Loss: 0.005263\tval_Loss: 0.005492\n",
      "Train Epoch: 485/10000 (5%)\ttrain_Loss: 0.005262\tval_Loss: 0.005491\n",
      "Train Epoch: 486/10000 (5%)\ttrain_Loss: 0.005260\tval_Loss: 0.005489\n",
      "Train Epoch: 487/10000 (5%)\ttrain_Loss: 0.005258\tval_Loss: 0.005488\n",
      "Train Epoch: 488/10000 (5%)\ttrain_Loss: 0.005257\tval_Loss: 0.005487\n",
      "Train Epoch: 489/10000 (5%)\ttrain_Loss: 0.005255\tval_Loss: 0.005485\n",
      "Train Epoch: 490/10000 (5%)\ttrain_Loss: 0.005253\tval_Loss: 0.005484\n",
      "Train Epoch: 491/10000 (5%)\ttrain_Loss: 0.005252\tval_Loss: 0.005482\n",
      "Train Epoch: 492/10000 (5%)\ttrain_Loss: 0.005250\tval_Loss: 0.005481\n",
      "Train Epoch: 493/10000 (5%)\ttrain_Loss: 0.005248\tval_Loss: 0.005480\n",
      "Train Epoch: 494/10000 (5%)\ttrain_Loss: 0.005247\tval_Loss: 0.005479\n",
      "Train Epoch: 495/10000 (5%)\ttrain_Loss: 0.005245\tval_Loss: 0.005478\n",
      "Train Epoch: 496/10000 (5%)\ttrain_Loss: 0.005243\tval_Loss: 0.005476\n",
      "Train Epoch: 497/10000 (5%)\ttrain_Loss: 0.005242\tval_Loss: 0.005475\n",
      "Train Epoch: 498/10000 (5%)\ttrain_Loss: 0.005240\tval_Loss: 0.005473\n",
      "Train Epoch: 499/10000 (5%)\ttrain_Loss: 0.005238\tval_Loss: 0.005472\n",
      "Train Epoch: 500/10000 (5%)\ttrain_Loss: 0.005237\tval_Loss: 0.005471\n",
      "Train Epoch: 501/10000 (5%)\ttrain_Loss: 0.005235\tval_Loss: 0.005469\n",
      "Train Epoch: 502/10000 (5%)\ttrain_Loss: 0.005233\tval_Loss: 0.005468\n",
      "Train Epoch: 503/10000 (5%)\ttrain_Loss: 0.005232\tval_Loss: 0.005467\n",
      "Train Epoch: 504/10000 (5%)\ttrain_Loss: 0.005230\tval_Loss: 0.005466\n",
      "Train Epoch: 505/10000 (5%)\ttrain_Loss: 0.005228\tval_Loss: 0.005464\n",
      "Train Epoch: 506/10000 (5%)\ttrain_Loss: 0.005226\tval_Loss: 0.005463\n",
      "Train Epoch: 507/10000 (5%)\ttrain_Loss: 0.005225\tval_Loss: 0.005461\n",
      "Train Epoch: 508/10000 (5%)\ttrain_Loss: 0.005223\tval_Loss: 0.005460\n",
      "Train Epoch: 509/10000 (5%)\ttrain_Loss: 0.005221\tval_Loss: 0.005459\n",
      "Train Epoch: 510/10000 (5%)\ttrain_Loss: 0.005220\tval_Loss: 0.005457\n",
      "Train Epoch: 511/10000 (5%)\ttrain_Loss: 0.005218\tval_Loss: 0.005456\n",
      "Train Epoch: 512/10000 (5%)\ttrain_Loss: 0.005216\tval_Loss: 0.005455\n",
      "Train Epoch: 513/10000 (5%)\ttrain_Loss: 0.005215\tval_Loss: 0.005453\n",
      "Train Epoch: 514/10000 (5%)\ttrain_Loss: 0.005213\tval_Loss: 0.005452\n",
      "Train Epoch: 515/10000 (5%)\ttrain_Loss: 0.005211\tval_Loss: 0.005450\n",
      "Train Epoch: 516/10000 (5%)\ttrain_Loss: 0.005210\tval_Loss: 0.005449\n",
      "Train Epoch: 517/10000 (5%)\ttrain_Loss: 0.005208\tval_Loss: 0.005447\n",
      "Train Epoch: 518/10000 (5%)\ttrain_Loss: 0.005206\tval_Loss: 0.005446\n",
      "Train Epoch: 519/10000 (5%)\ttrain_Loss: 0.005205\tval_Loss: 0.005445\n",
      "Train Epoch: 520/10000 (5%)\ttrain_Loss: 0.005203\tval_Loss: 0.005443\n",
      "Train Epoch: 521/10000 (5%)\ttrain_Loss: 0.005201\tval_Loss: 0.005442\n",
      "Train Epoch: 522/10000 (5%)\ttrain_Loss: 0.005200\tval_Loss: 0.005440\n",
      "Train Epoch: 523/10000 (5%)\ttrain_Loss: 0.005198\tval_Loss: 0.005439\n",
      "Train Epoch: 524/10000 (5%)\ttrain_Loss: 0.005196\tval_Loss: 0.005437\n",
      "Train Epoch: 525/10000 (5%)\ttrain_Loss: 0.005195\tval_Loss: 0.005435\n",
      "Train Epoch: 526/10000 (5%)\ttrain_Loss: 0.005193\tval_Loss: 0.005434\n",
      "Train Epoch: 527/10000 (5%)\ttrain_Loss: 0.005191\tval_Loss: 0.005432\n",
      "Train Epoch: 528/10000 (5%)\ttrain_Loss: 0.005189\tval_Loss: 0.005431\n",
      "Train Epoch: 529/10000 (5%)\ttrain_Loss: 0.005188\tval_Loss: 0.005430\n",
      "Train Epoch: 530/10000 (5%)\ttrain_Loss: 0.005186\tval_Loss: 0.005428\n",
      "Train Epoch: 531/10000 (5%)\ttrain_Loss: 0.005184\tval_Loss: 0.005427\n",
      "Train Epoch: 532/10000 (5%)\ttrain_Loss: 0.005183\tval_Loss: 0.005425\n",
      "Train Epoch: 533/10000 (5%)\ttrain_Loss: 0.005181\tval_Loss: 0.005424\n",
      "Train Epoch: 534/10000 (5%)\ttrain_Loss: 0.005179\tval_Loss: 0.005422\n",
      "Train Epoch: 535/10000 (5%)\ttrain_Loss: 0.005178\tval_Loss: 0.005421\n",
      "Train Epoch: 536/10000 (5%)\ttrain_Loss: 0.005176\tval_Loss: 0.005420\n",
      "Train Epoch: 537/10000 (5%)\ttrain_Loss: 0.005174\tval_Loss: 0.005418\n",
      "Train Epoch: 538/10000 (5%)\ttrain_Loss: 0.005173\tval_Loss: 0.005417\n",
      "Train Epoch: 539/10000 (5%)\ttrain_Loss: 0.005171\tval_Loss: 0.005415\n",
      "Train Epoch: 540/10000 (5%)\ttrain_Loss: 0.005169\tval_Loss: 0.005414\n",
      "Train Epoch: 541/10000 (5%)\ttrain_Loss: 0.005167\tval_Loss: 0.005412\n",
      "Train Epoch: 542/10000 (5%)\ttrain_Loss: 0.005166\tval_Loss: 0.005411\n",
      "Train Epoch: 543/10000 (5%)\ttrain_Loss: 0.005164\tval_Loss: 0.005410\n",
      "Train Epoch: 544/10000 (5%)\ttrain_Loss: 0.005162\tval_Loss: 0.005409\n",
      "Train Epoch: 545/10000 (5%)\ttrain_Loss: 0.005160\tval_Loss: 0.005407\n",
      "Train Epoch: 546/10000 (5%)\ttrain_Loss: 0.005159\tval_Loss: 0.005406\n",
      "Train Epoch: 547/10000 (5%)\ttrain_Loss: 0.005157\tval_Loss: 0.005404\n",
      "Train Epoch: 548/10000 (5%)\ttrain_Loss: 0.005155\tval_Loss: 0.005403\n",
      "Train Epoch: 549/10000 (5%)\ttrain_Loss: 0.005154\tval_Loss: 0.005402\n",
      "Train Epoch: 550/10000 (5%)\ttrain_Loss: 0.005152\tval_Loss: 0.005400\n",
      "Train Epoch: 551/10000 (6%)\ttrain_Loss: 0.005150\tval_Loss: 0.005399\n",
      "Train Epoch: 552/10000 (6%)\ttrain_Loss: 0.005148\tval_Loss: 0.005397\n",
      "Train Epoch: 553/10000 (6%)\ttrain_Loss: 0.005146\tval_Loss: 0.005396\n",
      "Train Epoch: 554/10000 (6%)\ttrain_Loss: 0.005145\tval_Loss: 0.005395\n",
      "Train Epoch: 555/10000 (6%)\ttrain_Loss: 0.005143\tval_Loss: 0.005393\n",
      "Train Epoch: 556/10000 (6%)\ttrain_Loss: 0.005141\tval_Loss: 0.005392\n",
      "Train Epoch: 557/10000 (6%)\ttrain_Loss: 0.005139\tval_Loss: 0.005391\n",
      "Train Epoch: 558/10000 (6%)\ttrain_Loss: 0.005138\tval_Loss: 0.005389\n",
      "Train Epoch: 559/10000 (6%)\ttrain_Loss: 0.005136\tval_Loss: 0.005388\n",
      "Train Epoch: 560/10000 (6%)\ttrain_Loss: 0.005134\tval_Loss: 0.005387\n",
      "Train Epoch: 561/10000 (6%)\ttrain_Loss: 0.005132\tval_Loss: 0.005385\n",
      "Train Epoch: 562/10000 (6%)\ttrain_Loss: 0.005130\tval_Loss: 0.005383\n",
      "Train Epoch: 563/10000 (6%)\ttrain_Loss: 0.005129\tval_Loss: 0.005381\n",
      "Train Epoch: 564/10000 (6%)\ttrain_Loss: 0.005127\tval_Loss: 0.005380\n",
      "Train Epoch: 565/10000 (6%)\ttrain_Loss: 0.005125\tval_Loss: 0.005378\n",
      "Train Epoch: 566/10000 (6%)\ttrain_Loss: 0.005123\tval_Loss: 0.005377\n",
      "Train Epoch: 567/10000 (6%)\ttrain_Loss: 0.005122\tval_Loss: 0.005375\n",
      "Train Epoch: 568/10000 (6%)\ttrain_Loss: 0.005120\tval_Loss: 0.005374\n",
      "Train Epoch: 569/10000 (6%)\ttrain_Loss: 0.005118\tval_Loss: 0.005372\n",
      "Train Epoch: 570/10000 (6%)\ttrain_Loss: 0.005116\tval_Loss: 0.005371\n",
      "Train Epoch: 571/10000 (6%)\ttrain_Loss: 0.005114\tval_Loss: 0.005370\n",
      "Train Epoch: 572/10000 (6%)\ttrain_Loss: 0.005113\tval_Loss: 0.005368\n",
      "Train Epoch: 573/10000 (6%)\ttrain_Loss: 0.005111\tval_Loss: 0.005367\n",
      "Train Epoch: 574/10000 (6%)\ttrain_Loss: 0.005109\tval_Loss: 0.005365\n",
      "Train Epoch: 575/10000 (6%)\ttrain_Loss: 0.005107\tval_Loss: 0.005363\n",
      "Train Epoch: 576/10000 (6%)\ttrain_Loss: 0.005106\tval_Loss: 0.005362\n",
      "Train Epoch: 577/10000 (6%)\ttrain_Loss: 0.005104\tval_Loss: 0.005360\n",
      "Train Epoch: 578/10000 (6%)\ttrain_Loss: 0.005102\tval_Loss: 0.005359\n",
      "Train Epoch: 579/10000 (6%)\ttrain_Loss: 0.005100\tval_Loss: 0.005357\n",
      "Train Epoch: 580/10000 (6%)\ttrain_Loss: 0.005099\tval_Loss: 0.005356\n",
      "Train Epoch: 581/10000 (6%)\ttrain_Loss: 0.005097\tval_Loss: 0.005354\n",
      "Train Epoch: 582/10000 (6%)\ttrain_Loss: 0.005095\tval_Loss: 0.005352\n",
      "Train Epoch: 583/10000 (6%)\ttrain_Loss: 0.005093\tval_Loss: 0.005351\n",
      "Train Epoch: 584/10000 (6%)\ttrain_Loss: 0.005092\tval_Loss: 0.005349\n",
      "Train Epoch: 585/10000 (6%)\ttrain_Loss: 0.005090\tval_Loss: 0.005348\n",
      "Train Epoch: 586/10000 (6%)\ttrain_Loss: 0.005088\tval_Loss: 0.005346\n",
      "Train Epoch: 587/10000 (6%)\ttrain_Loss: 0.005087\tval_Loss: 0.005345\n",
      "Train Epoch: 588/10000 (6%)\ttrain_Loss: 0.005085\tval_Loss: 0.005343\n",
      "Train Epoch: 589/10000 (6%)\ttrain_Loss: 0.005083\tval_Loss: 0.005341\n",
      "Train Epoch: 590/10000 (6%)\ttrain_Loss: 0.005082\tval_Loss: 0.005340\n",
      "Train Epoch: 591/10000 (6%)\ttrain_Loss: 0.005080\tval_Loss: 0.005338\n",
      "Train Epoch: 592/10000 (6%)\ttrain_Loss: 0.005078\tval_Loss: 0.005337\n",
      "Train Epoch: 593/10000 (6%)\ttrain_Loss: 0.005077\tval_Loss: 0.005335\n",
      "Train Epoch: 594/10000 (6%)\ttrain_Loss: 0.005075\tval_Loss: 0.005334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 595/10000 (6%)\ttrain_Loss: 0.005073\tval_Loss: 0.005332\n",
      "Train Epoch: 596/10000 (6%)\ttrain_Loss: 0.005072\tval_Loss: 0.005330\n",
      "Train Epoch: 597/10000 (6%)\ttrain_Loss: 0.005070\tval_Loss: 0.005329\n",
      "Train Epoch: 598/10000 (6%)\ttrain_Loss: 0.005068\tval_Loss: 0.005327\n",
      "Train Epoch: 599/10000 (6%)\ttrain_Loss: 0.005067\tval_Loss: 0.005326\n",
      "Train Epoch: 600/10000 (6%)\ttrain_Loss: 0.005065\tval_Loss: 0.005325\n",
      "Train Epoch: 601/10000 (6%)\ttrain_Loss: 0.005063\tval_Loss: 0.005323\n",
      "Train Epoch: 602/10000 (6%)\ttrain_Loss: 0.005062\tval_Loss: 0.005321\n",
      "Train Epoch: 603/10000 (6%)\ttrain_Loss: 0.005060\tval_Loss: 0.005320\n",
      "Train Epoch: 604/10000 (6%)\ttrain_Loss: 0.005058\tval_Loss: 0.005318\n",
      "Train Epoch: 605/10000 (6%)\ttrain_Loss: 0.005057\tval_Loss: 0.005317\n",
      "Train Epoch: 606/10000 (6%)\ttrain_Loss: 0.005055\tval_Loss: 0.005315\n",
      "Train Epoch: 607/10000 (6%)\ttrain_Loss: 0.005053\tval_Loss: 0.005314\n",
      "Train Epoch: 608/10000 (6%)\ttrain_Loss: 0.005052\tval_Loss: 0.005312\n",
      "Train Epoch: 609/10000 (6%)\ttrain_Loss: 0.005050\tval_Loss: 0.005310\n",
      "Train Epoch: 610/10000 (6%)\ttrain_Loss: 0.005048\tval_Loss: 0.005308\n",
      "Train Epoch: 611/10000 (6%)\ttrain_Loss: 0.005047\tval_Loss: 0.005307\n",
      "Train Epoch: 612/10000 (6%)\ttrain_Loss: 0.005045\tval_Loss: 0.005306\n",
      "Train Epoch: 613/10000 (6%)\ttrain_Loss: 0.005044\tval_Loss: 0.005304\n",
      "Train Epoch: 614/10000 (6%)\ttrain_Loss: 0.005042\tval_Loss: 0.005303\n",
      "Train Epoch: 615/10000 (6%)\ttrain_Loss: 0.005040\tval_Loss: 0.005301\n",
      "Train Epoch: 616/10000 (6%)\ttrain_Loss: 0.005039\tval_Loss: 0.005300\n",
      "Train Epoch: 617/10000 (6%)\ttrain_Loss: 0.005037\tval_Loss: 0.005298\n",
      "Train Epoch: 618/10000 (6%)\ttrain_Loss: 0.005035\tval_Loss: 0.005297\n",
      "Train Epoch: 619/10000 (6%)\ttrain_Loss: 0.005034\tval_Loss: 0.005296\n",
      "Train Epoch: 620/10000 (6%)\ttrain_Loss: 0.005032\tval_Loss: 0.005295\n",
      "Train Epoch: 621/10000 (6%)\ttrain_Loss: 0.005031\tval_Loss: 0.005294\n",
      "Train Epoch: 622/10000 (6%)\ttrain_Loss: 0.005029\tval_Loss: 0.005292\n",
      "Train Epoch: 623/10000 (6%)\ttrain_Loss: 0.005027\tval_Loss: 0.005290\n",
      "Train Epoch: 624/10000 (6%)\ttrain_Loss: 0.005026\tval_Loss: 0.005289\n",
      "Train Epoch: 625/10000 (6%)\ttrain_Loss: 0.005024\tval_Loss: 0.005287\n",
      "Train Epoch: 626/10000 (6%)\ttrain_Loss: 0.005022\tval_Loss: 0.005285\n",
      "Train Epoch: 627/10000 (6%)\ttrain_Loss: 0.005021\tval_Loss: 0.005284\n",
      "Train Epoch: 628/10000 (6%)\ttrain_Loss: 0.005019\tval_Loss: 0.005282\n",
      "Train Epoch: 629/10000 (6%)\ttrain_Loss: 0.005017\tval_Loss: 0.005281\n",
      "Train Epoch: 630/10000 (6%)\ttrain_Loss: 0.005016\tval_Loss: 0.005280\n",
      "Train Epoch: 631/10000 (6%)\ttrain_Loss: 0.005014\tval_Loss: 0.005278\n",
      "Train Epoch: 632/10000 (6%)\ttrain_Loss: 0.005013\tval_Loss: 0.005277\n",
      "Train Epoch: 633/10000 (6%)\ttrain_Loss: 0.005011\tval_Loss: 0.005275\n",
      "Train Epoch: 634/10000 (6%)\ttrain_Loss: 0.005009\tval_Loss: 0.005274\n",
      "Train Epoch: 635/10000 (6%)\ttrain_Loss: 0.005008\tval_Loss: 0.005272\n",
      "Train Epoch: 636/10000 (6%)\ttrain_Loss: 0.005006\tval_Loss: 0.005270\n",
      "Train Epoch: 637/10000 (6%)\ttrain_Loss: 0.005005\tval_Loss: 0.005269\n",
      "Train Epoch: 638/10000 (6%)\ttrain_Loss: 0.005003\tval_Loss: 0.005268\n",
      "Train Epoch: 639/10000 (6%)\ttrain_Loss: 0.005001\tval_Loss: 0.005267\n",
      "Train Epoch: 640/10000 (6%)\ttrain_Loss: 0.005000\tval_Loss: 0.005265\n",
      "Train Epoch: 641/10000 (6%)\ttrain_Loss: 0.004998\tval_Loss: 0.005264\n",
      "Train Epoch: 642/10000 (6%)\ttrain_Loss: 0.004997\tval_Loss: 0.005262\n",
      "Train Epoch: 643/10000 (6%)\ttrain_Loss: 0.004995\tval_Loss: 0.005261\n",
      "Train Epoch: 644/10000 (6%)\ttrain_Loss: 0.004993\tval_Loss: 0.005259\n",
      "Train Epoch: 645/10000 (6%)\ttrain_Loss: 0.004992\tval_Loss: 0.005258\n",
      "Train Epoch: 646/10000 (6%)\ttrain_Loss: 0.004990\tval_Loss: 0.005257\n",
      "Train Epoch: 647/10000 (6%)\ttrain_Loss: 0.004989\tval_Loss: 0.005256\n",
      "Train Epoch: 648/10000 (6%)\ttrain_Loss: 0.004987\tval_Loss: 0.005254\n",
      "Train Epoch: 649/10000 (6%)\ttrain_Loss: 0.004986\tval_Loss: 0.005253\n",
      "Train Epoch: 650/10000 (6%)\ttrain_Loss: 0.004984\tval_Loss: 0.005251\n",
      "Train Epoch: 651/10000 (6%)\ttrain_Loss: 0.004982\tval_Loss: 0.005249\n",
      "Train Epoch: 652/10000 (7%)\ttrain_Loss: 0.004981\tval_Loss: 0.005248\n",
      "Train Epoch: 653/10000 (7%)\ttrain_Loss: 0.004979\tval_Loss: 0.005246\n",
      "Train Epoch: 654/10000 (7%)\ttrain_Loss: 0.004977\tval_Loss: 0.005245\n",
      "Train Epoch: 655/10000 (7%)\ttrain_Loss: 0.004976\tval_Loss: 0.005244\n",
      "Train Epoch: 656/10000 (7%)\ttrain_Loss: 0.004974\tval_Loss: 0.005242\n",
      "Train Epoch: 657/10000 (7%)\ttrain_Loss: 0.004973\tval_Loss: 0.005241\n",
      "Train Epoch: 658/10000 (7%)\ttrain_Loss: 0.004971\tval_Loss: 0.005239\n",
      "Train Epoch: 659/10000 (7%)\ttrain_Loss: 0.004970\tval_Loss: 0.005238\n",
      "Train Epoch: 660/10000 (7%)\ttrain_Loss: 0.004968\tval_Loss: 0.005236\n",
      "Train Epoch: 661/10000 (7%)\ttrain_Loss: 0.004966\tval_Loss: 0.005235\n",
      "Train Epoch: 662/10000 (7%)\ttrain_Loss: 0.004965\tval_Loss: 0.005234\n",
      "Train Epoch: 663/10000 (7%)\ttrain_Loss: 0.004963\tval_Loss: 0.005233\n",
      "Train Epoch: 664/10000 (7%)\ttrain_Loss: 0.004962\tval_Loss: 0.005232\n",
      "Train Epoch: 665/10000 (7%)\ttrain_Loss: 0.004960\tval_Loss: 0.005230\n",
      "Train Epoch: 666/10000 (7%)\ttrain_Loss: 0.004959\tval_Loss: 0.005229\n",
      "Train Epoch: 667/10000 (7%)\ttrain_Loss: 0.004957\tval_Loss: 0.005227\n",
      "Train Epoch: 668/10000 (7%)\ttrain_Loss: 0.004955\tval_Loss: 0.005226\n",
      "Train Epoch: 669/10000 (7%)\ttrain_Loss: 0.004954\tval_Loss: 0.005224\n",
      "Train Epoch: 670/10000 (7%)\ttrain_Loss: 0.004952\tval_Loss: 0.005223\n",
      "Train Epoch: 671/10000 (7%)\ttrain_Loss: 0.004951\tval_Loss: 0.005222\n",
      "Train Epoch: 672/10000 (7%)\ttrain_Loss: 0.004949\tval_Loss: 0.005221\n",
      "Train Epoch: 673/10000 (7%)\ttrain_Loss: 0.004948\tval_Loss: 0.005220\n",
      "Train Epoch: 674/10000 (7%)\ttrain_Loss: 0.004946\tval_Loss: 0.005219\n",
      "Train Epoch: 675/10000 (7%)\ttrain_Loss: 0.004944\tval_Loss: 0.005217\n",
      "Train Epoch: 676/10000 (7%)\ttrain_Loss: 0.004943\tval_Loss: 0.005216\n",
      "Train Epoch: 677/10000 (7%)\ttrain_Loss: 0.004941\tval_Loss: 0.005215\n",
      "Train Epoch: 678/10000 (7%)\ttrain_Loss: 0.004940\tval_Loss: 0.005214\n",
      "Train Epoch: 679/10000 (7%)\ttrain_Loss: 0.004938\tval_Loss: 0.005213\n",
      "Train Epoch: 680/10000 (7%)\ttrain_Loss: 0.004937\tval_Loss: 0.005212\n",
      "Train Epoch: 681/10000 (7%)\ttrain_Loss: 0.004935\tval_Loss: 0.005210\n",
      "Train Epoch: 682/10000 (7%)\ttrain_Loss: 0.004934\tval_Loss: 0.005209\n",
      "Train Epoch: 683/10000 (7%)\ttrain_Loss: 0.004932\tval_Loss: 0.005208\n",
      "Train Epoch: 684/10000 (7%)\ttrain_Loss: 0.004930\tval_Loss: 0.005207\n",
      "Train Epoch: 685/10000 (7%)\ttrain_Loss: 0.004929\tval_Loss: 0.005206\n",
      "Train Epoch: 686/10000 (7%)\ttrain_Loss: 0.004927\tval_Loss: 0.005205\n",
      "Train Epoch: 687/10000 (7%)\ttrain_Loss: 0.004926\tval_Loss: 0.005203\n",
      "Train Epoch: 688/10000 (7%)\ttrain_Loss: 0.004924\tval_Loss: 0.005202\n",
      "Train Epoch: 689/10000 (7%)\ttrain_Loss: 0.004923\tval_Loss: 0.005200\n",
      "Train Epoch: 690/10000 (7%)\ttrain_Loss: 0.004921\tval_Loss: 0.005199\n",
      "Train Epoch: 691/10000 (7%)\ttrain_Loss: 0.004920\tval_Loss: 0.005197\n",
      "Train Epoch: 692/10000 (7%)\ttrain_Loss: 0.004918\tval_Loss: 0.005196\n",
      "Train Epoch: 693/10000 (7%)\ttrain_Loss: 0.004916\tval_Loss: 0.005195\n",
      "Train Epoch: 694/10000 (7%)\ttrain_Loss: 0.004915\tval_Loss: 0.005194\n",
      "Train Epoch: 695/10000 (7%)\ttrain_Loss: 0.004913\tval_Loss: 0.005193\n",
      "Train Epoch: 696/10000 (7%)\ttrain_Loss: 0.004912\tval_Loss: 0.005191\n",
      "Train Epoch: 697/10000 (7%)\ttrain_Loss: 0.004910\tval_Loss: 0.005189\n",
      "Train Epoch: 698/10000 (7%)\ttrain_Loss: 0.004909\tval_Loss: 0.005188\n",
      "Train Epoch: 699/10000 (7%)\ttrain_Loss: 0.004907\tval_Loss: 0.005186\n",
      "Train Epoch: 700/10000 (7%)\ttrain_Loss: 0.004906\tval_Loss: 0.005184\n",
      "Train Epoch: 701/10000 (7%)\ttrain_Loss: 0.004904\tval_Loss: 0.005183\n",
      "Train Epoch: 702/10000 (7%)\ttrain_Loss: 0.004902\tval_Loss: 0.005182\n",
      "Train Epoch: 703/10000 (7%)\ttrain_Loss: 0.004901\tval_Loss: 0.005181\n",
      "Train Epoch: 704/10000 (7%)\ttrain_Loss: 0.004900\tval_Loss: 0.005179\n",
      "Train Epoch: 705/10000 (7%)\ttrain_Loss: 0.004898\tval_Loss: 0.005178\n",
      "Train Epoch: 706/10000 (7%)\ttrain_Loss: 0.004896\tval_Loss: 0.005176\n",
      "Train Epoch: 707/10000 (7%)\ttrain_Loss: 0.004895\tval_Loss: 0.005174\n",
      "Train Epoch: 708/10000 (7%)\ttrain_Loss: 0.004893\tval_Loss: 0.005173\n",
      "Train Epoch: 709/10000 (7%)\ttrain_Loss: 0.004892\tval_Loss: 0.005171\n",
      "Train Epoch: 710/10000 (7%)\ttrain_Loss: 0.004890\tval_Loss: 0.005170\n",
      "Train Epoch: 711/10000 (7%)\ttrain_Loss: 0.004889\tval_Loss: 0.005169\n",
      "Train Epoch: 712/10000 (7%)\ttrain_Loss: 0.004887\tval_Loss: 0.005167\n",
      "Train Epoch: 713/10000 (7%)\ttrain_Loss: 0.004886\tval_Loss: 0.005165\n",
      "Train Epoch: 714/10000 (7%)\ttrain_Loss: 0.004884\tval_Loss: 0.005164\n",
      "Train Epoch: 715/10000 (7%)\ttrain_Loss: 0.004883\tval_Loss: 0.005163\n",
      "Train Epoch: 716/10000 (7%)\ttrain_Loss: 0.004881\tval_Loss: 0.005162\n",
      "Train Epoch: 717/10000 (7%)\ttrain_Loss: 0.004880\tval_Loss: 0.005161\n",
      "Train Epoch: 718/10000 (7%)\ttrain_Loss: 0.004878\tval_Loss: 0.005160\n",
      "Train Epoch: 719/10000 (7%)\ttrain_Loss: 0.004877\tval_Loss: 0.005159\n",
      "Train Epoch: 720/10000 (7%)\ttrain_Loss: 0.004875\tval_Loss: 0.005157\n",
      "Train Epoch: 721/10000 (7%)\ttrain_Loss: 0.004874\tval_Loss: 0.005156\n",
      "Train Epoch: 722/10000 (7%)\ttrain_Loss: 0.004872\tval_Loss: 0.005154\n",
      "Train Epoch: 723/10000 (7%)\ttrain_Loss: 0.004871\tval_Loss: 0.005153\n",
      "Train Epoch: 724/10000 (7%)\ttrain_Loss: 0.004869\tval_Loss: 0.005152\n",
      "Train Epoch: 725/10000 (7%)\ttrain_Loss: 0.004868\tval_Loss: 0.005151\n",
      "Train Epoch: 726/10000 (7%)\ttrain_Loss: 0.004866\tval_Loss: 0.005150\n",
      "Train Epoch: 727/10000 (7%)\ttrain_Loss: 0.004865\tval_Loss: 0.005148\n",
      "Train Epoch: 728/10000 (7%)\ttrain_Loss: 0.004864\tval_Loss: 0.005147\n",
      "Train Epoch: 729/10000 (7%)\ttrain_Loss: 0.004862\tval_Loss: 0.005146\n",
      "Train Epoch: 730/10000 (7%)\ttrain_Loss: 0.004861\tval_Loss: 0.005144\n",
      "Train Epoch: 731/10000 (7%)\ttrain_Loss: 0.004859\tval_Loss: 0.005143\n",
      "Train Epoch: 732/10000 (7%)\ttrain_Loss: 0.004858\tval_Loss: 0.005142\n",
      "Train Epoch: 733/10000 (7%)\ttrain_Loss: 0.004856\tval_Loss: 0.005141\n",
      "Train Epoch: 734/10000 (7%)\ttrain_Loss: 0.004855\tval_Loss: 0.005140\n",
      "Train Epoch: 735/10000 (7%)\ttrain_Loss: 0.004853\tval_Loss: 0.005139\n",
      "Train Epoch: 736/10000 (7%)\ttrain_Loss: 0.004852\tval_Loss: 0.005138\n",
      "Train Epoch: 737/10000 (7%)\ttrain_Loss: 0.004851\tval_Loss: 0.005137\n",
      "Train Epoch: 738/10000 (7%)\ttrain_Loss: 0.004849\tval_Loss: 0.005135\n",
      "Train Epoch: 739/10000 (7%)\ttrain_Loss: 0.004848\tval_Loss: 0.005134\n",
      "Train Epoch: 740/10000 (7%)\ttrain_Loss: 0.004846\tval_Loss: 0.005132\n",
      "Train Epoch: 741/10000 (7%)\ttrain_Loss: 0.004845\tval_Loss: 0.005131\n",
      "Train Epoch: 742/10000 (7%)\ttrain_Loss: 0.004844\tval_Loss: 0.005130\n",
      "Train Epoch: 743/10000 (7%)\ttrain_Loss: 0.004842\tval_Loss: 0.005128\n",
      "Train Epoch: 744/10000 (7%)\ttrain_Loss: 0.004841\tval_Loss: 0.005127\n",
      "Train Epoch: 745/10000 (7%)\ttrain_Loss: 0.004839\tval_Loss: 0.005126\n",
      "Train Epoch: 746/10000 (7%)\ttrain_Loss: 0.004838\tval_Loss: 0.005125\n",
      "Train Epoch: 747/10000 (7%)\ttrain_Loss: 0.004836\tval_Loss: 0.005124\n",
      "Train Epoch: 748/10000 (7%)\ttrain_Loss: 0.004835\tval_Loss: 0.005122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 749/10000 (7%)\ttrain_Loss: 0.004833\tval_Loss: 0.005121\n",
      "Train Epoch: 750/10000 (7%)\ttrain_Loss: 0.004832\tval_Loss: 0.005120\n",
      "Train Epoch: 751/10000 (8%)\ttrain_Loss: 0.004831\tval_Loss: 0.005119\n",
      "Train Epoch: 752/10000 (8%)\ttrain_Loss: 0.004829\tval_Loss: 0.005118\n",
      "Train Epoch: 753/10000 (8%)\ttrain_Loss: 0.004828\tval_Loss: 0.005117\n",
      "Train Epoch: 754/10000 (8%)\ttrain_Loss: 0.004826\tval_Loss: 0.005116\n",
      "Train Epoch: 755/10000 (8%)\ttrain_Loss: 0.004825\tval_Loss: 0.005114\n",
      "Train Epoch: 756/10000 (8%)\ttrain_Loss: 0.004824\tval_Loss: 0.005113\n",
      "Train Epoch: 757/10000 (8%)\ttrain_Loss: 0.004822\tval_Loss: 0.005112\n",
      "Train Epoch: 758/10000 (8%)\ttrain_Loss: 0.004821\tval_Loss: 0.005111\n",
      "Train Epoch: 759/10000 (8%)\ttrain_Loss: 0.004819\tval_Loss: 0.005110\n",
      "Train Epoch: 760/10000 (8%)\ttrain_Loss: 0.004818\tval_Loss: 0.005109\n",
      "Train Epoch: 761/10000 (8%)\ttrain_Loss: 0.004817\tval_Loss: 0.005107\n",
      "Train Epoch: 762/10000 (8%)\ttrain_Loss: 0.004815\tval_Loss: 0.005106\n",
      "Train Epoch: 763/10000 (8%)\ttrain_Loss: 0.004814\tval_Loss: 0.005105\n",
      "Train Epoch: 764/10000 (8%)\ttrain_Loss: 0.004812\tval_Loss: 0.005104\n",
      "Train Epoch: 765/10000 (8%)\ttrain_Loss: 0.004811\tval_Loss: 0.005103\n",
      "Train Epoch: 766/10000 (8%)\ttrain_Loss: 0.004810\tval_Loss: 0.005102\n",
      "Train Epoch: 767/10000 (8%)\ttrain_Loss: 0.004808\tval_Loss: 0.005101\n",
      "Train Epoch: 768/10000 (8%)\ttrain_Loss: 0.004807\tval_Loss: 0.005100\n",
      "Train Epoch: 769/10000 (8%)\ttrain_Loss: 0.004805\tval_Loss: 0.005099\n",
      "Train Epoch: 770/10000 (8%)\ttrain_Loss: 0.004804\tval_Loss: 0.005098\n",
      "Train Epoch: 771/10000 (8%)\ttrain_Loss: 0.004803\tval_Loss: 0.005097\n",
      "Train Epoch: 772/10000 (8%)\ttrain_Loss: 0.004801\tval_Loss: 0.005097\n",
      "Train Epoch: 773/10000 (8%)\ttrain_Loss: 0.004800\tval_Loss: 0.005096\n",
      "Train Epoch: 774/10000 (8%)\ttrain_Loss: 0.004798\tval_Loss: 0.005094\n",
      "Train Epoch: 775/10000 (8%)\ttrain_Loss: 0.004797\tval_Loss: 0.005093\n",
      "Train Epoch: 776/10000 (8%)\ttrain_Loss: 0.004795\tval_Loss: 0.005091\n",
      "Train Epoch: 777/10000 (8%)\ttrain_Loss: 0.004794\tval_Loss: 0.005090\n",
      "Train Epoch: 778/10000 (8%)\ttrain_Loss: 0.004793\tval_Loss: 0.005089\n",
      "Train Epoch: 779/10000 (8%)\ttrain_Loss: 0.004791\tval_Loss: 0.005088\n",
      "Train Epoch: 780/10000 (8%)\ttrain_Loss: 0.004790\tval_Loss: 0.005087\n",
      "Train Epoch: 781/10000 (8%)\ttrain_Loss: 0.004788\tval_Loss: 0.005086\n",
      "Train Epoch: 782/10000 (8%)\ttrain_Loss: 0.004787\tval_Loss: 0.005085\n",
      "Train Epoch: 783/10000 (8%)\ttrain_Loss: 0.004786\tval_Loss: 0.005084\n",
      "Train Epoch: 784/10000 (8%)\ttrain_Loss: 0.004784\tval_Loss: 0.005082\n",
      "Train Epoch: 785/10000 (8%)\ttrain_Loss: 0.004783\tval_Loss: 0.005080\n",
      "Train Epoch: 786/10000 (8%)\ttrain_Loss: 0.004781\tval_Loss: 0.005079\n",
      "Train Epoch: 787/10000 (8%)\ttrain_Loss: 0.004780\tval_Loss: 0.005077\n",
      "Train Epoch: 788/10000 (8%)\ttrain_Loss: 0.004779\tval_Loss: 0.005076\n",
      "Train Epoch: 789/10000 (8%)\ttrain_Loss: 0.004777\tval_Loss: 0.005075\n",
      "Train Epoch: 790/10000 (8%)\ttrain_Loss: 0.004776\tval_Loss: 0.005074\n",
      "Train Epoch: 791/10000 (8%)\ttrain_Loss: 0.004775\tval_Loss: 0.005073\n",
      "Train Epoch: 792/10000 (8%)\ttrain_Loss: 0.004773\tval_Loss: 0.005071\n",
      "Train Epoch: 793/10000 (8%)\ttrain_Loss: 0.004772\tval_Loss: 0.005069\n",
      "Train Epoch: 794/10000 (8%)\ttrain_Loss: 0.004770\tval_Loss: 0.005068\n",
      "Train Epoch: 795/10000 (8%)\ttrain_Loss: 0.004769\tval_Loss: 0.005066\n",
      "Train Epoch: 796/10000 (8%)\ttrain_Loss: 0.004768\tval_Loss: 0.005066\n",
      "Train Epoch: 797/10000 (8%)\ttrain_Loss: 0.004766\tval_Loss: 0.005065\n",
      "Train Epoch: 798/10000 (8%)\ttrain_Loss: 0.004765\tval_Loss: 0.005064\n",
      "Train Epoch: 799/10000 (8%)\ttrain_Loss: 0.004763\tval_Loss: 0.005063\n",
      "Train Epoch: 800/10000 (8%)\ttrain_Loss: 0.004762\tval_Loss: 0.005062\n",
      "Train Epoch: 801/10000 (8%)\ttrain_Loss: 0.004761\tval_Loss: 0.005060\n",
      "Train Epoch: 802/10000 (8%)\ttrain_Loss: 0.004759\tval_Loss: 0.005059\n",
      "Train Epoch: 803/10000 (8%)\ttrain_Loss: 0.004758\tval_Loss: 0.005058\n",
      "Train Epoch: 804/10000 (8%)\ttrain_Loss: 0.004757\tval_Loss: 0.005058\n",
      "Train Epoch: 805/10000 (8%)\ttrain_Loss: 0.004755\tval_Loss: 0.005057\n",
      "Train Epoch: 806/10000 (8%)\ttrain_Loss: 0.004754\tval_Loss: 0.005057\n",
      "Train Epoch: 807/10000 (8%)\ttrain_Loss: 0.004753\tval_Loss: 0.005055\n",
      "Train Epoch: 808/10000 (8%)\ttrain_Loss: 0.004751\tval_Loss: 0.005054\n",
      "Train Epoch: 809/10000 (8%)\ttrain_Loss: 0.004750\tval_Loss: 0.005053\n",
      "Train Epoch: 810/10000 (8%)\ttrain_Loss: 0.004748\tval_Loss: 0.005052\n",
      "Train Epoch: 811/10000 (8%)\ttrain_Loss: 0.004747\tval_Loss: 0.005051\n",
      "Train Epoch: 812/10000 (8%)\ttrain_Loss: 0.004746\tval_Loss: 0.005051\n",
      "Train Epoch: 813/10000 (8%)\ttrain_Loss: 0.004744\tval_Loss: 0.005050\n",
      "Train Epoch: 814/10000 (8%)\ttrain_Loss: 0.004743\tval_Loss: 0.005049\n",
      "Train Epoch: 815/10000 (8%)\ttrain_Loss: 0.004741\tval_Loss: 0.005048\n",
      "Train Epoch: 816/10000 (8%)\ttrain_Loss: 0.004740\tval_Loss: 0.005048\n",
      "Train Epoch: 817/10000 (8%)\ttrain_Loss: 0.004739\tval_Loss: 0.005047\n",
      "Train Epoch: 818/10000 (8%)\ttrain_Loss: 0.004737\tval_Loss: 0.005046\n",
      "Train Epoch: 819/10000 (8%)\ttrain_Loss: 0.004736\tval_Loss: 0.005044\n",
      "Train Epoch: 820/10000 (8%)\ttrain_Loss: 0.004735\tval_Loss: 0.005043\n",
      "Train Epoch: 821/10000 (8%)\ttrain_Loss: 0.004733\tval_Loss: 0.005042\n",
      "Train Epoch: 822/10000 (8%)\ttrain_Loss: 0.004732\tval_Loss: 0.005041\n",
      "Train Epoch: 823/10000 (8%)\ttrain_Loss: 0.004731\tval_Loss: 0.005040\n",
      "Train Epoch: 824/10000 (8%)\ttrain_Loss: 0.004729\tval_Loss: 0.005038\n",
      "Train Epoch: 825/10000 (8%)\ttrain_Loss: 0.004728\tval_Loss: 0.005037\n",
      "Train Epoch: 826/10000 (8%)\ttrain_Loss: 0.004727\tval_Loss: 0.005036\n",
      "Train Epoch: 827/10000 (8%)\ttrain_Loss: 0.004725\tval_Loss: 0.005034\n",
      "Train Epoch: 828/10000 (8%)\ttrain_Loss: 0.004724\tval_Loss: 0.005033\n",
      "Train Epoch: 829/10000 (8%)\ttrain_Loss: 0.004723\tval_Loss: 0.005032\n",
      "Train Epoch: 830/10000 (8%)\ttrain_Loss: 0.004721\tval_Loss: 0.005031\n",
      "Train Epoch: 831/10000 (8%)\ttrain_Loss: 0.004720\tval_Loss: 0.005029\n",
      "Train Epoch: 832/10000 (8%)\ttrain_Loss: 0.004719\tval_Loss: 0.005028\n",
      "Train Epoch: 833/10000 (8%)\ttrain_Loss: 0.004717\tval_Loss: 0.005027\n",
      "Train Epoch: 834/10000 (8%)\ttrain_Loss: 0.004716\tval_Loss: 0.005026\n",
      "Train Epoch: 835/10000 (8%)\ttrain_Loss: 0.004715\tval_Loss: 0.005024\n",
      "Train Epoch: 836/10000 (8%)\ttrain_Loss: 0.004713\tval_Loss: 0.005023\n",
      "Train Epoch: 837/10000 (8%)\ttrain_Loss: 0.004712\tval_Loss: 0.005022\n",
      "Train Epoch: 838/10000 (8%)\ttrain_Loss: 0.004711\tval_Loss: 0.005021\n",
      "Train Epoch: 839/10000 (8%)\ttrain_Loss: 0.004710\tval_Loss: 0.005020\n",
      "Train Epoch: 840/10000 (8%)\ttrain_Loss: 0.004708\tval_Loss: 0.005019\n",
      "Train Epoch: 841/10000 (8%)\ttrain_Loss: 0.004707\tval_Loss: 0.005017\n",
      "Train Epoch: 842/10000 (8%)\ttrain_Loss: 0.004706\tval_Loss: 0.005016\n",
      "Train Epoch: 843/10000 (8%)\ttrain_Loss: 0.004705\tval_Loss: 0.005015\n",
      "Train Epoch: 844/10000 (8%)\ttrain_Loss: 0.004703\tval_Loss: 0.005014\n",
      "Train Epoch: 845/10000 (8%)\ttrain_Loss: 0.004702\tval_Loss: 0.005013\n",
      "Train Epoch: 846/10000 (8%)\ttrain_Loss: 0.004701\tval_Loss: 0.005011\n",
      "Train Epoch: 847/10000 (8%)\ttrain_Loss: 0.004700\tval_Loss: 0.005010\n",
      "Train Epoch: 848/10000 (8%)\ttrain_Loss: 0.004698\tval_Loss: 0.005009\n",
      "Train Epoch: 849/10000 (8%)\ttrain_Loss: 0.004697\tval_Loss: 0.005008\n",
      "Train Epoch: 850/10000 (8%)\ttrain_Loss: 0.004696\tval_Loss: 0.005007\n",
      "Train Epoch: 851/10000 (8%)\ttrain_Loss: 0.004695\tval_Loss: 0.005006\n",
      "Train Epoch: 852/10000 (9%)\ttrain_Loss: 0.004693\tval_Loss: 0.005005\n",
      "Train Epoch: 853/10000 (9%)\ttrain_Loss: 0.004692\tval_Loss: 0.005004\n",
      "Train Epoch: 854/10000 (9%)\ttrain_Loss: 0.004691\tval_Loss: 0.005003\n",
      "Train Epoch: 855/10000 (9%)\ttrain_Loss: 0.004690\tval_Loss: 0.005002\n",
      "Train Epoch: 856/10000 (9%)\ttrain_Loss: 0.004688\tval_Loss: 0.005001\n",
      "Train Epoch: 857/10000 (9%)\ttrain_Loss: 0.004687\tval_Loss: 0.005000\n",
      "Train Epoch: 858/10000 (9%)\ttrain_Loss: 0.004686\tval_Loss: 0.004999\n",
      "Train Epoch: 859/10000 (9%)\ttrain_Loss: 0.004685\tval_Loss: 0.004998\n",
      "Train Epoch: 860/10000 (9%)\ttrain_Loss: 0.004684\tval_Loss: 0.004997\n",
      "Train Epoch: 861/10000 (9%)\ttrain_Loss: 0.004682\tval_Loss: 0.004996\n",
      "Train Epoch: 862/10000 (9%)\ttrain_Loss: 0.004681\tval_Loss: 0.004995\n",
      "Train Epoch: 863/10000 (9%)\ttrain_Loss: 0.004680\tval_Loss: 0.004993\n",
      "Train Epoch: 864/10000 (9%)\ttrain_Loss: 0.004679\tval_Loss: 0.004992\n",
      "Train Epoch: 865/10000 (9%)\ttrain_Loss: 0.004678\tval_Loss: 0.004992\n",
      "Train Epoch: 866/10000 (9%)\ttrain_Loss: 0.004676\tval_Loss: 0.004991\n",
      "Train Epoch: 867/10000 (9%)\ttrain_Loss: 0.004675\tval_Loss: 0.004990\n",
      "Train Epoch: 868/10000 (9%)\ttrain_Loss: 0.004674\tval_Loss: 0.004989\n",
      "Train Epoch: 869/10000 (9%)\ttrain_Loss: 0.004673\tval_Loss: 0.004987\n",
      "Train Epoch: 870/10000 (9%)\ttrain_Loss: 0.004672\tval_Loss: 0.004986\n",
      "Train Epoch: 871/10000 (9%)\ttrain_Loss: 0.004670\tval_Loss: 0.004985\n",
      "Train Epoch: 872/10000 (9%)\ttrain_Loss: 0.004669\tval_Loss: 0.004984\n",
      "Train Epoch: 873/10000 (9%)\ttrain_Loss: 0.004668\tval_Loss: 0.004983\n",
      "Train Epoch: 874/10000 (9%)\ttrain_Loss: 0.004667\tval_Loss: 0.004982\n",
      "Train Epoch: 875/10000 (9%)\ttrain_Loss: 0.004666\tval_Loss: 0.004981\n",
      "Train Epoch: 876/10000 (9%)\ttrain_Loss: 0.004665\tval_Loss: 0.004980\n",
      "Train Epoch: 877/10000 (9%)\ttrain_Loss: 0.004663\tval_Loss: 0.004979\n",
      "Train Epoch: 878/10000 (9%)\ttrain_Loss: 0.004662\tval_Loss: 0.004977\n",
      "Train Epoch: 879/10000 (9%)\ttrain_Loss: 0.004661\tval_Loss: 0.004976\n",
      "Train Epoch: 880/10000 (9%)\ttrain_Loss: 0.004660\tval_Loss: 0.004975\n",
      "Train Epoch: 881/10000 (9%)\ttrain_Loss: 0.004659\tval_Loss: 0.004974\n",
      "Train Epoch: 882/10000 (9%)\ttrain_Loss: 0.004658\tval_Loss: 0.004974\n",
      "Train Epoch: 883/10000 (9%)\ttrain_Loss: 0.004657\tval_Loss: 0.004972\n",
      "Train Epoch: 884/10000 (9%)\ttrain_Loss: 0.004656\tval_Loss: 0.004972\n",
      "Train Epoch: 885/10000 (9%)\ttrain_Loss: 0.004654\tval_Loss: 0.004971\n",
      "Train Epoch: 886/10000 (9%)\ttrain_Loss: 0.004653\tval_Loss: 0.004970\n",
      "Train Epoch: 887/10000 (9%)\ttrain_Loss: 0.004652\tval_Loss: 0.004969\n",
      "Train Epoch: 888/10000 (9%)\ttrain_Loss: 0.004651\tval_Loss: 0.004968\n",
      "Train Epoch: 889/10000 (9%)\ttrain_Loss: 0.004650\tval_Loss: 0.004967\n",
      "Train Epoch: 890/10000 (9%)\ttrain_Loss: 0.004649\tval_Loss: 0.004966\n",
      "Train Epoch: 891/10000 (9%)\ttrain_Loss: 0.004648\tval_Loss: 0.004965\n",
      "Train Epoch: 892/10000 (9%)\ttrain_Loss: 0.004647\tval_Loss: 0.004964\n",
      "Train Epoch: 893/10000 (9%)\ttrain_Loss: 0.004646\tval_Loss: 0.004963\n",
      "Train Epoch: 894/10000 (9%)\ttrain_Loss: 0.004644\tval_Loss: 0.004962\n",
      "Train Epoch: 895/10000 (9%)\ttrain_Loss: 0.004643\tval_Loss: 0.004961\n",
      "Train Epoch: 896/10000 (9%)\ttrain_Loss: 0.004642\tval_Loss: 0.004960\n",
      "Train Epoch: 897/10000 (9%)\ttrain_Loss: 0.004641\tval_Loss: 0.004959\n",
      "Train Epoch: 898/10000 (9%)\ttrain_Loss: 0.004640\tval_Loss: 0.004958\n",
      "Train Epoch: 899/10000 (9%)\ttrain_Loss: 0.004639\tval_Loss: 0.004958\n",
      "Train Epoch: 900/10000 (9%)\ttrain_Loss: 0.004638\tval_Loss: 0.004957\n",
      "Train Epoch: 901/10000 (9%)\ttrain_Loss: 0.004637\tval_Loss: 0.004956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 902/10000 (9%)\ttrain_Loss: 0.004636\tval_Loss: 0.004955\n",
      "Train Epoch: 903/10000 (9%)\ttrain_Loss: 0.004635\tval_Loss: 0.004954\n",
      "Train Epoch: 904/10000 (9%)\ttrain_Loss: 0.004634\tval_Loss: 0.004953\n",
      "Train Epoch: 905/10000 (9%)\ttrain_Loss: 0.004633\tval_Loss: 0.004952\n",
      "Train Epoch: 906/10000 (9%)\ttrain_Loss: 0.004632\tval_Loss: 0.004951\n",
      "Train Epoch: 907/10000 (9%)\ttrain_Loss: 0.004631\tval_Loss: 0.004950\n",
      "Train Epoch: 908/10000 (9%)\ttrain_Loss: 0.004630\tval_Loss: 0.004949\n",
      "Train Epoch: 909/10000 (9%)\ttrain_Loss: 0.004629\tval_Loss: 0.004948\n",
      "Train Epoch: 910/10000 (9%)\ttrain_Loss: 0.004627\tval_Loss: 0.004947\n",
      "Train Epoch: 911/10000 (9%)\ttrain_Loss: 0.004626\tval_Loss: 0.004946\n",
      "Train Epoch: 912/10000 (9%)\ttrain_Loss: 0.004625\tval_Loss: 0.004945\n",
      "Train Epoch: 913/10000 (9%)\ttrain_Loss: 0.004624\tval_Loss: 0.004945\n",
      "Train Epoch: 914/10000 (9%)\ttrain_Loss: 0.004623\tval_Loss: 0.004944\n",
      "Train Epoch: 915/10000 (9%)\ttrain_Loss: 0.004622\tval_Loss: 0.004943\n",
      "Train Epoch: 916/10000 (9%)\ttrain_Loss: 0.004621\tval_Loss: 0.004942\n",
      "Train Epoch: 917/10000 (9%)\ttrain_Loss: 0.004620\tval_Loss: 0.004941\n",
      "Train Epoch: 918/10000 (9%)\ttrain_Loss: 0.004619\tval_Loss: 0.004940\n",
      "Train Epoch: 919/10000 (9%)\ttrain_Loss: 0.004618\tval_Loss: 0.004939\n",
      "Train Epoch: 920/10000 (9%)\ttrain_Loss: 0.004617\tval_Loss: 0.004938\n",
      "Train Epoch: 921/10000 (9%)\ttrain_Loss: 0.004616\tval_Loss: 0.004937\n",
      "Train Epoch: 922/10000 (9%)\ttrain_Loss: 0.004615\tval_Loss: 0.004937\n",
      "Train Epoch: 923/10000 (9%)\ttrain_Loss: 0.004614\tval_Loss: 0.004936\n",
      "Train Epoch: 924/10000 (9%)\ttrain_Loss: 0.004613\tval_Loss: 0.004934\n",
      "Train Epoch: 925/10000 (9%)\ttrain_Loss: 0.004612\tval_Loss: 0.004934\n",
      "Train Epoch: 926/10000 (9%)\ttrain_Loss: 0.004611\tval_Loss: 0.004933\n",
      "Train Epoch: 927/10000 (9%)\ttrain_Loss: 0.004610\tval_Loss: 0.004932\n",
      "Train Epoch: 928/10000 (9%)\ttrain_Loss: 0.004609\tval_Loss: 0.004931\n",
      "Train Epoch: 929/10000 (9%)\ttrain_Loss: 0.004608\tval_Loss: 0.004930\n",
      "Train Epoch: 930/10000 (9%)\ttrain_Loss: 0.004607\tval_Loss: 0.004929\n",
      "Train Epoch: 931/10000 (9%)\ttrain_Loss: 0.004606\tval_Loss: 0.004929\n",
      "Train Epoch: 932/10000 (9%)\ttrain_Loss: 0.004605\tval_Loss: 0.004928\n",
      "Train Epoch: 933/10000 (9%)\ttrain_Loss: 0.004605\tval_Loss: 0.004927\n",
      "Train Epoch: 934/10000 (9%)\ttrain_Loss: 0.004604\tval_Loss: 0.004926\n",
      "Train Epoch: 935/10000 (9%)\ttrain_Loss: 0.004603\tval_Loss: 0.004925\n",
      "Train Epoch: 936/10000 (9%)\ttrain_Loss: 0.004602\tval_Loss: 0.004924\n",
      "Train Epoch: 937/10000 (9%)\ttrain_Loss: 0.004601\tval_Loss: 0.004923\n",
      "Train Epoch: 938/10000 (9%)\ttrain_Loss: 0.004600\tval_Loss: 0.004922\n",
      "Train Epoch: 939/10000 (9%)\ttrain_Loss: 0.004599\tval_Loss: 0.004921\n",
      "Train Epoch: 940/10000 (9%)\ttrain_Loss: 0.004598\tval_Loss: 0.004921\n",
      "Train Epoch: 941/10000 (9%)\ttrain_Loss: 0.004597\tval_Loss: 0.004920\n",
      "Train Epoch: 942/10000 (9%)\ttrain_Loss: 0.004596\tval_Loss: 0.004919\n",
      "Train Epoch: 943/10000 (9%)\ttrain_Loss: 0.004595\tval_Loss: 0.004919\n",
      "Train Epoch: 944/10000 (9%)\ttrain_Loss: 0.004594\tval_Loss: 0.004918\n",
      "Train Epoch: 945/10000 (9%)\ttrain_Loss: 0.004593\tval_Loss: 0.004917\n",
      "Train Epoch: 946/10000 (9%)\ttrain_Loss: 0.004592\tval_Loss: 0.004916\n",
      "Train Epoch: 947/10000 (9%)\ttrain_Loss: 0.004591\tval_Loss: 0.004915\n",
      "Train Epoch: 948/10000 (9%)\ttrain_Loss: 0.004590\tval_Loss: 0.004914\n",
      "Train Epoch: 949/10000 (9%)\ttrain_Loss: 0.004589\tval_Loss: 0.004913\n",
      "Train Epoch: 950/10000 (9%)\ttrain_Loss: 0.004588\tval_Loss: 0.004913\n",
      "Train Epoch: 951/10000 (10%)\ttrain_Loss: 0.004588\tval_Loss: 0.004912\n",
      "Train Epoch: 952/10000 (10%)\ttrain_Loss: 0.004587\tval_Loss: 0.004911\n",
      "Train Epoch: 953/10000 (10%)\ttrain_Loss: 0.004586\tval_Loss: 0.004910\n",
      "Train Epoch: 954/10000 (10%)\ttrain_Loss: 0.004585\tval_Loss: 0.004909\n",
      "Train Epoch: 955/10000 (10%)\ttrain_Loss: 0.004584\tval_Loss: 0.004908\n",
      "Train Epoch: 956/10000 (10%)\ttrain_Loss: 0.004583\tval_Loss: 0.004907\n",
      "Train Epoch: 957/10000 (10%)\ttrain_Loss: 0.004582\tval_Loss: 0.004907\n",
      "Train Epoch: 958/10000 (10%)\ttrain_Loss: 0.004581\tval_Loss: 0.004906\n",
      "Train Epoch: 959/10000 (10%)\ttrain_Loss: 0.004580\tval_Loss: 0.004905\n",
      "Train Epoch: 960/10000 (10%)\ttrain_Loss: 0.004580\tval_Loss: 0.004904\n",
      "Train Epoch: 961/10000 (10%)\ttrain_Loss: 0.004579\tval_Loss: 0.004903\n",
      "Train Epoch: 962/10000 (10%)\ttrain_Loss: 0.004578\tval_Loss: 0.004902\n",
      "Train Epoch: 963/10000 (10%)\ttrain_Loss: 0.004577\tval_Loss: 0.004901\n",
      "Train Epoch: 964/10000 (10%)\ttrain_Loss: 0.004576\tval_Loss: 0.004900\n",
      "Train Epoch: 965/10000 (10%)\ttrain_Loss: 0.004575\tval_Loss: 0.004899\n",
      "Train Epoch: 966/10000 (10%)\ttrain_Loss: 0.004574\tval_Loss: 0.004899\n",
      "Train Epoch: 967/10000 (10%)\ttrain_Loss: 0.004573\tval_Loss: 0.004898\n",
      "Train Epoch: 968/10000 (10%)\ttrain_Loss: 0.004573\tval_Loss: 0.004897\n",
      "Train Epoch: 969/10000 (10%)\ttrain_Loss: 0.004572\tval_Loss: 0.004897\n",
      "Train Epoch: 970/10000 (10%)\ttrain_Loss: 0.004571\tval_Loss: 0.004896\n",
      "Train Epoch: 971/10000 (10%)\ttrain_Loss: 0.004570\tval_Loss: 0.004895\n",
      "Train Epoch: 972/10000 (10%)\ttrain_Loss: 0.004569\tval_Loss: 0.004894\n",
      "Train Epoch: 973/10000 (10%)\ttrain_Loss: 0.004568\tval_Loss: 0.004893\n",
      "Train Epoch: 974/10000 (10%)\ttrain_Loss: 0.004567\tval_Loss: 0.004892\n",
      "Train Epoch: 975/10000 (10%)\ttrain_Loss: 0.004567\tval_Loss: 0.004891\n",
      "Train Epoch: 976/10000 (10%)\ttrain_Loss: 0.004566\tval_Loss: 0.004890\n",
      "Train Epoch: 977/10000 (10%)\ttrain_Loss: 0.004565\tval_Loss: 0.004890\n",
      "Train Epoch: 978/10000 (10%)\ttrain_Loss: 0.004564\tval_Loss: 0.004889\n",
      "Train Epoch: 979/10000 (10%)\ttrain_Loss: 0.004563\tval_Loss: 0.004888\n",
      "Train Epoch: 980/10000 (10%)\ttrain_Loss: 0.004562\tval_Loss: 0.004887\n",
      "Train Epoch: 981/10000 (10%)\ttrain_Loss: 0.004561\tval_Loss: 0.004886\n",
      "Train Epoch: 982/10000 (10%)\ttrain_Loss: 0.004561\tval_Loss: 0.004885\n",
      "Train Epoch: 983/10000 (10%)\ttrain_Loss: 0.004560\tval_Loss: 0.004885\n",
      "Train Epoch: 984/10000 (10%)\ttrain_Loss: 0.004559\tval_Loss: 0.004883\n",
      "Train Epoch: 985/10000 (10%)\ttrain_Loss: 0.004558\tval_Loss: 0.004883\n",
      "Train Epoch: 986/10000 (10%)\ttrain_Loss: 0.004557\tval_Loss: 0.004882\n",
      "Train Epoch: 987/10000 (10%)\ttrain_Loss: 0.004557\tval_Loss: 0.004881\n",
      "Train Epoch: 988/10000 (10%)\ttrain_Loss: 0.004556\tval_Loss: 0.004880\n",
      "Train Epoch: 989/10000 (10%)\ttrain_Loss: 0.004555\tval_Loss: 0.004879\n",
      "Train Epoch: 990/10000 (10%)\ttrain_Loss: 0.004554\tval_Loss: 0.004878\n",
      "Train Epoch: 991/10000 (10%)\ttrain_Loss: 0.004553\tval_Loss: 0.004878\n",
      "Train Epoch: 992/10000 (10%)\ttrain_Loss: 0.004552\tval_Loss: 0.004877\n",
      "Train Epoch: 993/10000 (10%)\ttrain_Loss: 0.004552\tval_Loss: 0.004876\n",
      "Train Epoch: 994/10000 (10%)\ttrain_Loss: 0.004551\tval_Loss: 0.004875\n",
      "Train Epoch: 995/10000 (10%)\ttrain_Loss: 0.004550\tval_Loss: 0.004874\n",
      "Train Epoch: 996/10000 (10%)\ttrain_Loss: 0.004549\tval_Loss: 0.004873\n",
      "Train Epoch: 997/10000 (10%)\ttrain_Loss: 0.004548\tval_Loss: 0.004872\n",
      "Train Epoch: 998/10000 (10%)\ttrain_Loss: 0.004548\tval_Loss: 0.004871\n",
      "Train Epoch: 999/10000 (10%)\ttrain_Loss: 0.004547\tval_Loss: 0.004870\n",
      "Train Epoch: 1000/10000 (10%)\ttrain_Loss: 0.004546\tval_Loss: 0.004869\n",
      "Train Epoch: 1001/10000 (10%)\ttrain_Loss: 0.004545\tval_Loss: 0.004868\n",
      "Train Epoch: 1002/10000 (10%)\ttrain_Loss: 0.004545\tval_Loss: 0.004867\n",
      "Train Epoch: 1003/10000 (10%)\ttrain_Loss: 0.004544\tval_Loss: 0.004866\n",
      "Train Epoch: 1004/10000 (10%)\ttrain_Loss: 0.004543\tval_Loss: 0.004865\n",
      "Train Epoch: 1005/10000 (10%)\ttrain_Loss: 0.004542\tval_Loss: 0.004864\n",
      "Train Epoch: 1006/10000 (10%)\ttrain_Loss: 0.004541\tval_Loss: 0.004863\n",
      "Train Epoch: 1007/10000 (10%)\ttrain_Loss: 0.004541\tval_Loss: 0.004862\n",
      "Train Epoch: 1008/10000 (10%)\ttrain_Loss: 0.004540\tval_Loss: 0.004861\n",
      "Train Epoch: 1009/10000 (10%)\ttrain_Loss: 0.004539\tval_Loss: 0.004860\n",
      "Train Epoch: 1010/10000 (10%)\ttrain_Loss: 0.004538\tval_Loss: 0.004859\n",
      "Train Epoch: 1011/10000 (10%)\ttrain_Loss: 0.004537\tval_Loss: 0.004858\n",
      "Train Epoch: 1012/10000 (10%)\ttrain_Loss: 0.004537\tval_Loss: 0.004857\n",
      "Train Epoch: 1013/10000 (10%)\ttrain_Loss: 0.004536\tval_Loss: 0.004857\n",
      "Train Epoch: 1014/10000 (10%)\ttrain_Loss: 0.004535\tval_Loss: 0.004856\n",
      "Train Epoch: 1015/10000 (10%)\ttrain_Loss: 0.004534\tval_Loss: 0.004855\n",
      "Train Epoch: 1016/10000 (10%)\ttrain_Loss: 0.004534\tval_Loss: 0.004854\n",
      "Train Epoch: 1017/10000 (10%)\ttrain_Loss: 0.004533\tval_Loss: 0.004853\n",
      "Train Epoch: 1018/10000 (10%)\ttrain_Loss: 0.004532\tval_Loss: 0.004852\n",
      "Train Epoch: 1019/10000 (10%)\ttrain_Loss: 0.004531\tval_Loss: 0.004851\n",
      "Train Epoch: 1020/10000 (10%)\ttrain_Loss: 0.004531\tval_Loss: 0.004850\n",
      "Train Epoch: 1021/10000 (10%)\ttrain_Loss: 0.004530\tval_Loss: 0.004850\n",
      "Train Epoch: 1022/10000 (10%)\ttrain_Loss: 0.004529\tval_Loss: 0.004849\n",
      "Train Epoch: 1023/10000 (10%)\ttrain_Loss: 0.004528\tval_Loss: 0.004848\n",
      "Train Epoch: 1024/10000 (10%)\ttrain_Loss: 0.004527\tval_Loss: 0.004847\n",
      "Train Epoch: 1025/10000 (10%)\ttrain_Loss: 0.004527\tval_Loss: 0.004846\n",
      "Train Epoch: 1026/10000 (10%)\ttrain_Loss: 0.004526\tval_Loss: 0.004845\n",
      "Train Epoch: 1027/10000 (10%)\ttrain_Loss: 0.004525\tval_Loss: 0.004844\n",
      "Train Epoch: 1028/10000 (10%)\ttrain_Loss: 0.004524\tval_Loss: 0.004843\n",
      "Train Epoch: 1029/10000 (10%)\ttrain_Loss: 0.004524\tval_Loss: 0.004843\n",
      "Train Epoch: 1030/10000 (10%)\ttrain_Loss: 0.004523\tval_Loss: 0.004842\n",
      "Train Epoch: 1031/10000 (10%)\ttrain_Loss: 0.004522\tval_Loss: 0.004841\n",
      "Train Epoch: 1032/10000 (10%)\ttrain_Loss: 0.004522\tval_Loss: 0.004840\n",
      "Train Epoch: 1033/10000 (10%)\ttrain_Loss: 0.004521\tval_Loss: 0.004839\n",
      "Train Epoch: 1034/10000 (10%)\ttrain_Loss: 0.004520\tval_Loss: 0.004838\n",
      "Train Epoch: 1035/10000 (10%)\ttrain_Loss: 0.004519\tval_Loss: 0.004837\n",
      "Train Epoch: 1036/10000 (10%)\ttrain_Loss: 0.004519\tval_Loss: 0.004837\n",
      "Train Epoch: 1037/10000 (10%)\ttrain_Loss: 0.004518\tval_Loss: 0.004836\n",
      "Train Epoch: 1038/10000 (10%)\ttrain_Loss: 0.004517\tval_Loss: 0.004835\n",
      "Train Epoch: 1039/10000 (10%)\ttrain_Loss: 0.004516\tval_Loss: 0.004834\n",
      "Train Epoch: 1040/10000 (10%)\ttrain_Loss: 0.004516\tval_Loss: 0.004833\n",
      "Train Epoch: 1041/10000 (10%)\ttrain_Loss: 0.004515\tval_Loss: 0.004832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1042/10000 (10%)\ttrain_Loss: 0.004514\tval_Loss: 0.004831\n",
      "Train Epoch: 1043/10000 (10%)\ttrain_Loss: 0.004514\tval_Loss: 0.004830\n",
      "Train Epoch: 1044/10000 (10%)\ttrain_Loss: 0.004513\tval_Loss: 0.004830\n",
      "Train Epoch: 1045/10000 (10%)\ttrain_Loss: 0.004512\tval_Loss: 0.004829\n",
      "Train Epoch: 1046/10000 (10%)\ttrain_Loss: 0.004511\tval_Loss: 0.004828\n",
      "Train Epoch: 1047/10000 (10%)\ttrain_Loss: 0.004511\tval_Loss: 0.004827\n",
      "Train Epoch: 1048/10000 (10%)\ttrain_Loss: 0.004510\tval_Loss: 0.004826\n",
      "Train Epoch: 1049/10000 (10%)\ttrain_Loss: 0.004509\tval_Loss: 0.004825\n",
      "Train Epoch: 1050/10000 (10%)\ttrain_Loss: 0.004509\tval_Loss: 0.004824\n",
      "Train Epoch: 1051/10000 (10%)\ttrain_Loss: 0.004508\tval_Loss: 0.004824\n",
      "Train Epoch: 1052/10000 (11%)\ttrain_Loss: 0.004507\tval_Loss: 0.004823\n",
      "Train Epoch: 1053/10000 (11%)\ttrain_Loss: 0.004506\tval_Loss: 0.004822\n",
      "Train Epoch: 1054/10000 (11%)\ttrain_Loss: 0.004506\tval_Loss: 0.004821\n",
      "Train Epoch: 1055/10000 (11%)\ttrain_Loss: 0.004505\tval_Loss: 0.004820\n",
      "Train Epoch: 1056/10000 (11%)\ttrain_Loss: 0.004504\tval_Loss: 0.004819\n",
      "Train Epoch: 1057/10000 (11%)\ttrain_Loss: 0.004504\tval_Loss: 0.004819\n",
      "Train Epoch: 1058/10000 (11%)\ttrain_Loss: 0.004503\tval_Loss: 0.004818\n",
      "Train Epoch: 1059/10000 (11%)\ttrain_Loss: 0.004502\tval_Loss: 0.004817\n",
      "Train Epoch: 1060/10000 (11%)\ttrain_Loss: 0.004502\tval_Loss: 0.004816\n",
      "Train Epoch: 1061/10000 (11%)\ttrain_Loss: 0.004501\tval_Loss: 0.004815\n",
      "Train Epoch: 1062/10000 (11%)\ttrain_Loss: 0.004500\tval_Loss: 0.004814\n",
      "Train Epoch: 1063/10000 (11%)\ttrain_Loss: 0.004500\tval_Loss: 0.004814\n",
      "Train Epoch: 1064/10000 (11%)\ttrain_Loss: 0.004499\tval_Loss: 0.004813\n",
      "Train Epoch: 1065/10000 (11%)\ttrain_Loss: 0.004498\tval_Loss: 0.004813\n",
      "Train Epoch: 1066/10000 (11%)\ttrain_Loss: 0.004498\tval_Loss: 0.004812\n",
      "Train Epoch: 1067/10000 (11%)\ttrain_Loss: 0.004497\tval_Loss: 0.004811\n",
      "Train Epoch: 1068/10000 (11%)\ttrain_Loss: 0.004496\tval_Loss: 0.004810\n",
      "Train Epoch: 1069/10000 (11%)\ttrain_Loss: 0.004496\tval_Loss: 0.004809\n",
      "Train Epoch: 1070/10000 (11%)\ttrain_Loss: 0.004495\tval_Loss: 0.004809\n",
      "Train Epoch: 1071/10000 (11%)\ttrain_Loss: 0.004494\tval_Loss: 0.004808\n",
      "Train Epoch: 1072/10000 (11%)\ttrain_Loss: 0.004494\tval_Loss: 0.004807\n",
      "Train Epoch: 1073/10000 (11%)\ttrain_Loss: 0.004493\tval_Loss: 0.004807\n",
      "Train Epoch: 1074/10000 (11%)\ttrain_Loss: 0.004492\tval_Loss: 0.004806\n",
      "Train Epoch: 1075/10000 (11%)\ttrain_Loss: 0.004492\tval_Loss: 0.004805\n",
      "Train Epoch: 1076/10000 (11%)\ttrain_Loss: 0.004491\tval_Loss: 0.004804\n",
      "Train Epoch: 1077/10000 (11%)\ttrain_Loss: 0.004490\tval_Loss: 0.004804\n",
      "Train Epoch: 1078/10000 (11%)\ttrain_Loss: 0.004490\tval_Loss: 0.004803\n",
      "Train Epoch: 1079/10000 (11%)\ttrain_Loss: 0.004489\tval_Loss: 0.004802\n",
      "Train Epoch: 1080/10000 (11%)\ttrain_Loss: 0.004488\tval_Loss: 0.004802\n",
      "Train Epoch: 1081/10000 (11%)\ttrain_Loss: 0.004488\tval_Loss: 0.004801\n",
      "Train Epoch: 1082/10000 (11%)\ttrain_Loss: 0.004487\tval_Loss: 0.004800\n",
      "Train Epoch: 1083/10000 (11%)\ttrain_Loss: 0.004487\tval_Loss: 0.004799\n",
      "Train Epoch: 1084/10000 (11%)\ttrain_Loss: 0.004486\tval_Loss: 0.004799\n",
      "Train Epoch: 1085/10000 (11%)\ttrain_Loss: 0.004485\tval_Loss: 0.004798\n",
      "Train Epoch: 1086/10000 (11%)\ttrain_Loss: 0.004485\tval_Loss: 0.004797\n",
      "Train Epoch: 1087/10000 (11%)\ttrain_Loss: 0.004484\tval_Loss: 0.004797\n",
      "Train Epoch: 1088/10000 (11%)\ttrain_Loss: 0.004483\tval_Loss: 0.004796\n",
      "Train Epoch: 1089/10000 (11%)\ttrain_Loss: 0.004483\tval_Loss: 0.004795\n",
      "Train Epoch: 1090/10000 (11%)\ttrain_Loss: 0.004482\tval_Loss: 0.004794\n",
      "Train Epoch: 1091/10000 (11%)\ttrain_Loss: 0.004482\tval_Loss: 0.004794\n",
      "Train Epoch: 1092/10000 (11%)\ttrain_Loss: 0.004481\tval_Loss: 0.004793\n",
      "Train Epoch: 1093/10000 (11%)\ttrain_Loss: 0.004480\tval_Loss: 0.004792\n",
      "Train Epoch: 1094/10000 (11%)\ttrain_Loss: 0.004480\tval_Loss: 0.004792\n",
      "Train Epoch: 1095/10000 (11%)\ttrain_Loss: 0.004479\tval_Loss: 0.004791\n",
      "Train Epoch: 1096/10000 (11%)\ttrain_Loss: 0.004479\tval_Loss: 0.004790\n",
      "Train Epoch: 1097/10000 (11%)\ttrain_Loss: 0.004478\tval_Loss: 0.004790\n",
      "Train Epoch: 1098/10000 (11%)\ttrain_Loss: 0.004477\tval_Loss: 0.004789\n",
      "Train Epoch: 1099/10000 (11%)\ttrain_Loss: 0.004477\tval_Loss: 0.004788\n",
      "Train Epoch: 1100/10000 (11%)\ttrain_Loss: 0.004476\tval_Loss: 0.004788\n",
      "Train Epoch: 1101/10000 (11%)\ttrain_Loss: 0.004476\tval_Loss: 0.004787\n",
      "Train Epoch: 1102/10000 (11%)\ttrain_Loss: 0.004475\tval_Loss: 0.004786\n",
      "Train Epoch: 1103/10000 (11%)\ttrain_Loss: 0.004475\tval_Loss: 0.004786\n",
      "Train Epoch: 1104/10000 (11%)\ttrain_Loss: 0.004474\tval_Loss: 0.004785\n",
      "Train Epoch: 1105/10000 (11%)\ttrain_Loss: 0.004473\tval_Loss: 0.004784\n",
      "Train Epoch: 1106/10000 (11%)\ttrain_Loss: 0.004473\tval_Loss: 0.004784\n",
      "Train Epoch: 1107/10000 (11%)\ttrain_Loss: 0.004472\tval_Loss: 0.004783\n",
      "Train Epoch: 1108/10000 (11%)\ttrain_Loss: 0.004472\tval_Loss: 0.004783\n",
      "Train Epoch: 1109/10000 (11%)\ttrain_Loss: 0.004471\tval_Loss: 0.004782\n",
      "Train Epoch: 1110/10000 (11%)\ttrain_Loss: 0.004471\tval_Loss: 0.004781\n",
      "Train Epoch: 1111/10000 (11%)\ttrain_Loss: 0.004470\tval_Loss: 0.004781\n",
      "Train Epoch: 1112/10000 (11%)\ttrain_Loss: 0.004469\tval_Loss: 0.004780\n",
      "Train Epoch: 1113/10000 (11%)\ttrain_Loss: 0.004469\tval_Loss: 0.004779\n",
      "Train Epoch: 1114/10000 (11%)\ttrain_Loss: 0.004468\tval_Loss: 0.004779\n",
      "Train Epoch: 1115/10000 (11%)\ttrain_Loss: 0.004468\tval_Loss: 0.004778\n",
      "Train Epoch: 1116/10000 (11%)\ttrain_Loss: 0.004467\tval_Loss: 0.004777\n",
      "Train Epoch: 1117/10000 (11%)\ttrain_Loss: 0.004467\tval_Loss: 0.004777\n",
      "Train Epoch: 1118/10000 (11%)\ttrain_Loss: 0.004466\tval_Loss: 0.004776\n",
      "Train Epoch: 1119/10000 (11%)\ttrain_Loss: 0.004465\tval_Loss: 0.004776\n",
      "Train Epoch: 1120/10000 (11%)\ttrain_Loss: 0.004465\tval_Loss: 0.004775\n",
      "Train Epoch: 1121/10000 (11%)\ttrain_Loss: 0.004464\tval_Loss: 0.004775\n",
      "Train Epoch: 1122/10000 (11%)\ttrain_Loss: 0.004464\tval_Loss: 0.004774\n",
      "Train Epoch: 1123/10000 (11%)\ttrain_Loss: 0.004463\tval_Loss: 0.004774\n",
      "Train Epoch: 1124/10000 (11%)\ttrain_Loss: 0.004463\tval_Loss: 0.004773\n",
      "Train Epoch: 1125/10000 (11%)\ttrain_Loss: 0.004462\tval_Loss: 0.004773\n",
      "Train Epoch: 1126/10000 (11%)\ttrain_Loss: 0.004462\tval_Loss: 0.004772\n",
      "Train Epoch: 1127/10000 (11%)\ttrain_Loss: 0.004461\tval_Loss: 0.004771\n",
      "Train Epoch: 1128/10000 (11%)\ttrain_Loss: 0.004461\tval_Loss: 0.004771\n",
      "Train Epoch: 1129/10000 (11%)\ttrain_Loss: 0.004460\tval_Loss: 0.004770\n",
      "Train Epoch: 1130/10000 (11%)\ttrain_Loss: 0.004460\tval_Loss: 0.004770\n",
      "Train Epoch: 1131/10000 (11%)\ttrain_Loss: 0.004459\tval_Loss: 0.004769\n",
      "Train Epoch: 1132/10000 (11%)\ttrain_Loss: 0.004458\tval_Loss: 0.004769\n",
      "Train Epoch: 1133/10000 (11%)\ttrain_Loss: 0.004458\tval_Loss: 0.004768\n",
      "Train Epoch: 1134/10000 (11%)\ttrain_Loss: 0.004457\tval_Loss: 0.004768\n",
      "Train Epoch: 1135/10000 (11%)\ttrain_Loss: 0.004457\tval_Loss: 0.004767\n",
      "Train Epoch: 1136/10000 (11%)\ttrain_Loss: 0.004456\tval_Loss: 0.004767\n",
      "Train Epoch: 1137/10000 (11%)\ttrain_Loss: 0.004456\tval_Loss: 0.004766\n",
      "Train Epoch: 1138/10000 (11%)\ttrain_Loss: 0.004455\tval_Loss: 0.004766\n",
      "Train Epoch: 1139/10000 (11%)\ttrain_Loss: 0.004455\tval_Loss: 0.004765\n",
      "Train Epoch: 1140/10000 (11%)\ttrain_Loss: 0.004454\tval_Loss: 0.004764\n",
      "Train Epoch: 1141/10000 (11%)\ttrain_Loss: 0.004454\tval_Loss: 0.004764\n",
      "Train Epoch: 1142/10000 (11%)\ttrain_Loss: 0.004453\tval_Loss: 0.004764\n",
      "Train Epoch: 1143/10000 (11%)\ttrain_Loss: 0.004453\tval_Loss: 0.004763\n",
      "Train Epoch: 1144/10000 (11%)\ttrain_Loss: 0.004452\tval_Loss: 0.004762\n",
      "Train Epoch: 1145/10000 (11%)\ttrain_Loss: 0.004452\tval_Loss: 0.004762\n",
      "Train Epoch: 1146/10000 (11%)\ttrain_Loss: 0.004451\tval_Loss: 0.004761\n",
      "Train Epoch: 1147/10000 (11%)\ttrain_Loss: 0.004451\tval_Loss: 0.004761\n",
      "Train Epoch: 1148/10000 (11%)\ttrain_Loss: 0.004450\tval_Loss: 0.004760\n",
      "Train Epoch: 1149/10000 (11%)\ttrain_Loss: 0.004450\tval_Loss: 0.004760\n",
      "Train Epoch: 1150/10000 (11%)\ttrain_Loss: 0.004449\tval_Loss: 0.004760\n",
      "Train Epoch: 1151/10000 (12%)\ttrain_Loss: 0.004449\tval_Loss: 0.004759\n",
      "Train Epoch: 1152/10000 (12%)\ttrain_Loss: 0.004448\tval_Loss: 0.004758\n",
      "Train Epoch: 1153/10000 (12%)\ttrain_Loss: 0.004448\tval_Loss: 0.004758\n",
      "Train Epoch: 1154/10000 (12%)\ttrain_Loss: 0.004447\tval_Loss: 0.004758\n",
      "Train Epoch: 1155/10000 (12%)\ttrain_Loss: 0.004447\tval_Loss: 0.004757\n",
      "Train Epoch: 1156/10000 (12%)\ttrain_Loss: 0.004446\tval_Loss: 0.004757\n",
      "Train Epoch: 1157/10000 (12%)\ttrain_Loss: 0.004446\tval_Loss: 0.004756\n",
      "Train Epoch: 1158/10000 (12%)\ttrain_Loss: 0.004445\tval_Loss: 0.004756\n",
      "Train Epoch: 1159/10000 (12%)\ttrain_Loss: 0.004445\tval_Loss: 0.004755\n",
      "Train Epoch: 1160/10000 (12%)\ttrain_Loss: 0.004445\tval_Loss: 0.004755\n",
      "Train Epoch: 1161/10000 (12%)\ttrain_Loss: 0.004444\tval_Loss: 0.004754\n",
      "Train Epoch: 1162/10000 (12%)\ttrain_Loss: 0.004443\tval_Loss: 0.004754\n",
      "Train Epoch: 1163/10000 (12%)\ttrain_Loss: 0.004443\tval_Loss: 0.004754\n",
      "Train Epoch: 1164/10000 (12%)\ttrain_Loss: 0.004443\tval_Loss: 0.004753\n",
      "Train Epoch: 1165/10000 (12%)\ttrain_Loss: 0.004442\tval_Loss: 0.004752\n",
      "Train Epoch: 1166/10000 (12%)\ttrain_Loss: 0.004442\tval_Loss: 0.004751\n",
      "Train Epoch: 1167/10000 (12%)\ttrain_Loss: 0.004441\tval_Loss: 0.004750\n",
      "Train Epoch: 1168/10000 (12%)\ttrain_Loss: 0.004441\tval_Loss: 0.004750\n",
      "Train Epoch: 1169/10000 (12%)\ttrain_Loss: 0.004440\tval_Loss: 0.004749\n",
      "Train Epoch: 1170/10000 (12%)\ttrain_Loss: 0.004440\tval_Loss: 0.004748\n",
      "Train Epoch: 1171/10000 (12%)\ttrain_Loss: 0.004439\tval_Loss: 0.004748\n",
      "Train Epoch: 1172/10000 (12%)\ttrain_Loss: 0.004439\tval_Loss: 0.004747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1173/10000 (12%)\ttrain_Loss: 0.004438\tval_Loss: 0.004746\n",
      "Train Epoch: 1174/10000 (12%)\ttrain_Loss: 0.004438\tval_Loss: 0.004746\n",
      "Train Epoch: 1175/10000 (12%)\ttrain_Loss: 0.004437\tval_Loss: 0.004745\n",
      "Train Epoch: 1176/10000 (12%)\ttrain_Loss: 0.004437\tval_Loss: 0.004745\n",
      "Train Epoch: 1177/10000 (12%)\ttrain_Loss: 0.004436\tval_Loss: 0.004744\n",
      "Train Epoch: 1178/10000 (12%)\ttrain_Loss: 0.004436\tval_Loss: 0.004744\n",
      "Train Epoch: 1179/10000 (12%)\ttrain_Loss: 0.004436\tval_Loss: 0.004744\n",
      "Train Epoch: 1180/10000 (12%)\ttrain_Loss: 0.004435\tval_Loss: 0.004743\n",
      "Train Epoch: 1181/10000 (12%)\ttrain_Loss: 0.004434\tval_Loss: 0.004742\n",
      "Train Epoch: 1182/10000 (12%)\ttrain_Loss: 0.004434\tval_Loss: 0.004742\n",
      "Train Epoch: 1183/10000 (12%)\ttrain_Loss: 0.004434\tval_Loss: 0.004741\n",
      "Train Epoch: 1184/10000 (12%)\ttrain_Loss: 0.004433\tval_Loss: 0.004741\n",
      "Train Epoch: 1185/10000 (12%)\ttrain_Loss: 0.004433\tval_Loss: 0.004741\n",
      "Train Epoch: 1186/10000 (12%)\ttrain_Loss: 0.004432\tval_Loss: 0.004741\n",
      "Train Epoch: 1187/10000 (12%)\ttrain_Loss: 0.004432\tval_Loss: 0.004740\n",
      "Train Epoch: 1188/10000 (12%)\ttrain_Loss: 0.004431\tval_Loss: 0.004739\n",
      "Train Epoch: 1189/10000 (12%)\ttrain_Loss: 0.004431\tval_Loss: 0.004738\n",
      "Train Epoch: 1190/10000 (12%)\ttrain_Loss: 0.004430\tval_Loss: 0.004738\n",
      "Train Epoch: 1191/10000 (12%)\ttrain_Loss: 0.004430\tval_Loss: 0.004737\n",
      "Train Epoch: 1192/10000 (12%)\ttrain_Loss: 0.004429\tval_Loss: 0.004737\n",
      "Train Epoch: 1193/10000 (12%)\ttrain_Loss: 0.004429\tval_Loss: 0.004737\n",
      "Train Epoch: 1194/10000 (12%)\ttrain_Loss: 0.004429\tval_Loss: 0.004736\n",
      "Train Epoch: 1195/10000 (12%)\ttrain_Loss: 0.004428\tval_Loss: 0.004736\n",
      "Train Epoch: 1196/10000 (12%)\ttrain_Loss: 0.004428\tval_Loss: 0.004735\n",
      "Train Epoch: 1197/10000 (12%)\ttrain_Loss: 0.004427\tval_Loss: 0.004735\n",
      "Train Epoch: 1198/10000 (12%)\ttrain_Loss: 0.004427\tval_Loss: 0.004734\n",
      "Train Epoch: 1199/10000 (12%)\ttrain_Loss: 0.004426\tval_Loss: 0.004734\n",
      "Train Epoch: 1200/10000 (12%)\ttrain_Loss: 0.004426\tval_Loss: 0.004734\n",
      "Train Epoch: 1201/10000 (12%)\ttrain_Loss: 0.004426\tval_Loss: 0.004734\n",
      "Train Epoch: 1202/10000 (12%)\ttrain_Loss: 0.004425\tval_Loss: 0.004734\n",
      "Train Epoch: 1203/10000 (12%)\ttrain_Loss: 0.004425\tval_Loss: 0.004734\n",
      "Train Epoch: 1204/10000 (12%)\ttrain_Loss: 0.004425\tval_Loss: 0.004733\n",
      "Train Epoch: 1205/10000 (12%)\ttrain_Loss: 0.004424\tval_Loss: 0.004733\n",
      "Train Epoch: 1206/10000 (12%)\ttrain_Loss: 0.004424\tval_Loss: 0.004732\n",
      "Train Epoch: 1207/10000 (12%)\ttrain_Loss: 0.004423\tval_Loss: 0.004732\n",
      "Train Epoch: 1208/10000 (12%)\ttrain_Loss: 0.004423\tval_Loss: 0.004731\n",
      "Train Epoch: 1209/10000 (12%)\ttrain_Loss: 0.004422\tval_Loss: 0.004731\n",
      "Train Epoch: 1210/10000 (12%)\ttrain_Loss: 0.004422\tval_Loss: 0.004731\n",
      "Train Epoch: 1211/10000 (12%)\ttrain_Loss: 0.004421\tval_Loss: 0.004731\n",
      "Train Epoch: 1212/10000 (12%)\ttrain_Loss: 0.004421\tval_Loss: 0.004730\n",
      "Train Epoch: 1213/10000 (12%)\ttrain_Loss: 0.004421\tval_Loss: 0.004730\n",
      "Train Epoch: 1214/10000 (12%)\ttrain_Loss: 0.004420\tval_Loss: 0.004730\n",
      "Train Epoch: 1215/10000 (12%)\ttrain_Loss: 0.004420\tval_Loss: 0.004729\n",
      "Train Epoch: 1216/10000 (12%)\ttrain_Loss: 0.004420\tval_Loss: 0.004729\n",
      "Train Epoch: 1217/10000 (12%)\ttrain_Loss: 0.004419\tval_Loss: 0.004729\n",
      "Train Epoch: 1218/10000 (12%)\ttrain_Loss: 0.004419\tval_Loss: 0.004728\n",
      "Train Epoch: 1219/10000 (12%)\ttrain_Loss: 0.004418\tval_Loss: 0.004728\n",
      "Train Epoch: 1220/10000 (12%)\ttrain_Loss: 0.004418\tval_Loss: 0.004728\n",
      "Train Epoch: 1221/10000 (12%)\ttrain_Loss: 0.004418\tval_Loss: 0.004727\n",
      "Train Epoch: 1222/10000 (12%)\ttrain_Loss: 0.004417\tval_Loss: 0.004727\n",
      "Train Epoch: 1223/10000 (12%)\ttrain_Loss: 0.004417\tval_Loss: 0.004727\n",
      "Train Epoch: 1224/10000 (12%)\ttrain_Loss: 0.004416\tval_Loss: 0.004727\n",
      "Train Epoch: 1225/10000 (12%)\ttrain_Loss: 0.004416\tval_Loss: 0.004727\n",
      "Train Epoch: 1226/10000 (12%)\ttrain_Loss: 0.004416\tval_Loss: 0.004726\n",
      "Train Epoch: 1227/10000 (12%)\ttrain_Loss: 0.004415\tval_Loss: 0.004726\n",
      "Train Epoch: 1228/10000 (12%)\ttrain_Loss: 0.004415\tval_Loss: 0.004726\n",
      "Train Epoch: 1229/10000 (12%)\ttrain_Loss: 0.004415\tval_Loss: 0.004725\n",
      "Train Epoch: 1230/10000 (12%)\ttrain_Loss: 0.004414\tval_Loss: 0.004725\n",
      "Train Epoch: 1231/10000 (12%)\ttrain_Loss: 0.004414\tval_Loss: 0.004724\n",
      "Train Epoch: 1232/10000 (12%)\ttrain_Loss: 0.004414\tval_Loss: 0.004724\n",
      "Train Epoch: 1233/10000 (12%)\ttrain_Loss: 0.004413\tval_Loss: 0.004724\n",
      "Train Epoch: 1234/10000 (12%)\ttrain_Loss: 0.004413\tval_Loss: 0.004723\n",
      "Train Epoch: 1235/10000 (12%)\ttrain_Loss: 0.004412\tval_Loss: 0.004723\n",
      "Train Epoch: 1236/10000 (12%)\ttrain_Loss: 0.004412\tval_Loss: 0.004723\n",
      "Train Epoch: 1237/10000 (12%)\ttrain_Loss: 0.004412\tval_Loss: 0.004722\n",
      "Train Epoch: 1238/10000 (12%)\ttrain_Loss: 0.004411\tval_Loss: 0.004722\n",
      "Train Epoch: 1239/10000 (12%)\ttrain_Loss: 0.004411\tval_Loss: 0.004722\n",
      "Train Epoch: 1240/10000 (12%)\ttrain_Loss: 0.004411\tval_Loss: 0.004721\n",
      "Train Epoch: 1241/10000 (12%)\ttrain_Loss: 0.004410\tval_Loss: 0.004721\n",
      "Train Epoch: 1242/10000 (12%)\ttrain_Loss: 0.004410\tval_Loss: 0.004721\n",
      "Train Epoch: 1243/10000 (12%)\ttrain_Loss: 0.004409\tval_Loss: 0.004720\n",
      "Train Epoch: 1244/10000 (12%)\ttrain_Loss: 0.004409\tval_Loss: 0.004720\n",
      "Train Epoch: 1245/10000 (12%)\ttrain_Loss: 0.004409\tval_Loss: 0.004719\n",
      "Train Epoch: 1246/10000 (12%)\ttrain_Loss: 0.004408\tval_Loss: 0.004719\n",
      "Train Epoch: 1247/10000 (12%)\ttrain_Loss: 0.004408\tval_Loss: 0.004718\n",
      "Train Epoch: 1248/10000 (12%)\ttrain_Loss: 0.004408\tval_Loss: 0.004718\n",
      "Train Epoch: 1249/10000 (12%)\ttrain_Loss: 0.004407\tval_Loss: 0.004717\n",
      "Train Epoch: 1250/10000 (12%)\ttrain_Loss: 0.004407\tval_Loss: 0.004717\n",
      "Train Epoch: 1251/10000 (12%)\ttrain_Loss: 0.004407\tval_Loss: 0.004716\n",
      "Train Epoch: 1252/10000 (13%)\ttrain_Loss: 0.004406\tval_Loss: 0.004716\n",
      "Train Epoch: 1253/10000 (13%)\ttrain_Loss: 0.004406\tval_Loss: 0.004715\n",
      "Train Epoch: 1254/10000 (13%)\ttrain_Loss: 0.004405\tval_Loss: 0.004715\n",
      "Train Epoch: 1255/10000 (13%)\ttrain_Loss: 0.004405\tval_Loss: 0.004714\n",
      "Train Epoch: 1256/10000 (13%)\ttrain_Loss: 0.004405\tval_Loss: 0.004714\n",
      "Train Epoch: 1257/10000 (13%)\ttrain_Loss: 0.004404\tval_Loss: 0.004714\n",
      "Train Epoch: 1258/10000 (13%)\ttrain_Loss: 0.004404\tval_Loss: 0.004714\n",
      "Train Epoch: 1259/10000 (13%)\ttrain_Loss: 0.004404\tval_Loss: 0.004713\n",
      "Train Epoch: 1260/10000 (13%)\ttrain_Loss: 0.004403\tval_Loss: 0.004713\n",
      "Train Epoch: 1261/10000 (13%)\ttrain_Loss: 0.004403\tval_Loss: 0.004712\n",
      "Train Epoch: 1262/10000 (13%)\ttrain_Loss: 0.004403\tval_Loss: 0.004712\n",
      "Train Epoch: 1263/10000 (13%)\ttrain_Loss: 0.004402\tval_Loss: 0.004712\n",
      "Train Epoch: 1264/10000 (13%)\ttrain_Loss: 0.004402\tval_Loss: 0.004712\n",
      "Train Epoch: 1265/10000 (13%)\ttrain_Loss: 0.004402\tval_Loss: 0.004711\n",
      "Train Epoch: 1266/10000 (13%)\ttrain_Loss: 0.004401\tval_Loss: 0.004711\n",
      "Train Epoch: 1267/10000 (13%)\ttrain_Loss: 0.004401\tval_Loss: 0.004711\n",
      "Train Epoch: 1268/10000 (13%)\ttrain_Loss: 0.004401\tval_Loss: 0.004711\n",
      "Train Epoch: 1269/10000 (13%)\ttrain_Loss: 0.004400\tval_Loss: 0.004710\n",
      "Train Epoch: 1270/10000 (13%)\ttrain_Loss: 0.004400\tval_Loss: 0.004710\n",
      "Train Epoch: 1271/10000 (13%)\ttrain_Loss: 0.004400\tval_Loss: 0.004710\n",
      "Train Epoch: 1272/10000 (13%)\ttrain_Loss: 0.004399\tval_Loss: 0.004710\n",
      "Train Epoch: 1273/10000 (13%)\ttrain_Loss: 0.004399\tval_Loss: 0.004709\n",
      "Train Epoch: 1274/10000 (13%)\ttrain_Loss: 0.004399\tval_Loss: 0.004709\n",
      "Train Epoch: 1275/10000 (13%)\ttrain_Loss: 0.004398\tval_Loss: 0.004709\n",
      "Train Epoch: 1276/10000 (13%)\ttrain_Loss: 0.004398\tval_Loss: 0.004709\n",
      "Train Epoch: 1277/10000 (13%)\ttrain_Loss: 0.004398\tval_Loss: 0.004708\n",
      "Train Epoch: 1278/10000 (13%)\ttrain_Loss: 0.004398\tval_Loss: 0.004708\n",
      "Train Epoch: 1279/10000 (13%)\ttrain_Loss: 0.004397\tval_Loss: 0.004708\n",
      "Train Epoch: 1280/10000 (13%)\ttrain_Loss: 0.004397\tval_Loss: 0.004708\n",
      "Train Epoch: 1281/10000 (13%)\ttrain_Loss: 0.004397\tval_Loss: 0.004707\n",
      "Train Epoch: 1282/10000 (13%)\ttrain_Loss: 0.004396\tval_Loss: 0.004707\n",
      "Train Epoch: 1283/10000 (13%)\ttrain_Loss: 0.004396\tval_Loss: 0.004707\n",
      "Train Epoch: 1284/10000 (13%)\ttrain_Loss: 0.004396\tval_Loss: 0.004706\n",
      "Train Epoch: 1285/10000 (13%)\ttrain_Loss: 0.004395\tval_Loss: 0.004706\n",
      "Train Epoch: 1286/10000 (13%)\ttrain_Loss: 0.004395\tval_Loss: 0.004706\n",
      "Train Epoch: 1287/10000 (13%)\ttrain_Loss: 0.004395\tval_Loss: 0.004706\n",
      "Train Epoch: 1288/10000 (13%)\ttrain_Loss: 0.004395\tval_Loss: 0.004705\n",
      "Train Epoch: 1289/10000 (13%)\ttrain_Loss: 0.004394\tval_Loss: 0.004705\n",
      "Train Epoch: 1290/10000 (13%)\ttrain_Loss: 0.004394\tval_Loss: 0.004705\n",
      "Train Epoch: 1291/10000 (13%)\ttrain_Loss: 0.004394\tval_Loss: 0.004705\n",
      "Train Epoch: 1292/10000 (13%)\ttrain_Loss: 0.004393\tval_Loss: 0.004704\n",
      "Train Epoch: 1293/10000 (13%)\ttrain_Loss: 0.004393\tval_Loss: 0.004704\n",
      "Train Epoch: 1294/10000 (13%)\ttrain_Loss: 0.004393\tval_Loss: 0.004704\n",
      "Train Epoch: 1295/10000 (13%)\ttrain_Loss: 0.004392\tval_Loss: 0.004704\n",
      "Train Epoch: 1296/10000 (13%)\ttrain_Loss: 0.004392\tval_Loss: 0.004703\n",
      "Train Epoch: 1297/10000 (13%)\ttrain_Loss: 0.004392\tval_Loss: 0.004703\n",
      "Train Epoch: 1298/10000 (13%)\ttrain_Loss: 0.004392\tval_Loss: 0.004703\n",
      "Train Epoch: 1299/10000 (13%)\ttrain_Loss: 0.004391\tval_Loss: 0.004702\n",
      "Train Epoch: 1300/10000 (13%)\ttrain_Loss: 0.004391\tval_Loss: 0.004702\n",
      "Train Epoch: 1301/10000 (13%)\ttrain_Loss: 0.004391\tval_Loss: 0.004702\n",
      "Train Epoch: 1302/10000 (13%)\ttrain_Loss: 0.004390\tval_Loss: 0.004702\n",
      "Train Epoch: 1303/10000 (13%)\ttrain_Loss: 0.004390\tval_Loss: 0.004701\n",
      "Train Epoch: 1304/10000 (13%)\ttrain_Loss: 0.004390\tval_Loss: 0.004701\n",
      "Train Epoch: 1305/10000 (13%)\ttrain_Loss: 0.004390\tval_Loss: 0.004701\n",
      "Train Epoch: 1306/10000 (13%)\ttrain_Loss: 0.004389\tval_Loss: 0.004700\n",
      "Train Epoch: 1307/10000 (13%)\ttrain_Loss: 0.004389\tval_Loss: 0.004700\n",
      "Train Epoch: 1308/10000 (13%)\ttrain_Loss: 0.004389\tval_Loss: 0.004700\n",
      "Train Epoch: 1309/10000 (13%)\ttrain_Loss: 0.004388\tval_Loss: 0.004699\n",
      "Train Epoch: 1310/10000 (13%)\ttrain_Loss: 0.004388\tval_Loss: 0.004699\n",
      "Train Epoch: 1311/10000 (13%)\ttrain_Loss: 0.004388\tval_Loss: 0.004699\n",
      "Train Epoch: 1312/10000 (13%)\ttrain_Loss: 0.004388\tval_Loss: 0.004699\n",
      "Train Epoch: 1313/10000 (13%)\ttrain_Loss: 0.004387\tval_Loss: 0.004698\n",
      "Train Epoch: 1314/10000 (13%)\ttrain_Loss: 0.004387\tval_Loss: 0.004698\n",
      "Train Epoch: 1315/10000 (13%)\ttrain_Loss: 0.004387\tval_Loss: 0.004697\n",
      "Train Epoch: 1316/10000 (13%)\ttrain_Loss: 0.004386\tval_Loss: 0.004697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1317/10000 (13%)\ttrain_Loss: 0.004386\tval_Loss: 0.004697\n",
      "Train Epoch: 1318/10000 (13%)\ttrain_Loss: 0.004386\tval_Loss: 0.004697\n",
      "Train Epoch: 1319/10000 (13%)\ttrain_Loss: 0.004385\tval_Loss: 0.004696\n",
      "Train Epoch: 1320/10000 (13%)\ttrain_Loss: 0.004385\tval_Loss: 0.004696\n",
      "Train Epoch: 1321/10000 (13%)\ttrain_Loss: 0.004385\tval_Loss: 0.004696\n",
      "Train Epoch: 1322/10000 (13%)\ttrain_Loss: 0.004385\tval_Loss: 0.004696\n",
      "Train Epoch: 1323/10000 (13%)\ttrain_Loss: 0.004384\tval_Loss: 0.004695\n",
      "Train Epoch: 1324/10000 (13%)\ttrain_Loss: 0.004384\tval_Loss: 0.004695\n",
      "Train Epoch: 1325/10000 (13%)\ttrain_Loss: 0.004384\tval_Loss: 0.004695\n",
      "Train Epoch: 1326/10000 (13%)\ttrain_Loss: 0.004384\tval_Loss: 0.004695\n",
      "Train Epoch: 1327/10000 (13%)\ttrain_Loss: 0.004383\tval_Loss: 0.004695\n",
      "Train Epoch: 1328/10000 (13%)\ttrain_Loss: 0.004383\tval_Loss: 0.004694\n",
      "Train Epoch: 1329/10000 (13%)\ttrain_Loss: 0.004383\tval_Loss: 0.004694\n",
      "Train Epoch: 1330/10000 (13%)\ttrain_Loss: 0.004383\tval_Loss: 0.004694\n",
      "Train Epoch: 1331/10000 (13%)\ttrain_Loss: 0.004382\tval_Loss: 0.004693\n",
      "Train Epoch: 1332/10000 (13%)\ttrain_Loss: 0.004382\tval_Loss: 0.004693\n",
      "Train Epoch: 1333/10000 (13%)\ttrain_Loss: 0.004382\tval_Loss: 0.004693\n",
      "Train Epoch: 1334/10000 (13%)\ttrain_Loss: 0.004382\tval_Loss: 0.004693\n",
      "Train Epoch: 1335/10000 (13%)\ttrain_Loss: 0.004381\tval_Loss: 0.004693\n",
      "Train Epoch: 1336/10000 (13%)\ttrain_Loss: 0.004381\tval_Loss: 0.004693\n",
      "Train Epoch: 1337/10000 (13%)\ttrain_Loss: 0.004381\tval_Loss: 0.004693\n",
      "Train Epoch: 1338/10000 (13%)\ttrain_Loss: 0.004381\tval_Loss: 0.004692\n",
      "Train Epoch: 1339/10000 (13%)\ttrain_Loss: 0.004380\tval_Loss: 0.004692\n",
      "Train Epoch: 1340/10000 (13%)\ttrain_Loss: 0.004380\tval_Loss: 0.004692\n",
      "Train Epoch: 1341/10000 (13%)\ttrain_Loss: 0.004380\tval_Loss: 0.004691\n",
      "Train Epoch: 1342/10000 (13%)\ttrain_Loss: 0.004379\tval_Loss: 0.004691\n",
      "Train Epoch: 1343/10000 (13%)\ttrain_Loss: 0.004379\tval_Loss: 0.004691\n",
      "Train Epoch: 1344/10000 (13%)\ttrain_Loss: 0.004379\tval_Loss: 0.004691\n",
      "Train Epoch: 1345/10000 (13%)\ttrain_Loss: 0.004379\tval_Loss: 0.004690\n",
      "Train Epoch: 1346/10000 (13%)\ttrain_Loss: 0.004378\tval_Loss: 0.004690\n",
      "Train Epoch: 1347/10000 (13%)\ttrain_Loss: 0.004378\tval_Loss: 0.004690\n",
      "Train Epoch: 1348/10000 (13%)\ttrain_Loss: 0.004378\tval_Loss: 0.004690\n",
      "Train Epoch: 1349/10000 (13%)\ttrain_Loss: 0.004378\tval_Loss: 0.004690\n",
      "Train Epoch: 1350/10000 (13%)\ttrain_Loss: 0.004377\tval_Loss: 0.004689\n",
      "Train Epoch: 1351/10000 (14%)\ttrain_Loss: 0.004377\tval_Loss: 0.004689\n",
      "Train Epoch: 1352/10000 (14%)\ttrain_Loss: 0.004377\tval_Loss: 0.004689\n",
      "Train Epoch: 1353/10000 (14%)\ttrain_Loss: 0.004377\tval_Loss: 0.004688\n",
      "Train Epoch: 1354/10000 (14%)\ttrain_Loss: 0.004376\tval_Loss: 0.004688\n",
      "Train Epoch: 1355/10000 (14%)\ttrain_Loss: 0.004376\tval_Loss: 0.004687\n",
      "Train Epoch: 1356/10000 (14%)\ttrain_Loss: 0.004376\tval_Loss: 0.004687\n",
      "Train Epoch: 1357/10000 (14%)\ttrain_Loss: 0.004375\tval_Loss: 0.004686\n",
      "Train Epoch: 1358/10000 (14%)\ttrain_Loss: 0.004375\tval_Loss: 0.004686\n",
      "Train Epoch: 1359/10000 (14%)\ttrain_Loss: 0.004375\tval_Loss: 0.004686\n",
      "Train Epoch: 1360/10000 (14%)\ttrain_Loss: 0.004374\tval_Loss: 0.004685\n",
      "Train Epoch: 1361/10000 (14%)\ttrain_Loss: 0.004374\tval_Loss: 0.004685\n",
      "Train Epoch: 1362/10000 (14%)\ttrain_Loss: 0.004374\tval_Loss: 0.004684\n",
      "Train Epoch: 1363/10000 (14%)\ttrain_Loss: 0.004374\tval_Loss: 0.004683\n",
      "Train Epoch: 1364/10000 (14%)\ttrain_Loss: 0.004373\tval_Loss: 0.004683\n",
      "Train Epoch: 1365/10000 (14%)\ttrain_Loss: 0.004373\tval_Loss: 0.004682\n",
      "Train Epoch: 1366/10000 (14%)\ttrain_Loss: 0.004373\tval_Loss: 0.004682\n",
      "Train Epoch: 1367/10000 (14%)\ttrain_Loss: 0.004373\tval_Loss: 0.004682\n",
      "Train Epoch: 1368/10000 (14%)\ttrain_Loss: 0.004372\tval_Loss: 0.004681\n",
      "Train Epoch: 1369/10000 (14%)\ttrain_Loss: 0.004372\tval_Loss: 0.004681\n",
      "Train Epoch: 1370/10000 (14%)\ttrain_Loss: 0.004372\tval_Loss: 0.004681\n",
      "Train Epoch: 1371/10000 (14%)\ttrain_Loss: 0.004372\tval_Loss: 0.004680\n",
      "Train Epoch: 1372/10000 (14%)\ttrain_Loss: 0.004371\tval_Loss: 0.004680\n",
      "Train Epoch: 1373/10000 (14%)\ttrain_Loss: 0.004371\tval_Loss: 0.004680\n",
      "Train Epoch: 1374/10000 (14%)\ttrain_Loss: 0.004371\tval_Loss: 0.004680\n",
      "Train Epoch: 1375/10000 (14%)\ttrain_Loss: 0.004371\tval_Loss: 0.004680\n",
      "Train Epoch: 1376/10000 (14%)\ttrain_Loss: 0.004370\tval_Loss: 0.004680\n",
      "Train Epoch: 1377/10000 (14%)\ttrain_Loss: 0.004370\tval_Loss: 0.004680\n",
      "Train Epoch: 1378/10000 (14%)\ttrain_Loss: 0.004370\tval_Loss: 0.004680\n",
      "Train Epoch: 1379/10000 (14%)\ttrain_Loss: 0.004370\tval_Loss: 0.004679\n",
      "Train Epoch: 1380/10000 (14%)\ttrain_Loss: 0.004369\tval_Loss: 0.004679\n",
      "Train Epoch: 1381/10000 (14%)\ttrain_Loss: 0.004369\tval_Loss: 0.004679\n",
      "Train Epoch: 1382/10000 (14%)\ttrain_Loss: 0.004369\tval_Loss: 0.004679\n",
      "Train Epoch: 1383/10000 (14%)\ttrain_Loss: 0.004369\tval_Loss: 0.004679\n",
      "Train Epoch: 1384/10000 (14%)\ttrain_Loss: 0.004369\tval_Loss: 0.004679\n",
      "Train Epoch: 1385/10000 (14%)\ttrain_Loss: 0.004368\tval_Loss: 0.004679\n",
      "Train Epoch: 1386/10000 (14%)\ttrain_Loss: 0.004368\tval_Loss: 0.004679\n",
      "Train Epoch: 1387/10000 (14%)\ttrain_Loss: 0.004368\tval_Loss: 0.004679\n",
      "Train Epoch: 1388/10000 (14%)\ttrain_Loss: 0.004368\tval_Loss: 0.004679\n",
      "Train Epoch: 1389/10000 (14%)\ttrain_Loss: 0.004367\tval_Loss: 0.004678\n",
      "Train Epoch: 1390/10000 (14%)\ttrain_Loss: 0.004367\tval_Loss: 0.004678\n",
      "Train Epoch: 1391/10000 (14%)\ttrain_Loss: 0.004367\tval_Loss: 0.004678\n",
      "Train Epoch: 1392/10000 (14%)\ttrain_Loss: 0.004367\tval_Loss: 0.004677\n",
      "Train Epoch: 1393/10000 (14%)\ttrain_Loss: 0.004367\tval_Loss: 0.004677\n",
      "Train Epoch: 1394/10000 (14%)\ttrain_Loss: 0.004366\tval_Loss: 0.004677\n",
      "Train Epoch: 1395/10000 (14%)\ttrain_Loss: 0.004366\tval_Loss: 0.004677\n",
      "Train Epoch: 1396/10000 (14%)\ttrain_Loss: 0.004366\tval_Loss: 0.004677\n",
      "Train Epoch: 1397/10000 (14%)\ttrain_Loss: 0.004366\tval_Loss: 0.004677\n",
      "Train Epoch: 1398/10000 (14%)\ttrain_Loss: 0.004365\tval_Loss: 0.004677\n",
      "Train Epoch: 1399/10000 (14%)\ttrain_Loss: 0.004365\tval_Loss: 0.004676\n",
      "Train Epoch: 1400/10000 (14%)\ttrain_Loss: 0.004365\tval_Loss: 0.004676\n",
      "Train Epoch: 1401/10000 (14%)\ttrain_Loss: 0.004365\tval_Loss: 0.004676\n",
      "Train Epoch: 1402/10000 (14%)\ttrain_Loss: 0.004365\tval_Loss: 0.004676\n",
      "Train Epoch: 1403/10000 (14%)\ttrain_Loss: 0.004364\tval_Loss: 0.004675\n",
      "Train Epoch: 1404/10000 (14%)\ttrain_Loss: 0.004364\tval_Loss: 0.004675\n",
      "Train Epoch: 1405/10000 (14%)\ttrain_Loss: 0.004364\tval_Loss: 0.004675\n",
      "Train Epoch: 1406/10000 (14%)\ttrain_Loss: 0.004364\tval_Loss: 0.004675\n",
      "Train Epoch: 1407/10000 (14%)\ttrain_Loss: 0.004364\tval_Loss: 0.004675\n",
      "Train Epoch: 1408/10000 (14%)\ttrain_Loss: 0.004363\tval_Loss: 0.004675\n",
      "Train Epoch: 1409/10000 (14%)\ttrain_Loss: 0.004363\tval_Loss: 0.004675\n",
      "Train Epoch: 1410/10000 (14%)\ttrain_Loss: 0.004363\tval_Loss: 0.004675\n",
      "Train Epoch: 1411/10000 (14%)\ttrain_Loss: 0.004363\tval_Loss: 0.004675\n",
      "Train Epoch: 1412/10000 (14%)\ttrain_Loss: 0.004363\tval_Loss: 0.004674\n",
      "Train Epoch: 1413/10000 (14%)\ttrain_Loss: 0.004362\tval_Loss: 0.004674\n",
      "Train Epoch: 1414/10000 (14%)\ttrain_Loss: 0.004362\tval_Loss: 0.004674\n",
      "Train Epoch: 1415/10000 (14%)\ttrain_Loss: 0.004362\tval_Loss: 0.004674\n",
      "Train Epoch: 1416/10000 (14%)\ttrain_Loss: 0.004362\tval_Loss: 0.004673\n",
      "Train Epoch: 1417/10000 (14%)\ttrain_Loss: 0.004361\tval_Loss: 0.004673\n",
      "Train Epoch: 1418/10000 (14%)\ttrain_Loss: 0.004361\tval_Loss: 0.004673\n",
      "Train Epoch: 1419/10000 (14%)\ttrain_Loss: 0.004361\tval_Loss: 0.004673\n",
      "Train Epoch: 1420/10000 (14%)\ttrain_Loss: 0.004361\tval_Loss: 0.004673\n",
      "Train Epoch: 1421/10000 (14%)\ttrain_Loss: 0.004361\tval_Loss: 0.004673\n",
      "Train Epoch: 1422/10000 (14%)\ttrain_Loss: 0.004361\tval_Loss: 0.004673\n",
      "Train Epoch: 1423/10000 (14%)\ttrain_Loss: 0.004360\tval_Loss: 0.004673\n",
      "Train Epoch: 1424/10000 (14%)\ttrain_Loss: 0.004360\tval_Loss: 0.004672\n",
      "Train Epoch: 1425/10000 (14%)\ttrain_Loss: 0.004360\tval_Loss: 0.004672\n",
      "Train Epoch: 1426/10000 (14%)\ttrain_Loss: 0.004360\tval_Loss: 0.004672\n",
      "Train Epoch: 1427/10000 (14%)\ttrain_Loss: 0.004360\tval_Loss: 0.004672\n",
      "Train Epoch: 1428/10000 (14%)\ttrain_Loss: 0.004360\tval_Loss: 0.004672\n",
      "Train Epoch: 1429/10000 (14%)\ttrain_Loss: 0.004359\tval_Loss: 0.004672\n",
      "Train Epoch: 1430/10000 (14%)\ttrain_Loss: 0.004359\tval_Loss: 0.004672\n",
      "Train Epoch: 1431/10000 (14%)\ttrain_Loss: 0.004359\tval_Loss: 0.004672\n",
      "Train Epoch: 1432/10000 (14%)\ttrain_Loss: 0.004359\tval_Loss: 0.004672\n",
      "Train Epoch: 1433/10000 (14%)\ttrain_Loss: 0.004359\tval_Loss: 0.004671\n",
      "Train Epoch: 1434/10000 (14%)\ttrain_Loss: 0.004358\tval_Loss: 0.004671\n",
      "Train Epoch: 1435/10000 (14%)\ttrain_Loss: 0.004358\tval_Loss: 0.004671\n",
      "Train Epoch: 1436/10000 (14%)\ttrain_Loss: 0.004358\tval_Loss: 0.004670\n",
      "Train Epoch: 1437/10000 (14%)\ttrain_Loss: 0.004358\tval_Loss: 0.004670\n",
      "Train Epoch: 1438/10000 (14%)\ttrain_Loss: 0.004358\tval_Loss: 0.004670\n",
      "Train Epoch: 1439/10000 (14%)\ttrain_Loss: 0.004357\tval_Loss: 0.004670\n",
      "Train Epoch: 1440/10000 (14%)\ttrain_Loss: 0.004357\tval_Loss: 0.004671\n",
      "Train Epoch: 1441/10000 (14%)\ttrain_Loss: 0.004357\tval_Loss: 0.004671\n",
      "Train Epoch: 1442/10000 (14%)\ttrain_Loss: 0.004357\tval_Loss: 0.004671\n",
      "Train Epoch: 1443/10000 (14%)\ttrain_Loss: 0.004357\tval_Loss: 0.004670\n",
      "Train Epoch: 1444/10000 (14%)\ttrain_Loss: 0.004357\tval_Loss: 0.004670\n",
      "Train Epoch: 1445/10000 (14%)\ttrain_Loss: 0.004356\tval_Loss: 0.004670\n",
      "Train Epoch: 1446/10000 (14%)\ttrain_Loss: 0.004356\tval_Loss: 0.004670\n",
      "Train Epoch: 1447/10000 (14%)\ttrain_Loss: 0.004356\tval_Loss: 0.004670\n",
      "Train Epoch: 1448/10000 (14%)\ttrain_Loss: 0.004356\tval_Loss: 0.004670\n",
      "Train Epoch: 1449/10000 (14%)\ttrain_Loss: 0.004356\tval_Loss: 0.004670\n",
      "Train Epoch: 1450/10000 (14%)\ttrain_Loss: 0.004356\tval_Loss: 0.004670\n",
      "Train Epoch: 1451/10000 (14%)\ttrain_Loss: 0.004355\tval_Loss: 0.004669\n",
      "Train Epoch: 1452/10000 (15%)\ttrain_Loss: 0.004355\tval_Loss: 0.004669\n",
      "Train Epoch: 1453/10000 (15%)\ttrain_Loss: 0.004355\tval_Loss: 0.004669\n",
      "Train Epoch: 1454/10000 (15%)\ttrain_Loss: 0.004355\tval_Loss: 0.004669\n",
      "Train Epoch: 1455/10000 (15%)\ttrain_Loss: 0.004355\tval_Loss: 0.004669\n",
      "Train Epoch: 1456/10000 (15%)\ttrain_Loss: 0.004355\tval_Loss: 0.004669\n",
      "Train Epoch: 1457/10000 (15%)\ttrain_Loss: 0.004355\tval_Loss: 0.004668\n",
      "Train Epoch: 1458/10000 (15%)\ttrain_Loss: 0.004354\tval_Loss: 0.004668\n",
      "Train Epoch: 1459/10000 (15%)\ttrain_Loss: 0.004354\tval_Loss: 0.004668\n",
      "Train Epoch: 1460/10000 (15%)\ttrain_Loss: 0.004354\tval_Loss: 0.004668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1461/10000 (15%)\ttrain_Loss: 0.004354\tval_Loss: 0.004668\n",
      "Train Epoch: 1462/10000 (15%)\ttrain_Loss: 0.004354\tval_Loss: 0.004667\n",
      "Train Epoch: 1463/10000 (15%)\ttrain_Loss: 0.004354\tval_Loss: 0.004667\n",
      "Train Epoch: 1464/10000 (15%)\ttrain_Loss: 0.004353\tval_Loss: 0.004667\n",
      "Train Epoch: 1465/10000 (15%)\ttrain_Loss: 0.004353\tval_Loss: 0.004667\n",
      "Train Epoch: 1466/10000 (15%)\ttrain_Loss: 0.004353\tval_Loss: 0.004667\n",
      "Train Epoch: 1467/10000 (15%)\ttrain_Loss: 0.004353\tval_Loss: 0.004667\n",
      "Train Epoch: 1468/10000 (15%)\ttrain_Loss: 0.004353\tval_Loss: 0.004666\n",
      "Train Epoch: 1469/10000 (15%)\ttrain_Loss: 0.004353\tval_Loss: 0.004666\n",
      "Train Epoch: 1470/10000 (15%)\ttrain_Loss: 0.004353\tval_Loss: 0.004666\n",
      "Train Epoch: 1471/10000 (15%)\ttrain_Loss: 0.004352\tval_Loss: 0.004666\n",
      "Train Epoch: 1472/10000 (15%)\ttrain_Loss: 0.004352\tval_Loss: 0.004666\n",
      "Train Epoch: 1473/10000 (15%)\ttrain_Loss: 0.004352\tval_Loss: 0.004665\n",
      "Train Epoch: 1474/10000 (15%)\ttrain_Loss: 0.004352\tval_Loss: 0.004665\n",
      "Train Epoch: 1475/10000 (15%)\ttrain_Loss: 0.004352\tval_Loss: 0.004665\n",
      "Train Epoch: 1476/10000 (15%)\ttrain_Loss: 0.004352\tval_Loss: 0.004665\n",
      "Train Epoch: 1477/10000 (15%)\ttrain_Loss: 0.004351\tval_Loss: 0.004665\n",
      "Train Epoch: 1478/10000 (15%)\ttrain_Loss: 0.004351\tval_Loss: 0.004665\n",
      "Train Epoch: 1479/10000 (15%)\ttrain_Loss: 0.004351\tval_Loss: 0.004665\n",
      "Train Epoch: 1480/10000 (15%)\ttrain_Loss: 0.004351\tval_Loss: 0.004664\n",
      "Train Epoch: 1481/10000 (15%)\ttrain_Loss: 0.004351\tval_Loss: 0.004664\n",
      "Train Epoch: 1482/10000 (15%)\ttrain_Loss: 0.004351\tval_Loss: 0.004664\n",
      "Train Epoch: 1483/10000 (15%)\ttrain_Loss: 0.004351\tval_Loss: 0.004664\n",
      "Train Epoch: 1484/10000 (15%)\ttrain_Loss: 0.004351\tval_Loss: 0.004663\n",
      "Train Epoch: 1485/10000 (15%)\ttrain_Loss: 0.004350\tval_Loss: 0.004663\n",
      "Train Epoch: 1486/10000 (15%)\ttrain_Loss: 0.004350\tval_Loss: 0.004663\n",
      "Train Epoch: 1487/10000 (15%)\ttrain_Loss: 0.004350\tval_Loss: 0.004663\n",
      "Train Epoch: 1488/10000 (15%)\ttrain_Loss: 0.004350\tval_Loss: 0.004663\n",
      "Train Epoch: 1489/10000 (15%)\ttrain_Loss: 0.004350\tval_Loss: 0.004663\n",
      "Train Epoch: 1490/10000 (15%)\ttrain_Loss: 0.004350\tval_Loss: 0.004663\n",
      "Train Epoch: 1491/10000 (15%)\ttrain_Loss: 0.004349\tval_Loss: 0.004662\n",
      "Train Epoch: 1492/10000 (15%)\ttrain_Loss: 0.004349\tval_Loss: 0.004662\n",
      "Train Epoch: 1493/10000 (15%)\ttrain_Loss: 0.004349\tval_Loss: 0.004662\n",
      "Train Epoch: 1494/10000 (15%)\ttrain_Loss: 0.004349\tval_Loss: 0.004662\n",
      "Train Epoch: 1495/10000 (15%)\ttrain_Loss: 0.004349\tval_Loss: 0.004662\n",
      "Train Epoch: 1496/10000 (15%)\ttrain_Loss: 0.004349\tval_Loss: 0.004662\n",
      "Train Epoch: 1497/10000 (15%)\ttrain_Loss: 0.004349\tval_Loss: 0.004661\n",
      "Train Epoch: 1498/10000 (15%)\ttrain_Loss: 0.004349\tval_Loss: 0.004661\n",
      "Train Epoch: 1499/10000 (15%)\ttrain_Loss: 0.004348\tval_Loss: 0.004661\n",
      "Train Epoch: 1500/10000 (15%)\ttrain_Loss: 0.004348\tval_Loss: 0.004661\n",
      "Train Epoch: 1501/10000 (15%)\ttrain_Loss: 0.004348\tval_Loss: 0.004660\n",
      "Train Epoch: 1502/10000 (15%)\ttrain_Loss: 0.004348\tval_Loss: 0.004660\n",
      "Train Epoch: 1503/10000 (15%)\ttrain_Loss: 0.004348\tval_Loss: 0.004660\n",
      "Train Epoch: 1504/10000 (15%)\ttrain_Loss: 0.004348\tval_Loss: 0.004660\n",
      "Train Epoch: 1505/10000 (15%)\ttrain_Loss: 0.004348\tval_Loss: 0.004660\n",
      "Train Epoch: 1506/10000 (15%)\ttrain_Loss: 0.004347\tval_Loss: 0.004660\n",
      "Train Epoch: 1507/10000 (15%)\ttrain_Loss: 0.004347\tval_Loss: 0.004660\n",
      "Train Epoch: 1508/10000 (15%)\ttrain_Loss: 0.004347\tval_Loss: 0.004660\n",
      "Train Epoch: 1509/10000 (15%)\ttrain_Loss: 0.004347\tval_Loss: 0.004660\n",
      "Train Epoch: 1510/10000 (15%)\ttrain_Loss: 0.004347\tval_Loss: 0.004659\n",
      "Train Epoch: 1511/10000 (15%)\ttrain_Loss: 0.004347\tval_Loss: 0.004659\n",
      "Train Epoch: 1512/10000 (15%)\ttrain_Loss: 0.004347\tval_Loss: 0.004659\n",
      "Train Epoch: 1513/10000 (15%)\ttrain_Loss: 0.004346\tval_Loss: 0.004659\n",
      "Train Epoch: 1514/10000 (15%)\ttrain_Loss: 0.004346\tval_Loss: 0.004659\n",
      "Train Epoch: 1515/10000 (15%)\ttrain_Loss: 0.004346\tval_Loss: 0.004659\n",
      "Train Epoch: 1516/10000 (15%)\ttrain_Loss: 0.004346\tval_Loss: 0.004658\n",
      "Train Epoch: 1517/10000 (15%)\ttrain_Loss: 0.004346\tval_Loss: 0.004658\n",
      "Train Epoch: 1518/10000 (15%)\ttrain_Loss: 0.004346\tval_Loss: 0.004658\n",
      "Train Epoch: 1519/10000 (15%)\ttrain_Loss: 0.004346\tval_Loss: 0.004658\n",
      "Train Epoch: 1520/10000 (15%)\ttrain_Loss: 0.004346\tval_Loss: 0.004658\n",
      "Train Epoch: 1521/10000 (15%)\ttrain_Loss: 0.004346\tval_Loss: 0.004658\n",
      "Train Epoch: 1522/10000 (15%)\ttrain_Loss: 0.004345\tval_Loss: 0.004658\n",
      "Train Epoch: 1523/10000 (15%)\ttrain_Loss: 0.004345\tval_Loss: 0.004657\n",
      "Train Epoch: 1524/10000 (15%)\ttrain_Loss: 0.004345\tval_Loss: 0.004657\n",
      "Train Epoch: 1525/10000 (15%)\ttrain_Loss: 0.004345\tval_Loss: 0.004657\n",
      "Train Epoch: 1526/10000 (15%)\ttrain_Loss: 0.004345\tval_Loss: 0.004657\n",
      "Train Epoch: 1527/10000 (15%)\ttrain_Loss: 0.004345\tval_Loss: 0.004657\n",
      "Train Epoch: 1528/10000 (15%)\ttrain_Loss: 0.004345\tval_Loss: 0.004657\n",
      "Train Epoch: 1529/10000 (15%)\ttrain_Loss: 0.004344\tval_Loss: 0.004657\n",
      "Train Epoch: 1530/10000 (15%)\ttrain_Loss: 0.004344\tval_Loss: 0.004657\n",
      "Train Epoch: 1531/10000 (15%)\ttrain_Loss: 0.004344\tval_Loss: 0.004657\n",
      "Train Epoch: 1532/10000 (15%)\ttrain_Loss: 0.004344\tval_Loss: 0.004656\n",
      "Train Epoch: 1533/10000 (15%)\ttrain_Loss: 0.004344\tval_Loss: 0.004656\n",
      "Train Epoch: 1534/10000 (15%)\ttrain_Loss: 0.004344\tval_Loss: 0.004656\n",
      "Train Epoch: 1535/10000 (15%)\ttrain_Loss: 0.004344\tval_Loss: 0.004656\n",
      "Train Epoch: 1536/10000 (15%)\ttrain_Loss: 0.004344\tval_Loss: 0.004656\n",
      "Train Epoch: 1537/10000 (15%)\ttrain_Loss: 0.004343\tval_Loss: 0.004656\n",
      "Train Epoch: 1538/10000 (15%)\ttrain_Loss: 0.004343\tval_Loss: 0.004656\n",
      "Train Epoch: 1539/10000 (15%)\ttrain_Loss: 0.004343\tval_Loss: 0.004656\n",
      "Train Epoch: 1540/10000 (15%)\ttrain_Loss: 0.004343\tval_Loss: 0.004655\n",
      "Train Epoch: 1541/10000 (15%)\ttrain_Loss: 0.004343\tval_Loss: 0.004655\n",
      "Train Epoch: 1542/10000 (15%)\ttrain_Loss: 0.004343\tval_Loss: 0.004655\n",
      "Train Epoch: 1543/10000 (15%)\ttrain_Loss: 0.004343\tval_Loss: 0.004655\n",
      "Train Epoch: 1544/10000 (15%)\ttrain_Loss: 0.004343\tval_Loss: 0.004655\n",
      "Train Epoch: 1545/10000 (15%)\ttrain_Loss: 0.004342\tval_Loss: 0.004655\n",
      "Train Epoch: 1546/10000 (15%)\ttrain_Loss: 0.004342\tval_Loss: 0.004655\n",
      "Train Epoch: 1547/10000 (15%)\ttrain_Loss: 0.004342\tval_Loss: 0.004655\n",
      "Train Epoch: 1548/10000 (15%)\ttrain_Loss: 0.004342\tval_Loss: 0.004654\n",
      "Train Epoch: 1549/10000 (15%)\ttrain_Loss: 0.004342\tval_Loss: 0.004654\n",
      "Train Epoch: 1550/10000 (15%)\ttrain_Loss: 0.004342\tval_Loss: 0.004654\n",
      "Train Epoch: 1551/10000 (16%)\ttrain_Loss: 0.004342\tval_Loss: 0.004654\n",
      "Train Epoch: 1552/10000 (16%)\ttrain_Loss: 0.004342\tval_Loss: 0.004654\n",
      "Train Epoch: 1553/10000 (16%)\ttrain_Loss: 0.004342\tval_Loss: 0.004654\n",
      "Train Epoch: 1554/10000 (16%)\ttrain_Loss: 0.004341\tval_Loss: 0.004653\n",
      "Train Epoch: 1555/10000 (16%)\ttrain_Loss: 0.004341\tval_Loss: 0.004653\n",
      "Train Epoch: 1556/10000 (16%)\ttrain_Loss: 0.004341\tval_Loss: 0.004653\n",
      "Train Epoch: 1557/10000 (16%)\ttrain_Loss: 0.004341\tval_Loss: 0.004653\n",
      "Train Epoch: 1558/10000 (16%)\ttrain_Loss: 0.004341\tval_Loss: 0.004653\n",
      "Train Epoch: 1559/10000 (16%)\ttrain_Loss: 0.004341\tval_Loss: 0.004652\n",
      "Train Epoch: 1560/10000 (16%)\ttrain_Loss: 0.004341\tval_Loss: 0.004652\n",
      "Train Epoch: 1561/10000 (16%)\ttrain_Loss: 0.004341\tval_Loss: 0.004652\n",
      "Train Epoch: 1562/10000 (16%)\ttrain_Loss: 0.004340\tval_Loss: 0.004652\n",
      "Train Epoch: 1563/10000 (16%)\ttrain_Loss: 0.004340\tval_Loss: 0.004651\n",
      "Train Epoch: 1564/10000 (16%)\ttrain_Loss: 0.004340\tval_Loss: 0.004651\n",
      "Train Epoch: 1565/10000 (16%)\ttrain_Loss: 0.004340\tval_Loss: 0.004651\n",
      "Train Epoch: 1566/10000 (16%)\ttrain_Loss: 0.004340\tval_Loss: 0.004650\n",
      "Train Epoch: 1567/10000 (16%)\ttrain_Loss: 0.004340\tval_Loss: 0.004650\n",
      "Train Epoch: 1568/10000 (16%)\ttrain_Loss: 0.004340\tval_Loss: 0.004650\n",
      "Train Epoch: 1569/10000 (16%)\ttrain_Loss: 0.004340\tval_Loss: 0.004650\n",
      "Train Epoch: 1570/10000 (16%)\ttrain_Loss: 0.004339\tval_Loss: 0.004649\n",
      "Train Epoch: 1571/10000 (16%)\ttrain_Loss: 0.004339\tval_Loss: 0.004649\n",
      "Train Epoch: 1572/10000 (16%)\ttrain_Loss: 0.004339\tval_Loss: 0.004649\n",
      "Train Epoch: 1573/10000 (16%)\ttrain_Loss: 0.004339\tval_Loss: 0.004649\n",
      "Train Epoch: 1574/10000 (16%)\ttrain_Loss: 0.004339\tval_Loss: 0.004649\n",
      "Train Epoch: 1575/10000 (16%)\ttrain_Loss: 0.004339\tval_Loss: 0.004649\n",
      "Train Epoch: 1576/10000 (16%)\ttrain_Loss: 0.004339\tval_Loss: 0.004649\n",
      "Train Epoch: 1577/10000 (16%)\ttrain_Loss: 0.004339\tval_Loss: 0.004649\n",
      "Train Epoch: 1578/10000 (16%)\ttrain_Loss: 0.004339\tval_Loss: 0.004649\n",
      "Train Epoch: 1579/10000 (16%)\ttrain_Loss: 0.004338\tval_Loss: 0.004649\n",
      "Train Epoch: 1580/10000 (16%)\ttrain_Loss: 0.004338\tval_Loss: 0.004649\n",
      "Train Epoch: 1581/10000 (16%)\ttrain_Loss: 0.004338\tval_Loss: 0.004649\n",
      "Train Epoch: 1582/10000 (16%)\ttrain_Loss: 0.004338\tval_Loss: 0.004648\n",
      "Train Epoch: 1583/10000 (16%)\ttrain_Loss: 0.004338\tval_Loss: 0.004648\n",
      "Train Epoch: 1584/10000 (16%)\ttrain_Loss: 0.004338\tval_Loss: 0.004648\n",
      "Train Epoch: 1585/10000 (16%)\ttrain_Loss: 0.004338\tval_Loss: 0.004648\n",
      "Train Epoch: 1586/10000 (16%)\ttrain_Loss: 0.004338\tval_Loss: 0.004648\n",
      "Train Epoch: 1587/10000 (16%)\ttrain_Loss: 0.004338\tval_Loss: 0.004649\n",
      "Train Epoch: 1588/10000 (16%)\ttrain_Loss: 0.004337\tval_Loss: 0.004649\n",
      "Train Epoch: 1589/10000 (16%)\ttrain_Loss: 0.004337\tval_Loss: 0.004649\n",
      "Train Epoch: 1590/10000 (16%)\ttrain_Loss: 0.004337\tval_Loss: 0.004649\n",
      "Train Epoch: 1591/10000 (16%)\ttrain_Loss: 0.004337\tval_Loss: 0.004649\n",
      "Train Epoch: 1592/10000 (16%)\ttrain_Loss: 0.004337\tval_Loss: 0.004648\n",
      "Train Epoch: 1593/10000 (16%)\ttrain_Loss: 0.004337\tval_Loss: 0.004648\n",
      "Train Epoch: 1594/10000 (16%)\ttrain_Loss: 0.004337\tval_Loss: 0.004648\n",
      "Train Epoch: 1595/10000 (16%)\ttrain_Loss: 0.004337\tval_Loss: 0.004648\n",
      "Train Epoch: 1596/10000 (16%)\ttrain_Loss: 0.004337\tval_Loss: 0.004648\n",
      "Train Epoch: 1597/10000 (16%)\ttrain_Loss: 0.004336\tval_Loss: 0.004648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1598/10000 (16%)\ttrain_Loss: 0.004336\tval_Loss: 0.004648\n",
      "Train Epoch: 1599/10000 (16%)\ttrain_Loss: 0.004336\tval_Loss: 0.004648\n",
      "Train Epoch: 1600/10000 (16%)\ttrain_Loss: 0.004336\tval_Loss: 0.004648\n",
      "Train Epoch: 1601/10000 (16%)\ttrain_Loss: 0.004336\tval_Loss: 0.004648\n",
      "Train Epoch: 1602/10000 (16%)\ttrain_Loss: 0.004336\tval_Loss: 0.004648\n",
      "Train Epoch: 1603/10000 (16%)\ttrain_Loss: 0.004336\tval_Loss: 0.004648\n",
      "Train Epoch: 1604/10000 (16%)\ttrain_Loss: 0.004336\tval_Loss: 0.004648\n",
      "Train Epoch: 1605/10000 (16%)\ttrain_Loss: 0.004336\tval_Loss: 0.004648\n",
      "Train Epoch: 1606/10000 (16%)\ttrain_Loss: 0.004336\tval_Loss: 0.004648\n",
      "Train Epoch: 1607/10000 (16%)\ttrain_Loss: 0.004335\tval_Loss: 0.004648\n",
      "Train Epoch: 1608/10000 (16%)\ttrain_Loss: 0.004335\tval_Loss: 0.004647\n",
      "Train Epoch: 1609/10000 (16%)\ttrain_Loss: 0.004335\tval_Loss: 0.004647\n",
      "Train Epoch: 1610/10000 (16%)\ttrain_Loss: 0.004335\tval_Loss: 0.004647\n",
      "Train Epoch: 1611/10000 (16%)\ttrain_Loss: 0.004335\tval_Loss: 0.004647\n",
      "Train Epoch: 1612/10000 (16%)\ttrain_Loss: 0.004335\tval_Loss: 0.004647\n",
      "Train Epoch: 1613/10000 (16%)\ttrain_Loss: 0.004335\tval_Loss: 0.004647\n",
      "Train Epoch: 1614/10000 (16%)\ttrain_Loss: 0.004335\tval_Loss: 0.004647\n",
      "Train Epoch: 1615/10000 (16%)\ttrain_Loss: 0.004335\tval_Loss: 0.004647\n",
      "Train Epoch: 1616/10000 (16%)\ttrain_Loss: 0.004335\tval_Loss: 0.004647\n",
      "Train Epoch: 1617/10000 (16%)\ttrain_Loss: 0.004335\tval_Loss: 0.004647\n",
      "Train Epoch: 1618/10000 (16%)\ttrain_Loss: 0.004334\tval_Loss: 0.004647\n",
      "Train Epoch: 1619/10000 (16%)\ttrain_Loss: 0.004334\tval_Loss: 0.004647\n",
      "Train Epoch: 1620/10000 (16%)\ttrain_Loss: 0.004334\tval_Loss: 0.004647\n",
      "Train Epoch: 1621/10000 (16%)\ttrain_Loss: 0.004334\tval_Loss: 0.004646\n",
      "Train Epoch: 1622/10000 (16%)\ttrain_Loss: 0.004334\tval_Loss: 0.004646\n",
      "Train Epoch: 1623/10000 (16%)\ttrain_Loss: 0.004334\tval_Loss: 0.004646\n",
      "Train Epoch: 1624/10000 (16%)\ttrain_Loss: 0.004334\tval_Loss: 0.004646\n",
      "Train Epoch: 1625/10000 (16%)\ttrain_Loss: 0.004334\tval_Loss: 0.004646\n",
      "Train Epoch: 1626/10000 (16%)\ttrain_Loss: 0.004334\tval_Loss: 0.004646\n",
      "Train Epoch: 1627/10000 (16%)\ttrain_Loss: 0.004334\tval_Loss: 0.004646\n",
      "Train Epoch: 1628/10000 (16%)\ttrain_Loss: 0.004334\tval_Loss: 0.004646\n",
      "Train Epoch: 1629/10000 (16%)\ttrain_Loss: 0.004333\tval_Loss: 0.004646\n",
      "Train Epoch: 1630/10000 (16%)\ttrain_Loss: 0.004333\tval_Loss: 0.004646\n",
      "Train Epoch: 1631/10000 (16%)\ttrain_Loss: 0.004333\tval_Loss: 0.004646\n",
      "Train Epoch: 1632/10000 (16%)\ttrain_Loss: 0.004333\tval_Loss: 0.004646\n",
      "Train Epoch: 1633/10000 (16%)\ttrain_Loss: 0.004333\tval_Loss: 0.004645\n",
      "Train Epoch: 1634/10000 (16%)\ttrain_Loss: 0.004333\tval_Loss: 0.004645\n",
      "Train Epoch: 1635/10000 (16%)\ttrain_Loss: 0.004333\tval_Loss: 0.004645\n",
      "Train Epoch: 1636/10000 (16%)\ttrain_Loss: 0.004333\tval_Loss: 0.004645\n",
      "Train Epoch: 1637/10000 (16%)\ttrain_Loss: 0.004333\tval_Loss: 0.004645\n",
      "Train Epoch: 1638/10000 (16%)\ttrain_Loss: 0.004333\tval_Loss: 0.004644\n",
      "Train Epoch: 1639/10000 (16%)\ttrain_Loss: 0.004332\tval_Loss: 0.004644\n",
      "Train Epoch: 1640/10000 (16%)\ttrain_Loss: 0.004332\tval_Loss: 0.004644\n",
      "Train Epoch: 1641/10000 (16%)\ttrain_Loss: 0.004332\tval_Loss: 0.004644\n",
      "Train Epoch: 1642/10000 (16%)\ttrain_Loss: 0.004332\tval_Loss: 0.004643\n",
      "Train Epoch: 1643/10000 (16%)\ttrain_Loss: 0.004332\tval_Loss: 0.004643\n",
      "Train Epoch: 1644/10000 (16%)\ttrain_Loss: 0.004332\tval_Loss: 0.004643\n",
      "Train Epoch: 1645/10000 (16%)\ttrain_Loss: 0.004332\tval_Loss: 0.004642\n",
      "Train Epoch: 1646/10000 (16%)\ttrain_Loss: 0.004332\tval_Loss: 0.004642\n",
      "Train Epoch: 1647/10000 (16%)\ttrain_Loss: 0.004332\tval_Loss: 0.004642\n",
      "Train Epoch: 1648/10000 (16%)\ttrain_Loss: 0.004331\tval_Loss: 0.004641\n",
      "Train Epoch: 1649/10000 (16%)\ttrain_Loss: 0.004331\tval_Loss: 0.004641\n",
      "Train Epoch: 1650/10000 (16%)\ttrain_Loss: 0.004331\tval_Loss: 0.004641\n",
      "Train Epoch: 1651/10000 (16%)\ttrain_Loss: 0.004331\tval_Loss: 0.004640\n",
      "Train Epoch: 1652/10000 (17%)\ttrain_Loss: 0.004331\tval_Loss: 0.004640\n",
      "Train Epoch: 1653/10000 (17%)\ttrain_Loss: 0.004331\tval_Loss: 0.004640\n",
      "Train Epoch: 1654/10000 (17%)\ttrain_Loss: 0.004331\tval_Loss: 0.004640\n",
      "Train Epoch: 1655/10000 (17%)\ttrain_Loss: 0.004331\tval_Loss: 0.004640\n",
      "Train Epoch: 1656/10000 (17%)\ttrain_Loss: 0.004331\tval_Loss: 0.004640\n",
      "Train Epoch: 1657/10000 (17%)\ttrain_Loss: 0.004331\tval_Loss: 0.004639\n",
      "Train Epoch: 1658/10000 (17%)\ttrain_Loss: 0.004330\tval_Loss: 0.004639\n",
      "Train Epoch: 1659/10000 (17%)\ttrain_Loss: 0.004330\tval_Loss: 0.004639\n",
      "Train Epoch: 1660/10000 (17%)\ttrain_Loss: 0.004330\tval_Loss: 0.004640\n",
      "Train Epoch: 1661/10000 (17%)\ttrain_Loss: 0.004330\tval_Loss: 0.004640\n",
      "Train Epoch: 1662/10000 (17%)\ttrain_Loss: 0.004330\tval_Loss: 0.004640\n",
      "Train Epoch: 1663/10000 (17%)\ttrain_Loss: 0.004330\tval_Loss: 0.004640\n",
      "Train Epoch: 1664/10000 (17%)\ttrain_Loss: 0.004330\tval_Loss: 0.004640\n",
      "Train Epoch: 1665/10000 (17%)\ttrain_Loss: 0.004330\tval_Loss: 0.004639\n",
      "Train Epoch: 1666/10000 (17%)\ttrain_Loss: 0.004330\tval_Loss: 0.004639\n",
      "Train Epoch: 1667/10000 (17%)\ttrain_Loss: 0.004330\tval_Loss: 0.004639\n",
      "Train Epoch: 1668/10000 (17%)\ttrain_Loss: 0.004329\tval_Loss: 0.004639\n",
      "Train Epoch: 1669/10000 (17%)\ttrain_Loss: 0.004329\tval_Loss: 0.004640\n",
      "Train Epoch: 1670/10000 (17%)\ttrain_Loss: 0.004329\tval_Loss: 0.004640\n",
      "Train Epoch: 1671/10000 (17%)\ttrain_Loss: 0.004329\tval_Loss: 0.004640\n",
      "Train Epoch: 1672/10000 (17%)\ttrain_Loss: 0.004329\tval_Loss: 0.004640\n",
      "Train Epoch: 1673/10000 (17%)\ttrain_Loss: 0.004329\tval_Loss: 0.004640\n",
      "Train Epoch: 1674/10000 (17%)\ttrain_Loss: 0.004329\tval_Loss: 0.004640\n",
      "Train Epoch: 1675/10000 (17%)\ttrain_Loss: 0.004329\tval_Loss: 0.004640\n",
      "Train Epoch: 1676/10000 (17%)\ttrain_Loss: 0.004329\tval_Loss: 0.004640\n",
      "Train Epoch: 1677/10000 (17%)\ttrain_Loss: 0.004329\tval_Loss: 0.004640\n",
      "Train Epoch: 1678/10000 (17%)\ttrain_Loss: 0.004329\tval_Loss: 0.004639\n",
      "Train Epoch: 1679/10000 (17%)\ttrain_Loss: 0.004329\tval_Loss: 0.004639\n",
      "Train Epoch: 1680/10000 (17%)\ttrain_Loss: 0.004328\tval_Loss: 0.004639\n",
      "Train Epoch: 1681/10000 (17%)\ttrain_Loss: 0.004328\tval_Loss: 0.004639\n",
      "Train Epoch: 1682/10000 (17%)\ttrain_Loss: 0.004328\tval_Loss: 0.004639\n",
      "Train Epoch: 1683/10000 (17%)\ttrain_Loss: 0.004328\tval_Loss: 0.004639\n",
      "Train Epoch: 1684/10000 (17%)\ttrain_Loss: 0.004328\tval_Loss: 0.004639\n",
      "Train Epoch: 1685/10000 (17%)\ttrain_Loss: 0.004328\tval_Loss: 0.004639\n",
      "Train Epoch: 1686/10000 (17%)\ttrain_Loss: 0.004328\tval_Loss: 0.004639\n",
      "Train Epoch: 1687/10000 (17%)\ttrain_Loss: 0.004328\tval_Loss: 0.004638\n",
      "Train Epoch: 1688/10000 (17%)\ttrain_Loss: 0.004328\tval_Loss: 0.004638\n",
      "Train Epoch: 1689/10000 (17%)\ttrain_Loss: 0.004328\tval_Loss: 0.004638\n",
      "Train Epoch: 1690/10000 (17%)\ttrain_Loss: 0.004328\tval_Loss: 0.004638\n",
      "Train Epoch: 1691/10000 (17%)\ttrain_Loss: 0.004327\tval_Loss: 0.004638\n",
      "Train Epoch: 1692/10000 (17%)\ttrain_Loss: 0.004327\tval_Loss: 0.004638\n",
      "Train Epoch: 1693/10000 (17%)\ttrain_Loss: 0.004327\tval_Loss: 0.004638\n",
      "Train Epoch: 1694/10000 (17%)\ttrain_Loss: 0.004327\tval_Loss: 0.004638\n",
      "Train Epoch: 1695/10000 (17%)\ttrain_Loss: 0.004327\tval_Loss: 0.004638\n",
      "Train Epoch: 1696/10000 (17%)\ttrain_Loss: 0.004327\tval_Loss: 0.004638\n",
      "Train Epoch: 1697/10000 (17%)\ttrain_Loss: 0.004327\tval_Loss: 0.004638\n",
      "Train Epoch: 1698/10000 (17%)\ttrain_Loss: 0.004327\tval_Loss: 0.004638\n",
      "Train Epoch: 1699/10000 (17%)\ttrain_Loss: 0.004327\tval_Loss: 0.004638\n",
      "Train Epoch: 1700/10000 (17%)\ttrain_Loss: 0.004327\tval_Loss: 0.004638\n",
      "Train Epoch: 1701/10000 (17%)\ttrain_Loss: 0.004327\tval_Loss: 0.004638\n",
      "Train Epoch: 1702/10000 (17%)\ttrain_Loss: 0.004326\tval_Loss: 0.004638\n",
      "Train Epoch: 1703/10000 (17%)\ttrain_Loss: 0.004326\tval_Loss: 0.004638\n",
      "Train Epoch: 1704/10000 (17%)\ttrain_Loss: 0.004326\tval_Loss: 0.004638\n",
      "Train Epoch: 1705/10000 (17%)\ttrain_Loss: 0.004326\tval_Loss: 0.004637\n",
      "Train Epoch: 1706/10000 (17%)\ttrain_Loss: 0.004326\tval_Loss: 0.004637\n",
      "Train Epoch: 1707/10000 (17%)\ttrain_Loss: 0.004326\tval_Loss: 0.004638\n",
      "Train Epoch: 1708/10000 (17%)\ttrain_Loss: 0.004326\tval_Loss: 0.004638\n",
      "Train Epoch: 1709/10000 (17%)\ttrain_Loss: 0.004326\tval_Loss: 0.004638\n",
      "Train Epoch: 1710/10000 (17%)\ttrain_Loss: 0.004326\tval_Loss: 0.004638\n",
      "Train Epoch: 1711/10000 (17%)\ttrain_Loss: 0.004326\tval_Loss: 0.004638\n",
      "Train Epoch: 1712/10000 (17%)\ttrain_Loss: 0.004326\tval_Loss: 0.004638\n",
      "Train Epoch: 1713/10000 (17%)\ttrain_Loss: 0.004326\tval_Loss: 0.004637\n",
      "Train Epoch: 1714/10000 (17%)\ttrain_Loss: 0.004326\tval_Loss: 0.004637\n",
      "Train Epoch: 1715/10000 (17%)\ttrain_Loss: 0.004325\tval_Loss: 0.004637\n",
      "Train Epoch: 1716/10000 (17%)\ttrain_Loss: 0.004325\tval_Loss: 0.004637\n",
      "Train Epoch: 1717/10000 (17%)\ttrain_Loss: 0.004325\tval_Loss: 0.004638\n",
      "Train Epoch: 1718/10000 (17%)\ttrain_Loss: 0.004325\tval_Loss: 0.004638\n",
      "Train Epoch: 1719/10000 (17%)\ttrain_Loss: 0.004325\tval_Loss: 0.004638\n",
      "Train Epoch: 1720/10000 (17%)\ttrain_Loss: 0.004325\tval_Loss: 0.004637\n",
      "Train Epoch: 1721/10000 (17%)\ttrain_Loss: 0.004325\tval_Loss: 0.004637\n",
      "Train Epoch: 1722/10000 (17%)\ttrain_Loss: 0.004325\tval_Loss: 0.004637\n",
      "Train Epoch: 1723/10000 (17%)\ttrain_Loss: 0.004325\tval_Loss: 0.004637\n",
      "Train Epoch: 1724/10000 (17%)\ttrain_Loss: 0.004325\tval_Loss: 0.004637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1725/10000 (17%)\ttrain_Loss: 0.004325\tval_Loss: 0.004637\n",
      "Train Epoch: 1726/10000 (17%)\ttrain_Loss: 0.004325\tval_Loss: 0.004637\n",
      "Train Epoch: 1727/10000 (17%)\ttrain_Loss: 0.004325\tval_Loss: 0.004637\n",
      "Train Epoch: 1728/10000 (17%)\ttrain_Loss: 0.004324\tval_Loss: 0.004637\n",
      "Train Epoch: 1729/10000 (17%)\ttrain_Loss: 0.004324\tval_Loss: 0.004637\n",
      "Train Epoch: 1730/10000 (17%)\ttrain_Loss: 0.004324\tval_Loss: 0.004637\n",
      "Train Epoch: 1731/10000 (17%)\ttrain_Loss: 0.004324\tval_Loss: 0.004637\n",
      "Train Epoch: 1732/10000 (17%)\ttrain_Loss: 0.004324\tval_Loss: 0.004637\n",
      "Train Epoch: 1733/10000 (17%)\ttrain_Loss: 0.004324\tval_Loss: 0.004637\n",
      "Train Epoch: 1734/10000 (17%)\ttrain_Loss: 0.004324\tval_Loss: 0.004637\n",
      "Train Epoch: 1735/10000 (17%)\ttrain_Loss: 0.004324\tval_Loss: 0.004637\n",
      "Train Epoch: 1736/10000 (17%)\ttrain_Loss: 0.004324\tval_Loss: 0.004637\n",
      "Train Epoch: 1737/10000 (17%)\ttrain_Loss: 0.004324\tval_Loss: 0.004637\n",
      "Train Epoch: 1738/10000 (17%)\ttrain_Loss: 0.004324\tval_Loss: 0.004637\n",
      "Train Epoch: 1739/10000 (17%)\ttrain_Loss: 0.004324\tval_Loss: 0.004636\n",
      "Train Epoch: 1740/10000 (17%)\ttrain_Loss: 0.004324\tval_Loss: 0.004636\n",
      "Train Epoch: 1741/10000 (17%)\ttrain_Loss: 0.004324\tval_Loss: 0.004636\n",
      "Train Epoch: 1742/10000 (17%)\ttrain_Loss: 0.004323\tval_Loss: 0.004636\n",
      "Train Epoch: 1743/10000 (17%)\ttrain_Loss: 0.004323\tval_Loss: 0.004636\n",
      "Train Epoch: 1744/10000 (17%)\ttrain_Loss: 0.004323\tval_Loss: 0.004636\n",
      "Train Epoch: 1745/10000 (17%)\ttrain_Loss: 0.004323\tval_Loss: 0.004636\n",
      "Train Epoch: 1746/10000 (17%)\ttrain_Loss: 0.004323\tval_Loss: 0.004636\n",
      "Train Epoch: 1747/10000 (17%)\ttrain_Loss: 0.004323\tval_Loss: 0.004636\n",
      "Train Epoch: 1748/10000 (17%)\ttrain_Loss: 0.004323\tval_Loss: 0.004636\n",
      "Train Epoch: 1749/10000 (17%)\ttrain_Loss: 0.004323\tval_Loss: 0.004636\n",
      "Train Epoch: 1750/10000 (17%)\ttrain_Loss: 0.004323\tval_Loss: 0.004636\n",
      "Train Epoch: 1751/10000 (18%)\ttrain_Loss: 0.004323\tval_Loss: 0.004636\n",
      "Train Epoch: 1752/10000 (18%)\ttrain_Loss: 0.004323\tval_Loss: 0.004636\n",
      "Train Epoch: 1753/10000 (18%)\ttrain_Loss: 0.004323\tval_Loss: 0.004636\n",
      "Train Epoch: 1754/10000 (18%)\ttrain_Loss: 0.004323\tval_Loss: 0.004636\n",
      "Train Epoch: 1755/10000 (18%)\ttrain_Loss: 0.004323\tval_Loss: 0.004636\n",
      "Train Epoch: 1756/10000 (18%)\ttrain_Loss: 0.004323\tval_Loss: 0.004636\n",
      "Train Epoch: 1757/10000 (18%)\ttrain_Loss: 0.004322\tval_Loss: 0.004636\n",
      "Train Epoch: 1758/10000 (18%)\ttrain_Loss: 0.004322\tval_Loss: 0.004636\n",
      "Train Epoch: 1759/10000 (18%)\ttrain_Loss: 0.004322\tval_Loss: 0.004636\n",
      "Train Epoch: 1760/10000 (18%)\ttrain_Loss: 0.004322\tval_Loss: 0.004635\n",
      "Train Epoch: 1761/10000 (18%)\ttrain_Loss: 0.004322\tval_Loss: 0.004635\n",
      "Train Epoch: 1762/10000 (18%)\ttrain_Loss: 0.004322\tval_Loss: 0.004635\n",
      "Train Epoch: 1763/10000 (18%)\ttrain_Loss: 0.004322\tval_Loss: 0.004635\n",
      "Train Epoch: 1764/10000 (18%)\ttrain_Loss: 0.004322\tval_Loss: 0.004635\n",
      "Train Epoch: 1765/10000 (18%)\ttrain_Loss: 0.004322\tval_Loss: 0.004635\n",
      "Train Epoch: 1766/10000 (18%)\ttrain_Loss: 0.004322\tval_Loss: 0.004635\n",
      "Train Epoch: 1767/10000 (18%)\ttrain_Loss: 0.004322\tval_Loss: 0.004635\n",
      "Train Epoch: 1768/10000 (18%)\ttrain_Loss: 0.004322\tval_Loss: 0.004635\n",
      "Train Epoch: 1769/10000 (18%)\ttrain_Loss: 0.004322\tval_Loss: 0.004635\n",
      "Train Epoch: 1770/10000 (18%)\ttrain_Loss: 0.004322\tval_Loss: 0.004635\n",
      "Train Epoch: 1771/10000 (18%)\ttrain_Loss: 0.004322\tval_Loss: 0.004635\n",
      "Train Epoch: 1772/10000 (18%)\ttrain_Loss: 0.004321\tval_Loss: 0.004635\n",
      "Train Epoch: 1773/10000 (18%)\ttrain_Loss: 0.004321\tval_Loss: 0.004635\n",
      "Train Epoch: 1774/10000 (18%)\ttrain_Loss: 0.004321\tval_Loss: 0.004635\n",
      "Train Epoch: 1775/10000 (18%)\ttrain_Loss: 0.004321\tval_Loss: 0.004635\n",
      "Train Epoch: 1776/10000 (18%)\ttrain_Loss: 0.004321\tval_Loss: 0.004635\n",
      "Train Epoch: 1777/10000 (18%)\ttrain_Loss: 0.004321\tval_Loss: 0.004635\n",
      "Train Epoch: 1778/10000 (18%)\ttrain_Loss: 0.004321\tval_Loss: 0.004635\n",
      "Train Epoch: 1779/10000 (18%)\ttrain_Loss: 0.004321\tval_Loss: 0.004635\n",
      "Train Epoch: 1780/10000 (18%)\ttrain_Loss: 0.004321\tval_Loss: 0.004635\n",
      "Train Epoch: 1781/10000 (18%)\ttrain_Loss: 0.004321\tval_Loss: 0.004635\n",
      "Train Epoch: 1782/10000 (18%)\ttrain_Loss: 0.004321\tval_Loss: 0.004635\n",
      "Train Epoch: 1783/10000 (18%)\ttrain_Loss: 0.004321\tval_Loss: 0.004634\n",
      "Train Epoch: 1784/10000 (18%)\ttrain_Loss: 0.004321\tval_Loss: 0.004634\n",
      "Train Epoch: 1785/10000 (18%)\ttrain_Loss: 0.004321\tval_Loss: 0.004634\n",
      "Train Epoch: 1786/10000 (18%)\ttrain_Loss: 0.004321\tval_Loss: 0.004634\n",
      "Train Epoch: 1787/10000 (18%)\ttrain_Loss: 0.004320\tval_Loss: 0.004634\n",
      "Train Epoch: 1788/10000 (18%)\ttrain_Loss: 0.004320\tval_Loss: 0.004634\n",
      "Train Epoch: 1789/10000 (18%)\ttrain_Loss: 0.004320\tval_Loss: 0.004634\n",
      "Train Epoch: 1790/10000 (18%)\ttrain_Loss: 0.004320\tval_Loss: 0.004634\n",
      "Train Epoch: 1791/10000 (18%)\ttrain_Loss: 0.004320\tval_Loss: 0.004634\n",
      "Train Epoch: 1792/10000 (18%)\ttrain_Loss: 0.004320\tval_Loss: 0.004634\n",
      "Train Epoch: 1793/10000 (18%)\ttrain_Loss: 0.004320\tval_Loss: 0.004634\n",
      "Train Epoch: 1794/10000 (18%)\ttrain_Loss: 0.004320\tval_Loss: 0.004634\n",
      "Train Epoch: 1795/10000 (18%)\ttrain_Loss: 0.004320\tval_Loss: 0.004634\n",
      "Train Epoch: 1796/10000 (18%)\ttrain_Loss: 0.004320\tval_Loss: 0.004634\n",
      "Train Epoch: 1797/10000 (18%)\ttrain_Loss: 0.004320\tval_Loss: 0.004634\n",
      "Train Epoch: 1798/10000 (18%)\ttrain_Loss: 0.004320\tval_Loss: 0.004634\n",
      "Train Epoch: 1799/10000 (18%)\ttrain_Loss: 0.004320\tval_Loss: 0.004634\n",
      "Train Epoch: 1800/10000 (18%)\ttrain_Loss: 0.004320\tval_Loss: 0.004634\n",
      "Train Epoch: 1801/10000 (18%)\ttrain_Loss: 0.004320\tval_Loss: 0.004634\n",
      "Train Epoch: 1802/10000 (18%)\ttrain_Loss: 0.004320\tval_Loss: 0.004634\n",
      "Train Epoch: 1803/10000 (18%)\ttrain_Loss: 0.004319\tval_Loss: 0.004634\n",
      "Train Epoch: 1804/10000 (18%)\ttrain_Loss: 0.004319\tval_Loss: 0.004634\n",
      "Train Epoch: 1805/10000 (18%)\ttrain_Loss: 0.004319\tval_Loss: 0.004634\n",
      "Train Epoch: 1806/10000 (18%)\ttrain_Loss: 0.004319\tval_Loss: 0.004634\n",
      "Train Epoch: 1807/10000 (18%)\ttrain_Loss: 0.004319\tval_Loss: 0.004634\n",
      "Train Epoch: 1808/10000 (18%)\ttrain_Loss: 0.004319\tval_Loss: 0.004633\n",
      "Train Epoch: 1809/10000 (18%)\ttrain_Loss: 0.004319\tval_Loss: 0.004633\n",
      "Train Epoch: 1810/10000 (18%)\ttrain_Loss: 0.004319\tval_Loss: 0.004633\n",
      "Train Epoch: 1811/10000 (18%)\ttrain_Loss: 0.004319\tval_Loss: 0.004633\n",
      "Train Epoch: 1812/10000 (18%)\ttrain_Loss: 0.004319\tval_Loss: 0.004633\n",
      "Train Epoch: 1813/10000 (18%)\ttrain_Loss: 0.004319\tval_Loss: 0.004633\n",
      "Train Epoch: 1814/10000 (18%)\ttrain_Loss: 0.004319\tval_Loss: 0.004633\n",
      "Train Epoch: 1815/10000 (18%)\ttrain_Loss: 0.004319\tval_Loss: 0.004633\n",
      "Train Epoch: 1816/10000 (18%)\ttrain_Loss: 0.004319\tval_Loss: 0.004633\n",
      "Train Epoch: 1817/10000 (18%)\ttrain_Loss: 0.004319\tval_Loss: 0.004633\n",
      "Train Epoch: 1818/10000 (18%)\ttrain_Loss: 0.004319\tval_Loss: 0.004633\n",
      "Train Epoch: 1819/10000 (18%)\ttrain_Loss: 0.004319\tval_Loss: 0.004633\n",
      "Train Epoch: 1820/10000 (18%)\ttrain_Loss: 0.004318\tval_Loss: 0.004633\n",
      "Train Epoch: 1821/10000 (18%)\ttrain_Loss: 0.004318\tval_Loss: 0.004633\n",
      "Train Epoch: 1822/10000 (18%)\ttrain_Loss: 0.004318\tval_Loss: 0.004633\n",
      "Train Epoch: 1823/10000 (18%)\ttrain_Loss: 0.004318\tval_Loss: 0.004633\n",
      "Train Epoch: 1824/10000 (18%)\ttrain_Loss: 0.004318\tval_Loss: 0.004633\n",
      "Train Epoch: 1825/10000 (18%)\ttrain_Loss: 0.004318\tval_Loss: 0.004633\n",
      "Train Epoch: 1826/10000 (18%)\ttrain_Loss: 0.004318\tval_Loss: 0.004633\n",
      "Train Epoch: 1827/10000 (18%)\ttrain_Loss: 0.004318\tval_Loss: 0.004633\n",
      "Train Epoch: 1828/10000 (18%)\ttrain_Loss: 0.004318\tval_Loss: 0.004633\n",
      "Train Epoch: 1829/10000 (18%)\ttrain_Loss: 0.004318\tval_Loss: 0.004633\n",
      "Train Epoch: 1830/10000 (18%)\ttrain_Loss: 0.004318\tval_Loss: 0.004633\n",
      "Train Epoch: 1831/10000 (18%)\ttrain_Loss: 0.004318\tval_Loss: 0.004633\n",
      "Train Epoch: 1832/10000 (18%)\ttrain_Loss: 0.004318\tval_Loss: 0.004633\n",
      "Train Epoch: 1833/10000 (18%)\ttrain_Loss: 0.004318\tval_Loss: 0.004633\n",
      "Train Epoch: 1834/10000 (18%)\ttrain_Loss: 0.004318\tval_Loss: 0.004633\n",
      "Train Epoch: 1835/10000 (18%)\ttrain_Loss: 0.004318\tval_Loss: 0.004633\n",
      "Train Epoch: 1836/10000 (18%)\ttrain_Loss: 0.004318\tval_Loss: 0.004633\n",
      "Train Epoch: 1837/10000 (18%)\ttrain_Loss: 0.004317\tval_Loss: 0.004633\n",
      "Train Epoch: 1838/10000 (18%)\ttrain_Loss: 0.004317\tval_Loss: 0.004633\n",
      "Train Epoch: 1839/10000 (18%)\ttrain_Loss: 0.004317\tval_Loss: 0.004633\n",
      "Train Epoch: 1840/10000 (18%)\ttrain_Loss: 0.004317\tval_Loss: 0.004633\n",
      "Train Epoch: 1841/10000 (18%)\ttrain_Loss: 0.004317\tval_Loss: 0.004632\n",
      "Train Epoch: 1842/10000 (18%)\ttrain_Loss: 0.004317\tval_Loss: 0.004632\n",
      "Train Epoch: 1843/10000 (18%)\ttrain_Loss: 0.004317\tval_Loss: 0.004632\n",
      "Train Epoch: 1844/10000 (18%)\ttrain_Loss: 0.004317\tval_Loss: 0.004632\n",
      "Train Epoch: 1845/10000 (18%)\ttrain_Loss: 0.004317\tval_Loss: 0.004632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1846/10000 (18%)\ttrain_Loss: 0.004317\tval_Loss: 0.004632\n",
      "Train Epoch: 1847/10000 (18%)\ttrain_Loss: 0.004317\tval_Loss: 0.004632\n",
      "Train Epoch: 1848/10000 (18%)\ttrain_Loss: 0.004317\tval_Loss: 0.004632\n",
      "Train Epoch: 1849/10000 (18%)\ttrain_Loss: 0.004317\tval_Loss: 0.004632\n",
      "Train Epoch: 1850/10000 (18%)\ttrain_Loss: 0.004317\tval_Loss: 0.004632\n",
      "Train Epoch: 1851/10000 (18%)\ttrain_Loss: 0.004317\tval_Loss: 0.004632\n",
      "Train Epoch: 1852/10000 (19%)\ttrain_Loss: 0.004317\tval_Loss: 0.004632\n",
      "Train Epoch: 1853/10000 (19%)\ttrain_Loss: 0.004317\tval_Loss: 0.004632\n",
      "Train Epoch: 1854/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004632\n",
      "Train Epoch: 1855/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004632\n",
      "Train Epoch: 1856/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004632\n",
      "Train Epoch: 1857/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004632\n",
      "Train Epoch: 1858/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004632\n",
      "Train Epoch: 1859/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004632\n",
      "Train Epoch: 1860/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004632\n",
      "Train Epoch: 1861/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004632\n",
      "Train Epoch: 1862/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004632\n",
      "Train Epoch: 1863/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004632\n",
      "Train Epoch: 1864/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004632\n",
      "Train Epoch: 1865/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004632\n",
      "Train Epoch: 1866/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004632\n",
      "Train Epoch: 1867/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004631\n",
      "Train Epoch: 1868/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004631\n",
      "Train Epoch: 1869/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004631\n",
      "Train Epoch: 1870/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004631\n",
      "Train Epoch: 1871/10000 (19%)\ttrain_Loss: 0.004316\tval_Loss: 0.004631\n",
      "Train Epoch: 1872/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004632\n",
      "Train Epoch: 1873/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004632\n",
      "Train Epoch: 1874/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004632\n",
      "Train Epoch: 1875/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004632\n",
      "Train Epoch: 1876/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004632\n",
      "Train Epoch: 1877/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004632\n",
      "Train Epoch: 1878/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004632\n",
      "Train Epoch: 1879/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004632\n",
      "Train Epoch: 1880/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004631\n",
      "Train Epoch: 1881/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004631\n",
      "Train Epoch: 1882/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004631\n",
      "Train Epoch: 1883/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004632\n",
      "Train Epoch: 1884/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004631\n",
      "Train Epoch: 1885/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004631\n",
      "Train Epoch: 1886/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004631\n",
      "Train Epoch: 1887/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004631\n",
      "Train Epoch: 1888/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004631\n",
      "Train Epoch: 1889/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004631\n",
      "Train Epoch: 1890/10000 (19%)\ttrain_Loss: 0.004315\tval_Loss: 0.004631\n",
      "Train Epoch: 1891/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004631\n",
      "Train Epoch: 1892/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004631\n",
      "Train Epoch: 1893/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004631\n",
      "Train Epoch: 1894/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004631\n",
      "Train Epoch: 1895/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004631\n",
      "Train Epoch: 1896/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004631\n",
      "Train Epoch: 1897/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004631\n",
      "Train Epoch: 1898/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004631\n",
      "Train Epoch: 1899/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004630\n",
      "Train Epoch: 1900/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004630\n",
      "Train Epoch: 1901/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004630\n",
      "Train Epoch: 1902/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004631\n",
      "Train Epoch: 1903/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004631\n",
      "Train Epoch: 1904/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004631\n",
      "Train Epoch: 1905/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004631\n",
      "Train Epoch: 1906/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004631\n",
      "Train Epoch: 1907/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004631\n",
      "Train Epoch: 1908/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004631\n",
      "Train Epoch: 1909/10000 (19%)\ttrain_Loss: 0.004314\tval_Loss: 0.004631\n",
      "Train Epoch: 1910/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004631\n",
      "Train Epoch: 1911/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004631\n",
      "Train Epoch: 1912/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004630\n",
      "Train Epoch: 1913/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004630\n",
      "Train Epoch: 1914/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004630\n",
      "Train Epoch: 1915/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004630\n",
      "Train Epoch: 1916/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004630\n",
      "Train Epoch: 1917/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004630\n",
      "Train Epoch: 1918/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004630\n",
      "Train Epoch: 1919/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004630\n",
      "Train Epoch: 1920/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004630\n",
      "Train Epoch: 1921/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004630\n",
      "Train Epoch: 1922/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004630\n",
      "Train Epoch: 1923/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004630\n",
      "Train Epoch: 1924/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004630\n",
      "Train Epoch: 1925/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004630\n",
      "Train Epoch: 1926/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004630\n",
      "Train Epoch: 1927/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004630\n",
      "Train Epoch: 1928/10000 (19%)\ttrain_Loss: 0.004313\tval_Loss: 0.004630\n",
      "Train Epoch: 1929/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1930/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1931/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1932/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1933/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1934/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1935/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1936/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1937/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1938/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1939/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1940/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1941/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1942/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1943/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1944/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1945/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1946/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1947/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1948/10000 (19%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 1949/10000 (19%)\ttrain_Loss: 0.004311\tval_Loss: 0.004630\n",
      "Train Epoch: 1950/10000 (19%)\ttrain_Loss: 0.004311\tval_Loss: 0.004630\n",
      "Train Epoch: 1951/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004630\n",
      "Train Epoch: 1952/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004630\n",
      "Train Epoch: 1953/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004629\n",
      "Train Epoch: 1954/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004629\n",
      "Train Epoch: 1955/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004629\n",
      "Train Epoch: 1956/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004629\n",
      "Train Epoch: 1957/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004629\n",
      "Train Epoch: 1958/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004630\n",
      "Train Epoch: 1959/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004630\n",
      "Train Epoch: 1960/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004630\n",
      "Train Epoch: 1961/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004630\n",
      "Train Epoch: 1962/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004630\n",
      "Train Epoch: 1963/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004630\n",
      "Train Epoch: 1964/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004630\n",
      "Train Epoch: 1965/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004630\n",
      "Train Epoch: 1966/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004629\n",
      "Train Epoch: 1967/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004630\n",
      "Train Epoch: 1968/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004630\n",
      "Train Epoch: 1969/10000 (20%)\ttrain_Loss: 0.004311\tval_Loss: 0.004629\n",
      "Train Epoch: 1970/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004629\n",
      "Train Epoch: 1971/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004629\n",
      "Train Epoch: 1972/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004630\n",
      "Train Epoch: 1973/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004630\n",
      "Train Epoch: 1974/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004630\n",
      "Train Epoch: 1975/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004630\n",
      "Train Epoch: 1976/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004630\n",
      "Train Epoch: 1977/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004630\n",
      "Train Epoch: 1978/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004630\n",
      "Train Epoch: 1979/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004629\n",
      "Train Epoch: 1980/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004629\n",
      "Train Epoch: 1981/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004629\n",
      "Train Epoch: 1982/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004629\n",
      "Train Epoch: 1983/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1984/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004629\n",
      "Train Epoch: 1985/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004629\n",
      "Train Epoch: 1986/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004629\n",
      "Train Epoch: 1987/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004629\n",
      "Train Epoch: 1988/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004628\n",
      "Train Epoch: 1989/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004628\n",
      "Train Epoch: 1990/10000 (20%)\ttrain_Loss: 0.004310\tval_Loss: 0.004628\n",
      "Train Epoch: 1991/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 1992/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 1993/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 1994/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 1995/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 1996/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 1997/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 1998/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 1999/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 2000/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 2001/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 2002/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 2003/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 2004/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 2005/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 2006/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 2007/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 2008/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 2009/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 2010/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 2011/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 2012/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 2013/10000 (20%)\ttrain_Loss: 0.004309\tval_Loss: 0.004628\n",
      "Train Epoch: 2014/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2015/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2016/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2017/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2018/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2019/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2020/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2021/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2022/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2023/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2024/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2025/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2026/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2027/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2028/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2029/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2030/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2031/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2032/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2033/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2034/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2035/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2036/10000 (20%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 2037/10000 (20%)\ttrain_Loss: 0.004307\tval_Loss: 0.004628\n",
      "Train Epoch: 2038/10000 (20%)\ttrain_Loss: 0.004307\tval_Loss: 0.004628\n",
      "Train Epoch: 2039/10000 (20%)\ttrain_Loss: 0.004307\tval_Loss: 0.004628\n",
      "Train Epoch: 2040/10000 (20%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2041/10000 (20%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2042/10000 (20%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2043/10000 (20%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2044/10000 (20%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2045/10000 (20%)\ttrain_Loss: 0.004307\tval_Loss: 0.004628\n",
      "Train Epoch: 2046/10000 (20%)\ttrain_Loss: 0.004307\tval_Loss: 0.004628\n",
      "Train Epoch: 2047/10000 (20%)\ttrain_Loss: 0.004307\tval_Loss: 0.004628\n",
      "Train Epoch: 2048/10000 (20%)\ttrain_Loss: 0.004307\tval_Loss: 0.004628\n",
      "Train Epoch: 2049/10000 (20%)\ttrain_Loss: 0.004307\tval_Loss: 0.004628\n",
      "Train Epoch: 2050/10000 (20%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2051/10000 (20%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2052/10000 (21%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2053/10000 (21%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2054/10000 (21%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2055/10000 (21%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2056/10000 (21%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2057/10000 (21%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2058/10000 (21%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2059/10000 (21%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2060/10000 (21%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2061/10000 (21%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2062/10000 (21%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2063/10000 (21%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2064/10000 (21%)\ttrain_Loss: 0.004307\tval_Loss: 0.004629\n",
      "Train Epoch: 2065/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2066/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2067/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2068/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2069/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2070/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2071/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2072/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2073/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2074/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2075/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2076/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2077/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2078/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2079/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2080/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2081/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2082/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2083/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2084/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2085/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2086/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2087/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2088/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2089/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2090/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2091/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2092/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2093/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2094/10000 (21%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 2095/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2096/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2097/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2098/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2099/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2100/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2101/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2102/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2103/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2104/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2105/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2106/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2107/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2108/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2109/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2110/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2111/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2112/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2113/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2114/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2115/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2116/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2117/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2118/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2119/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2120/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 2121/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004627\n",
      "Train Epoch: 2122/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004627\n",
      "Train Epoch: 2123/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004627\n",
      "Train Epoch: 2124/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004627\n",
      "Train Epoch: 2125/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004627\n",
      "Train Epoch: 2126/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004627\n",
      "Train Epoch: 2127/10000 (21%)\ttrain_Loss: 0.004305\tval_Loss: 0.004627\n",
      "Train Epoch: 2128/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2129/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2130/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2131/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2132/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2133/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2134/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2135/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2136/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2137/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2138/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2139/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2140/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2141/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2142/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2143/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2144/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2145/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004626\n",
      "Train Epoch: 2146/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004626\n",
      "Train Epoch: 2147/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004626\n",
      "Train Epoch: 2148/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004626\n",
      "Train Epoch: 2149/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004626\n",
      "Train Epoch: 2150/10000 (21%)\ttrain_Loss: 0.004304\tval_Loss: 0.004626\n",
      "Train Epoch: 2151/10000 (22%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2152/10000 (22%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2153/10000 (22%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2154/10000 (22%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2155/10000 (22%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2156/10000 (22%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2157/10000 (22%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2158/10000 (22%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 2159/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2160/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2161/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2162/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2163/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2164/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2165/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2166/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2167/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2168/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2169/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2170/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004626\n",
      "Train Epoch: 2171/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004626\n",
      "Train Epoch: 2172/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004626\n",
      "Train Epoch: 2173/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004626\n",
      "Train Epoch: 2174/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2175/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2176/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2177/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2178/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2179/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2180/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004626\n",
      "Train Epoch: 2181/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004626\n",
      "Train Epoch: 2182/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2183/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2184/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2185/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2186/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2187/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2188/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2189/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2190/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2191/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2192/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2193/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2194/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2195/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2196/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2197/10000 (22%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 2198/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2199/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2200/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2201/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2202/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2203/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2204/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2205/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2206/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2207/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2208/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2209/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2210/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2211/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2212/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2213/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2214/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2215/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2216/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2217/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 2218/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2219/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2220/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2221/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2222/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2223/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2224/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2225/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2226/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2227/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2228/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2229/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2230/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2231/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2232/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2233/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2234/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2235/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2236/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2237/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2238/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2239/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2240/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2241/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2242/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2243/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2244/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2245/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2246/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2247/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2248/10000 (22%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 2249/10000 (22%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2250/10000 (22%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2251/10000 (22%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2252/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2253/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2254/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2255/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2256/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2257/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2258/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2259/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2260/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2261/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2262/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2263/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2264/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2265/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2266/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2267/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2268/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2269/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2270/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2271/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2272/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2273/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2274/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2275/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2276/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2277/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2278/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2279/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2280/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2281/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2282/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2283/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2284/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2285/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2286/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2287/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2288/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2289/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2290/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2291/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2292/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2293/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2294/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2295/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2296/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2297/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2298/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2299/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2300/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2301/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2302/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2303/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2304/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2305/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2306/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2307/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2308/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2309/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2310/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2311/10000 (23%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 2312/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2313/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2314/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2315/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2316/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2317/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2318/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2319/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2320/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2321/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2322/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2323/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2324/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2325/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2326/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004629\n",
      "Train Epoch: 2327/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004629\n",
      "Train Epoch: 2328/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2329/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2330/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2331/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2332/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2333/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2334/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2335/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2336/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2337/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2338/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2339/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2340/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2341/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2342/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2343/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2344/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2345/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004627\n",
      "Train Epoch: 2346/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2347/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2348/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2349/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2350/10000 (23%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2351/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2352/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2353/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2354/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2355/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004627\n",
      "Train Epoch: 2356/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004627\n",
      "Train Epoch: 2357/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004627\n",
      "Train Epoch: 2358/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004627\n",
      "Train Epoch: 2359/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2360/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2361/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2362/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2363/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2364/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2365/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2366/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2367/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2368/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2369/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2370/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2371/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004629\n",
      "Train Epoch: 2372/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2373/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2374/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2375/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2376/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2377/10000 (24%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 2378/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2379/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2380/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2381/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2382/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2383/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2384/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2385/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2386/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2387/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2388/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2389/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2390/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2391/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2392/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2393/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2394/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2395/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2396/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2397/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2398/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2399/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2400/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2401/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2402/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2403/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004629\n",
      "Train Epoch: 2404/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004629\n",
      "Train Epoch: 2405/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004629\n",
      "Train Epoch: 2406/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004629\n",
      "Train Epoch: 2407/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004629\n",
      "Train Epoch: 2408/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2409/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2410/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2411/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2412/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2413/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2414/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2415/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2416/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2417/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2418/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004629\n",
      "Train Epoch: 2419/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2420/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2421/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2422/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2423/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2424/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2425/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2426/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2427/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2428/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004629\n",
      "Train Epoch: 2429/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004629\n",
      "Train Epoch: 2430/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004629\n",
      "Train Epoch: 2431/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004629\n",
      "Train Epoch: 2432/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2433/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004628\n",
      "Train Epoch: 2434/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004627\n",
      "Train Epoch: 2435/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004626\n",
      "Train Epoch: 2436/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004626\n",
      "Train Epoch: 2437/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004626\n",
      "Train Epoch: 2438/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004626\n",
      "Train Epoch: 2439/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004626\n",
      "Train Epoch: 2440/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004625\n",
      "Train Epoch: 2441/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004625\n",
      "Train Epoch: 2442/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004625\n",
      "Train Epoch: 2443/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004625\n",
      "Train Epoch: 2444/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004625\n",
      "Train Epoch: 2445/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004625\n",
      "Train Epoch: 2446/10000 (24%)\ttrain_Loss: 0.004299\tval_Loss: 0.004625\n",
      "Train Epoch: 2447/10000 (24%)\ttrain_Loss: 0.004298\tval_Loss: 0.004625\n",
      "Train Epoch: 2448/10000 (24%)\ttrain_Loss: 0.004298\tval_Loss: 0.004625\n",
      "Train Epoch: 2449/10000 (24%)\ttrain_Loss: 0.004298\tval_Loss: 0.004625\n",
      "Train Epoch: 2450/10000 (24%)\ttrain_Loss: 0.004298\tval_Loss: 0.004625\n",
      "Train Epoch: 2451/10000 (24%)\ttrain_Loss: 0.004298\tval_Loss: 0.004625\n",
      "Train Epoch: 2452/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004625\n",
      "Train Epoch: 2453/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004625\n",
      "Train Epoch: 2454/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004625\n",
      "Train Epoch: 2455/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 2456/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 2457/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 2458/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 2459/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 2460/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 2461/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 2462/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 2463/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2464/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2465/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2466/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2467/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2468/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2469/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2470/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2471/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2472/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2473/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2474/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2475/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2476/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2477/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2478/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2479/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 2480/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 2481/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 2482/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 2483/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 2484/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2485/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2486/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2487/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2488/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2489/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2490/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2491/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2492/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 2493/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 2494/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 2495/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 2496/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2497/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2498/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2499/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2500/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2501/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2502/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2503/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2504/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2505/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2506/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2507/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2508/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2509/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2510/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2511/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2512/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2513/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2514/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2515/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2516/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2517/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2518/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2519/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2520/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2521/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2522/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2523/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2524/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2525/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2526/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2527/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2528/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2529/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2530/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2531/10000 (25%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 2532/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2533/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2534/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2535/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2536/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2537/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2538/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2539/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2540/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2541/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2542/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2543/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2544/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2545/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2546/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2547/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2548/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2549/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2550/10000 (25%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2551/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2552/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2553/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2554/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2555/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2556/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2557/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2558/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2559/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2560/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2561/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2562/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2563/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2564/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2565/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2566/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2567/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2568/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2569/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2570/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2571/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2572/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2573/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2574/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2575/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2576/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2577/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2578/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2579/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2580/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2581/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2582/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2583/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2584/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2585/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2586/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2587/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2588/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2589/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2590/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2591/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2592/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2593/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2594/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2595/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2596/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 2597/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2598/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2599/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2600/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2601/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2602/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2603/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2604/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2605/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2606/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2607/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2608/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2609/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2610/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2611/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2612/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2613/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2614/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2615/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2616/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2617/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2618/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2619/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2620/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2621/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2622/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2623/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2624/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2625/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2626/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2627/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2628/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2629/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2630/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2631/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2632/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2633/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2634/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2635/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2636/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2637/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2638/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2639/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2640/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2641/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2642/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2643/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2644/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2645/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2646/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2647/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2648/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2649/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2650/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2651/10000 (26%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2652/10000 (27%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2653/10000 (27%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2654/10000 (27%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2655/10000 (27%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2656/10000 (27%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2657/10000 (27%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2658/10000 (27%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2659/10000 (27%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2660/10000 (27%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 2661/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2662/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004628\n",
      "Train Epoch: 2663/10000 (27%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2664/10000 (27%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2665/10000 (27%)\ttrain_Loss: 0.004297\tval_Loss: 0.004628\n",
      "Train Epoch: 2666/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004628\n",
      "Train Epoch: 2667/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2668/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2669/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2670/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2671/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2672/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2673/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2674/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2675/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2676/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2677/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2678/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2679/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2680/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2681/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2682/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2683/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2684/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2685/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2686/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2687/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2688/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2689/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2690/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2691/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2692/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2693/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2694/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2695/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2696/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2697/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2698/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2699/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2700/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2701/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2702/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2703/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2704/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2705/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2706/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2707/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2708/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2709/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2710/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2711/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2712/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2713/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2714/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2715/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2716/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2717/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2718/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2719/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2720/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2721/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2722/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2723/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2724/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2725/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2726/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2727/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2728/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2729/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2730/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2731/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2732/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2733/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2734/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2735/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004629\n",
      "Train Epoch: 2736/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2737/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2738/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2739/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2740/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2741/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2742/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2743/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2744/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2745/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2746/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2747/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2748/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2749/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2750/10000 (27%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2751/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2752/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2753/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2754/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2755/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2756/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2757/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2758/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2759/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2760/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2761/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2762/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2763/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2764/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2765/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2766/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2767/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2768/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2769/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2770/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2771/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2772/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2773/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2774/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2775/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2776/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2777/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2778/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2779/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2780/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2781/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2782/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2783/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2784/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2785/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 2786/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2787/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2788/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2789/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2790/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2791/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2792/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2793/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2794/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2795/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2796/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2797/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2798/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2799/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2800/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2801/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2802/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2803/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2804/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2805/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2806/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2807/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2808/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2809/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2810/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2811/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2812/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2813/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2814/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2815/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2816/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2817/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2818/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2819/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2820/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2821/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2822/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2823/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2824/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2825/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2826/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2827/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2828/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2829/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2830/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2831/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2832/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2833/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2834/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2835/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2836/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2837/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2838/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2839/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2840/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2841/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2842/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2843/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2844/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2845/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2846/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2847/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2848/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2849/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2850/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2851/10000 (28%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2852/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2853/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2854/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2855/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2856/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2857/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2858/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2859/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2860/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2861/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2862/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2863/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2864/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2865/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2866/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2867/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2868/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2869/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2870/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2871/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2872/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2873/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2874/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2875/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2876/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2877/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2878/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2879/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2880/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2881/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2882/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004631\n",
      "Train Epoch: 2883/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2884/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2885/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2886/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2887/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2888/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2889/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2890/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2891/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2892/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2893/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2894/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2895/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2896/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2897/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2898/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2899/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2900/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2901/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2902/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2903/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2904/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2905/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2906/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2907/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2908/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2909/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2910/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2911/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2912/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2913/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2914/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2915/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2916/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2917/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2918/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2919/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2920/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2921/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2922/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2923/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2924/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2925/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2926/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2927/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2928/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2929/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2930/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2931/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2932/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2933/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2934/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2935/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004632\n",
      "Train Epoch: 2936/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2937/10000 (29%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 2938/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004634\n",
      "Train Epoch: 2939/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004634\n",
      "Train Epoch: 2940/10000 (29%)\ttrain_Loss: 0.004296\tval_Loss: 0.004633\n",
      "Train Epoch: 2941/10000 (29%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2942/10000 (29%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2943/10000 (29%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2944/10000 (29%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 2945/10000 (29%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2946/10000 (29%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2947/10000 (29%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2948/10000 (29%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2949/10000 (29%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2950/10000 (29%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2951/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2952/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2953/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004632\n",
      "Train Epoch: 2954/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2955/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2956/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2957/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2958/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004632\n",
      "Train Epoch: 2959/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004632\n",
      "Train Epoch: 2960/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2961/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2962/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2963/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2964/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2965/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2966/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2967/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2968/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004632\n",
      "Train Epoch: 2969/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004632\n",
      "Train Epoch: 2970/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2971/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2972/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 2973/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2974/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2975/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2976/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2977/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2978/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 2979/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 2980/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2981/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2982/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2983/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2984/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 2985/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 2986/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2987/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2988/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2989/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2990/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2991/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2992/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004632\n",
      "Train Epoch: 2993/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004632\n",
      "Train Epoch: 2994/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2995/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2996/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 2997/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 2998/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 2999/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3000/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3001/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3002/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3003/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3004/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3005/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3006/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004632\n",
      "Train Epoch: 3007/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3008/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3009/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3010/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3011/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3012/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3013/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3014/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3015/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3016/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3017/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3018/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3019/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3020/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3021/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3022/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3023/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3024/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3025/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3026/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3027/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3028/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3029/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3030/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3031/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3032/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3033/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3034/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3035/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3036/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3037/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3038/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3039/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3040/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3041/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3042/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3043/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3044/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3045/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3046/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3047/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3048/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3049/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3050/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3051/10000 (30%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3052/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004632\n",
      "Train Epoch: 3053/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004632\n",
      "Train Epoch: 3054/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3055/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3056/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3057/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3058/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3059/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3060/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3061/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3062/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3063/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3064/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3065/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3066/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3067/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3068/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3069/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3070/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3071/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3072/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3073/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3074/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3075/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3076/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3077/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3078/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3079/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3080/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3081/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3082/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3083/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3084/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3085/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3086/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3087/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3088/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3089/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3090/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3091/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3092/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3093/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3094/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3095/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3096/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3097/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3098/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3099/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3100/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3101/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3102/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3103/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3104/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3105/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3106/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3107/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3108/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3109/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3110/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3111/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3112/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3113/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3114/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3115/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3116/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3117/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3118/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3119/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3120/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3121/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3122/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3123/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3124/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3125/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3126/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3127/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3128/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3129/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3130/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3131/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3132/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3133/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3134/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3135/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3136/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3137/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3138/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3139/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3140/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3141/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3142/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3143/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3144/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3145/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3146/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3147/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3148/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3149/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3150/10000 (31%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3151/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3152/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3153/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3154/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3155/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3156/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3157/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3158/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3159/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3160/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3161/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3162/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3163/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3164/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3165/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3166/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3167/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3168/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3169/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3170/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3171/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3172/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3173/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3174/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3175/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3176/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3177/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3178/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3179/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3180/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3181/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3182/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3183/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3184/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3185/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3186/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3187/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3188/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3189/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3190/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3191/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3192/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3193/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3194/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3195/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3196/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3197/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3198/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3199/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3200/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3201/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3202/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3203/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3204/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3205/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3206/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3207/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3208/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3209/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3210/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3211/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3212/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3213/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3214/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3215/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3216/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3217/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3218/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3219/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3220/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3221/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3222/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3223/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3224/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3225/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3226/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3227/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3228/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3229/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3230/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3231/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3232/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3233/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3234/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3235/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3236/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3237/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3238/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3239/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3240/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3241/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3242/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3243/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3244/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3245/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3246/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3247/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3248/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3249/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3250/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3251/10000 (32%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3252/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3253/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3254/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3255/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3256/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3257/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3258/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3259/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3260/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3261/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3262/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3263/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3264/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3265/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3266/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3267/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3268/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3269/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3270/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3271/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3272/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3273/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3274/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3275/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3276/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3277/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3278/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3279/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3280/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3281/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3282/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3283/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3284/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3285/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3286/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3287/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3288/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3289/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3290/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3291/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3292/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3293/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3294/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3295/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3296/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3297/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3298/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3299/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3300/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3301/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3302/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3303/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3304/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3305/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3306/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3307/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3308/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3309/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3310/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3311/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3312/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3313/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3314/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3315/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3316/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3317/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3318/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3319/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3320/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3321/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3322/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3323/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3324/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3325/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3326/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3327/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3328/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3329/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3330/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3331/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3332/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3333/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3334/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3335/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3336/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3337/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3338/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 3339/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3340/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3341/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3342/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3343/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3344/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3345/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3346/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3347/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3348/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3349/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3350/10000 (33%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3351/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3352/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3353/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3354/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3355/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3356/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3357/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3358/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3359/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3360/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3361/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3362/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3363/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3364/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3365/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3366/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3367/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3368/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3369/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3370/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3371/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3372/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3373/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3374/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3375/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3376/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3377/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3378/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3379/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3380/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3381/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3382/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3383/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3384/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3385/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3386/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3387/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3388/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3389/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004636\n",
      "Train Epoch: 3390/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3391/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3392/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3393/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3394/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3395/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3396/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3397/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3398/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3399/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3400/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3401/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3402/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3403/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3404/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3405/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3406/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3407/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3408/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3409/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3410/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3411/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3412/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3413/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3414/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004636\n",
      "Train Epoch: 3415/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3416/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3417/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3418/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3419/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3420/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3421/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3422/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3423/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3424/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3425/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3426/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3427/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3428/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3429/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3430/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3431/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3432/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3433/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3434/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3435/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3436/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3437/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3438/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3439/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3440/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3441/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3442/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3443/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3444/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3445/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3446/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3447/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3448/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3449/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3450/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3451/10000 (34%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3452/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3453/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3454/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3455/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004636\n",
      "Train Epoch: 3456/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004636\n",
      "Train Epoch: 3457/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3458/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3459/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3460/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3461/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3462/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3463/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3464/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3465/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3466/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3467/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3468/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3469/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3470/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3471/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3472/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3473/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3474/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3475/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3476/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3477/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3478/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3479/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3480/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3481/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3482/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3483/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3484/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3485/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3486/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3487/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3488/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3489/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3490/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3491/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3492/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3493/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3494/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3495/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3496/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3497/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3498/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3499/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3500/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3501/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3502/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3503/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3504/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3505/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3506/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3507/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3508/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3509/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3510/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3511/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3512/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3513/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3514/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3515/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3516/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3517/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3518/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3519/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3520/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3521/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3522/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3523/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3524/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3525/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3526/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3527/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3528/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3529/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3530/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3531/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3532/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3533/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3534/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3535/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3536/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3537/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3538/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3539/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3540/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3541/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3542/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3543/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3544/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3545/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3546/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3547/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3548/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3549/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004636\n",
      "Train Epoch: 3550/10000 (35%)\ttrain_Loss: 0.004295\tval_Loss: 0.004636\n",
      "Train Epoch: 3551/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3552/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3553/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3554/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3555/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3556/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004636\n",
      "Train Epoch: 3557/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3558/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3559/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3560/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3561/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3562/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3563/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3564/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3565/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3566/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3567/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3568/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3569/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3570/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3571/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3572/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3573/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3574/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3575/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3576/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3577/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3578/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3579/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3580/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3581/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3582/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3583/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3584/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004636\n",
      "Train Epoch: 3585/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004636\n",
      "Train Epoch: 3586/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3587/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3588/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3589/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3590/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3591/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3592/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3593/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3594/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3595/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3596/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3597/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3598/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3599/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3600/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3601/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3602/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3603/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3604/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3605/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3606/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3607/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3608/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3609/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3610/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3611/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3612/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3613/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004636\n",
      "Train Epoch: 3614/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004636\n",
      "Train Epoch: 3615/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3616/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3617/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3618/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3619/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3620/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3621/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3622/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3623/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004636\n",
      "Train Epoch: 3624/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3625/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3626/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3627/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3628/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3629/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3630/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3631/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3632/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3633/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3634/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3635/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3636/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3637/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3638/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3639/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3640/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3641/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3642/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3643/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3644/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3645/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3646/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004636\n",
      "Train Epoch: 3647/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004636\n",
      "Train Epoch: 3648/10000 (36%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3649/10000 (36%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3650/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3651/10000 (36%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3652/10000 (37%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3653/10000 (37%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3654/10000 (37%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3655/10000 (37%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3656/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3657/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3658/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3659/10000 (37%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3660/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3661/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3662/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3663/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3664/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3665/10000 (37%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 3666/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3667/10000 (37%)\ttrain_Loss: 0.004295\tval_Loss: 0.004636\n",
      "Train Epoch: 3668/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3669/10000 (37%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3670/10000 (37%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3671/10000 (37%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 3672/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3673/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3674/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3675/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3676/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3677/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3678/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3679/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3680/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3681/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3682/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3683/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3684/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3685/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3686/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3687/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3688/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3689/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3690/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3691/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3692/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3693/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3694/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3695/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3696/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3697/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3698/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3699/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3700/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3701/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3702/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3703/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3704/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3705/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3706/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3707/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3708/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3709/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3710/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3711/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3712/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3713/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3714/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3715/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3716/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3717/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3718/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3719/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3720/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3721/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3722/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3723/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3724/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3725/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3726/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3727/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3728/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3729/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3730/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3731/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3732/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3733/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3734/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3735/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3736/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3737/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3738/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3739/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3740/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3741/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3742/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3743/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3744/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3745/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3746/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3747/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3748/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3749/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3750/10000 (37%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3751/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3752/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3753/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3754/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3755/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3756/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3757/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3758/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3759/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3760/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3761/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3762/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3763/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3764/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3765/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3766/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3767/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3768/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3769/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3770/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3771/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3772/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3773/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3774/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3775/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3776/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3777/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3778/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3779/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3780/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3781/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3782/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3783/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3784/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3785/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3786/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3787/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3788/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3789/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3790/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3791/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3792/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3793/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3794/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3795/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3796/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3797/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3798/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3799/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3800/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3801/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3802/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3803/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3804/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3805/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3806/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3807/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3808/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3809/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3810/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3811/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3812/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3813/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3814/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3815/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3816/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3817/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3818/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3819/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3820/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3821/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3822/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3823/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3824/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3825/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3826/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3827/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3828/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3829/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3830/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3831/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3832/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3833/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3834/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3835/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3836/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3837/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3838/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3839/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3840/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3841/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3842/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3843/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3844/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3845/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3846/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3847/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3848/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3849/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3850/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3851/10000 (38%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3852/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3853/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3854/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3855/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3856/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3857/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3858/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3859/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3860/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3861/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3862/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3863/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3864/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3865/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3866/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3867/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3868/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3869/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3870/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3871/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3872/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3873/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3874/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3875/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3876/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3877/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3878/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3879/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3880/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3881/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3882/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3883/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3884/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3885/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3886/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3887/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3888/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3889/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3890/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3891/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3892/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3893/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3894/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3895/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3896/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3897/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3898/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3899/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3900/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3901/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3902/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3903/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3904/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3905/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3906/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3907/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3908/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3909/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3910/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3911/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3912/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3913/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3914/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3915/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3916/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3917/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3918/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3919/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3920/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3921/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3922/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3923/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3924/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3925/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3926/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3927/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3928/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3929/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3930/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3931/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3932/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3933/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3934/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3935/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3936/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3937/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3938/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3939/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3940/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3941/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3942/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3943/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3944/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3945/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3946/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3947/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3948/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3949/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3950/10000 (39%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3951/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3952/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3953/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3954/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3955/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3956/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3957/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3958/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3959/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3960/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3961/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3962/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3963/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3964/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3965/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3966/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3967/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3968/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3969/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3970/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3971/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3972/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 3973/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3974/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3975/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3976/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3977/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3978/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3979/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3980/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3981/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3982/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3983/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3984/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3985/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3986/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3987/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3988/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3989/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3990/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3991/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3992/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3993/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3994/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3995/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3996/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 3997/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3998/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 3999/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4000/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4001/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4002/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4003/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4004/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4005/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4006/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4007/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4008/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4009/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4010/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4011/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4012/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4013/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4014/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4015/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4016/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4017/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4018/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4019/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4020/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4021/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4022/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4023/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4024/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4025/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4026/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4027/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4028/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4029/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4030/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4031/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4032/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4033/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4034/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4035/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4036/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4037/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4038/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4039/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4040/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4041/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4042/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4043/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4044/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4045/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4046/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4047/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4048/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4049/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4050/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4051/10000 (40%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4052/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4053/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4054/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4055/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4056/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4057/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4058/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4059/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4060/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4061/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4062/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4063/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4064/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4065/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4066/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4067/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4068/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4069/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4070/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4071/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4072/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4073/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4074/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4075/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4076/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4077/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4078/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4079/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4080/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4081/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4082/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4083/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4084/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4085/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4086/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4087/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4088/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4089/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4090/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4091/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4092/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4093/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4094/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4095/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4096/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4097/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4098/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4099/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4100/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4101/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4102/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4103/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4104/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4105/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4106/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4107/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4108/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4109/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4110/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4111/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4112/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4113/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4114/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4115/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4116/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4117/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4118/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4119/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4120/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4121/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4122/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4123/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4124/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4125/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4126/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4127/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4128/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4129/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4130/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4131/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4132/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4133/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4134/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4135/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4136/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4137/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4138/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4139/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4140/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4141/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4142/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4143/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4144/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4145/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4146/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4147/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4148/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4149/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4150/10000 (41%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4151/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4152/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4153/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4154/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4155/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4156/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4157/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4158/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4159/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4160/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4161/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4162/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4163/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4164/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4165/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4166/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4167/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4168/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4169/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4170/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4171/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4172/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4173/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4174/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4175/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4176/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4177/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4178/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4179/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4180/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4181/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4182/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4183/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4184/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4185/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4186/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4187/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4188/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4189/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4190/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4191/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4192/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4193/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4194/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4195/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4196/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4197/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4198/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4199/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4200/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4201/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4202/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4203/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4204/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4205/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4206/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4207/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4208/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4209/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4210/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4211/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4212/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4213/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4214/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4215/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4216/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4217/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4218/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4219/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4220/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4221/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4222/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4223/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4224/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4225/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4226/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4227/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4228/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4229/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4230/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4231/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4232/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4233/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4234/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4235/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4236/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4237/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4238/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4239/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4240/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4241/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4242/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4243/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4244/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4245/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4246/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4247/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4248/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4249/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4250/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4251/10000 (42%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4252/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4253/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4254/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4255/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4256/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4257/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4258/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4259/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4260/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4261/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4262/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4263/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4264/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4265/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4266/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4267/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4268/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4269/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4270/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4271/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4272/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4273/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4274/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4275/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4276/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4277/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4278/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4279/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4280/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4281/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4282/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4283/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4284/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4285/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4286/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4287/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4288/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4289/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4290/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4291/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4292/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4293/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4294/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4295/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4296/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4297/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4298/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4299/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4300/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4301/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4302/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4303/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4304/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4305/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4306/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4307/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4308/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4309/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4310/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4311/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4312/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4313/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4314/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4315/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4316/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4317/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4318/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4319/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4320/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4321/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4322/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4323/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4324/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4325/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4326/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4327/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4328/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4329/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4330/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4331/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4332/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4333/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4334/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4335/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4336/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4337/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4338/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4339/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4340/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4341/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4342/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4343/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4344/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4345/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4346/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4347/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4348/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4349/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4350/10000 (43%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4351/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4352/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4353/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4354/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4355/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4356/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4357/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4358/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4359/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4360/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4361/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4362/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4363/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4364/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4365/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4366/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4367/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4368/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4369/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4370/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4371/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4372/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4373/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4374/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4375/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4376/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4377/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4378/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4379/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4380/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4381/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4382/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4383/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4384/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4385/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4386/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4387/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4388/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4389/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4390/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4391/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4392/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4393/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4394/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4395/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4396/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4397/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4398/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4399/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4400/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4401/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4402/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4403/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4404/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4405/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4406/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4407/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4408/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4409/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4410/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4411/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4412/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4413/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4414/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4415/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4416/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4417/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4418/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4419/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4420/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4421/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4422/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4423/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4424/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4425/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4426/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4427/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4428/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4429/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4430/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4431/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4432/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4433/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4434/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4435/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4436/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4437/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4438/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4439/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4440/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4441/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4442/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4443/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4444/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4445/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4446/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4447/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4448/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4449/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4450/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4451/10000 (44%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4452/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4453/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4454/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4455/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4456/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4457/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4458/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4459/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4460/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4461/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4462/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4463/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4464/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4465/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4466/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4467/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4468/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4469/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4470/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4471/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4472/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4473/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4474/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4475/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4476/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4477/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4478/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4479/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4480/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4481/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4482/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4483/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4484/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4485/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4486/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4487/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4488/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4489/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4490/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4491/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4492/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4493/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4494/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4495/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4496/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4497/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4498/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4499/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4500/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4501/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4502/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4503/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4504/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4505/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4506/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4507/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4508/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4509/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4510/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4511/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4512/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4513/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4514/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4515/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4516/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4517/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4518/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4519/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4520/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4521/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4522/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4523/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4524/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4525/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4526/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4527/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4528/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4529/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4530/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4531/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4532/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4533/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4534/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4535/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4536/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4537/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4538/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4539/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4540/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 4541/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4542/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4543/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4544/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4545/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4546/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4547/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4548/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4549/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4550/10000 (45%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4551/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4552/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4553/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4554/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4555/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4556/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4557/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4558/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4559/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4560/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4561/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4562/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4563/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4564/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4565/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4566/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4567/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4568/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4569/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4570/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4571/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4572/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4573/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4574/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4575/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4576/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4577/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4578/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4579/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4580/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4581/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4582/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4583/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4584/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4585/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4586/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4587/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4588/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4589/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4590/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4591/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4592/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4593/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4594/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4595/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4596/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4597/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4598/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4599/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4600/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4601/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4602/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4603/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4604/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4605/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4606/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4607/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4608/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4609/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4610/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4611/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4612/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4613/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4614/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4615/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4616/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4617/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4618/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4619/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4620/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4621/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4622/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4623/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4624/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4625/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4626/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4627/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4628/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4629/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4630/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4631/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4632/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4633/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4634/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4635/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4636/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4637/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4638/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4639/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4640/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4641/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4642/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4643/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4644/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4645/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4646/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4647/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4648/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4649/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4650/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4651/10000 (46%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4652/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4653/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4654/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4655/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4656/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4657/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4658/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4659/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4660/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4661/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4662/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4663/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4664/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4665/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4666/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4667/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4668/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4669/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4670/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4671/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4672/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4673/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4674/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4675/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4676/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4677/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4678/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4679/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4680/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4681/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4682/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4683/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4684/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4685/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4686/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4687/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4688/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4689/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4690/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4691/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4692/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4693/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4694/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4695/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4696/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4697/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4698/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4699/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4700/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4701/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4702/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4703/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4704/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4705/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4706/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4707/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4708/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4709/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4710/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4711/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4712/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4713/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4714/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4715/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4716/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4717/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4718/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4719/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4720/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4721/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4722/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4723/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4724/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4725/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4726/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4727/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4728/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4729/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4730/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4731/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4732/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4733/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4734/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4735/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4736/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4737/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4738/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4739/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4740/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 4741/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4742/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4743/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4744/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4745/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4746/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4747/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4748/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4749/10000 (47%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4750/10000 (47%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4751/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4752/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4753/10000 (48%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4754/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4755/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4756/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4757/10000 (48%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4758/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4759/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4760/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4761/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004636\n",
      "Train Epoch: 4762/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4763/10000 (48%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 4764/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4765/10000 (48%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 4766/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4767/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4768/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4769/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4770/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4771/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4772/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4773/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4774/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4775/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4776/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4777/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4778/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4779/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4780/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4781/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4782/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4783/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4784/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4785/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4786/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4787/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4788/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4789/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4790/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4791/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4792/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4793/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4794/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4795/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4796/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4797/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4798/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4799/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4800/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4801/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4802/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4803/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4804/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4805/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4806/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4807/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4808/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4809/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4810/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4811/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4812/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4813/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4814/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4815/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4816/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4817/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4818/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4819/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4820/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4821/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4822/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4823/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4824/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4825/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4826/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4827/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4828/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4829/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4830/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4831/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4832/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4833/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4834/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4835/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4836/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4837/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4838/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4839/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4840/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4841/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4842/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4843/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4844/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4845/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4846/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4847/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4848/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4849/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4850/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 4851/10000 (48%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 4852/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4853/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4854/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4855/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4856/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4857/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4858/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4859/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4860/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4861/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4862/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4863/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4864/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4865/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4866/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4867/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4868/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4869/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4870/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4871/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4872/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4873/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4874/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4875/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4876/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4877/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4878/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4879/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4880/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4881/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4882/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4883/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4884/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4885/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4886/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4887/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4888/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4889/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4890/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4891/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4892/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4893/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4894/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4895/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4896/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4897/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4898/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4899/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4900/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4901/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4902/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4903/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4904/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4905/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4906/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4907/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4908/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4909/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4910/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4911/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4912/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4913/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4914/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4915/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4916/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4917/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4918/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4919/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4920/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4921/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4922/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4923/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4924/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4925/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4926/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4927/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4928/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4929/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4930/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4931/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4932/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4933/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4934/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4935/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4936/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4937/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4938/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4939/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4940/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4941/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4942/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4943/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4944/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4945/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4946/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4947/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4948/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4949/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4950/10000 (49%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4951/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4952/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4953/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4954/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4955/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4956/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4957/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4958/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4959/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4960/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4961/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4962/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4963/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4964/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4965/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4966/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4967/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4968/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4969/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4970/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4971/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4972/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4973/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4974/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4975/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4976/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4977/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4978/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4979/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4980/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4981/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4982/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4983/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4984/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4985/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4986/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4987/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4988/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4989/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4990/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4991/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4992/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4993/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 4994/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4995/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4996/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4997/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 4998/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 4999/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5000/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5001/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5002/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5003/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5004/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5005/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5006/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5007/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5008/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5009/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5010/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5011/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5012/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5013/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5014/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5015/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5016/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5017/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5018/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5019/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5020/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5021/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5022/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5023/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5024/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5025/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5026/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5027/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5028/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5029/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5030/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5031/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5032/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5033/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5034/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5035/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5036/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5037/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5038/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5039/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5040/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5041/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5042/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5043/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5044/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5045/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5046/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5047/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5048/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5049/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5050/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5051/10000 (50%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5052/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5053/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5054/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5055/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5056/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5057/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5058/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5059/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5060/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5061/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5062/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5063/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5064/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5065/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5066/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5067/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5068/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5069/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5070/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5071/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5072/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5073/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5074/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5075/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5076/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5077/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5078/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5079/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5080/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5081/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5082/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5083/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5084/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5085/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5086/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5087/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5088/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5089/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5090/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5091/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5092/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5093/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5094/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5095/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5096/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5097/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5098/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5099/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5100/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5101/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5102/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5103/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5104/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5105/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5106/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5107/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5108/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5109/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5110/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5111/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5112/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5113/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5114/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5115/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5116/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5117/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5118/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5119/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5120/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5121/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5122/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5123/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5124/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5125/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5126/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5127/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5128/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5129/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5130/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5131/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5132/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5133/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5134/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5135/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5136/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5137/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5138/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5139/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5140/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5141/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5142/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5143/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5144/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5145/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5146/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5147/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5148/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5149/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5150/10000 (51%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5151/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5152/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5153/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5154/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5155/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5156/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5157/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5158/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5159/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5160/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5161/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5162/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5163/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5164/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5165/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5166/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5167/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5168/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5169/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5170/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5171/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5172/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5173/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5174/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5175/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5176/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5177/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5178/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5179/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5180/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5181/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5182/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5183/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5184/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5185/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5186/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5187/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5188/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5189/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5190/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5191/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5192/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5193/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5194/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5195/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5196/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5197/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5198/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5199/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5200/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5201/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5202/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5203/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5204/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5205/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5206/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5207/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5208/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5209/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5210/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5211/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5212/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5213/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5214/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5215/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5216/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5217/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5218/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5219/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5220/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5221/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5222/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5223/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5224/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5225/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5226/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5227/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5228/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5229/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5230/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5231/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5232/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5233/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5234/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5235/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5236/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5237/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5238/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5239/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5240/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5241/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5242/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5243/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5244/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5245/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5246/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5247/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5248/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5249/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5250/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5251/10000 (52%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5252/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5253/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5254/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5255/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5256/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5257/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5258/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5259/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5260/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5261/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5262/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5263/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5264/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5265/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5266/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5267/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5268/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5269/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5270/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5271/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5272/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5273/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5274/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5275/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5276/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5277/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5278/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5279/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5280/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5281/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5282/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5283/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5284/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5285/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5286/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5287/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5288/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5289/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5290/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5291/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5292/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5293/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5294/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5295/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5296/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5297/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5298/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5299/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5300/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5301/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5302/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5303/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5304/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5305/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5306/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5307/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5308/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5309/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5310/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5311/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5312/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5313/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5314/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5315/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5316/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5317/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5318/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5319/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5320/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5321/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5322/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5323/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5324/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5325/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5326/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5327/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5328/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5329/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5330/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5331/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5332/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5333/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5334/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5335/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5336/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5337/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5338/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5339/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5340/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5341/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5342/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5343/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5344/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5345/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5346/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5347/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5348/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5349/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5350/10000 (53%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5351/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5352/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5353/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5354/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5355/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5356/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5357/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5358/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5359/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5360/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5361/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5362/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5363/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5364/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5365/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5366/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5367/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5368/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5369/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5370/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5371/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5372/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5373/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5374/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5375/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5376/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5377/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5378/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5379/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5380/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5381/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5382/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5383/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5384/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5385/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5386/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5387/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5388/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5389/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5390/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5391/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5392/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5393/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5394/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5395/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5396/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5397/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5398/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5399/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5400/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5401/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5402/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5403/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5404/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5405/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5406/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5407/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5408/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5409/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5410/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5411/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5412/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5413/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5414/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5415/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5416/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5417/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5418/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5419/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5420/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5421/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5422/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5423/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5424/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5425/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5426/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5427/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5428/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5429/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5430/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5431/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5432/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5433/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5434/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5435/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5436/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5437/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5438/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5439/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5440/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5441/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5442/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5443/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5444/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5445/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5446/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5447/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5448/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5449/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5450/10000 (54%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5451/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5452/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5453/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5454/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5455/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5456/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5457/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5458/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5459/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5460/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5461/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004631\n",
      "Train Epoch: 5462/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5463/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5464/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5465/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5466/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5467/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5468/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5469/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5470/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5471/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5472/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5473/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5474/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5475/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5476/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5477/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5478/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5479/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5480/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5481/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5482/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5483/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5484/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5485/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5486/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5487/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5488/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5489/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5490/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5491/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5492/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5493/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5494/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5495/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004631\n",
      "Train Epoch: 5496/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004631\n",
      "Train Epoch: 5497/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004631\n",
      "Train Epoch: 5498/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5499/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5500/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5501/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5502/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5503/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5504/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5505/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5506/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5507/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5508/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5509/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5510/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5511/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5512/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5513/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5514/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5515/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5516/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5517/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5518/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004631\n",
      "Train Epoch: 5519/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004631\n",
      "Train Epoch: 5520/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5521/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5522/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5523/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5524/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5525/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5526/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5527/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5528/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5529/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5530/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5531/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5532/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5533/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5534/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5535/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5536/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5537/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5538/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5539/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5540/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5541/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5542/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5543/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5544/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5545/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5546/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5547/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5548/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5549/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5550/10000 (55%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5551/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5552/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5553/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5554/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5555/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5556/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5557/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5558/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5559/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5560/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5561/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5562/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5563/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5564/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5565/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5566/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5567/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5568/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5569/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5570/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5571/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5572/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5573/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5574/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5575/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5576/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5577/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5578/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5579/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5580/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5581/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5582/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5583/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5584/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 5585/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5586/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5587/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5588/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5589/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5590/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5591/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5592/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5593/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5594/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5595/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5596/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5597/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5598/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5599/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5600/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5601/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5602/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5603/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5604/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5605/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5606/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5607/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5608/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5609/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5610/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5611/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5612/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5613/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5614/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5615/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5616/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5617/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 5618/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5619/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5620/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5621/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5622/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 5623/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5624/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5625/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5626/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5627/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5628/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5629/10000 (56%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 5630/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5631/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5632/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5633/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5634/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5635/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5636/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5637/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5638/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5639/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5640/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5641/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5642/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5643/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5644/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5645/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5646/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5647/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5648/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5649/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5650/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5651/10000 (56%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5652/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5653/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5654/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5655/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5656/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5657/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5658/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5659/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5660/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5661/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5662/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5663/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5664/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5665/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5666/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5667/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5668/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5669/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5670/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5671/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5672/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5673/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5674/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5675/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5676/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5677/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5678/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5679/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5680/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5681/10000 (57%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 5682/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5683/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5684/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5685/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5686/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5687/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5688/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5689/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5690/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5691/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5692/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5693/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5694/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5695/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5696/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5697/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5698/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5699/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5700/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5701/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5702/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5703/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5704/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5705/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5706/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5707/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5708/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5709/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5710/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5711/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5712/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5713/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5714/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5715/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5716/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5717/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5718/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5719/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5720/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5721/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5722/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5723/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5724/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5725/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5726/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5727/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5728/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5729/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5730/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5731/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5732/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5733/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5734/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5735/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5736/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5737/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5738/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5739/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5740/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5741/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5742/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5743/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5744/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5745/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5746/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5747/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5748/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5749/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5750/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5751/10000 (57%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5752/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5753/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5754/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5755/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5756/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 5757/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 5758/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5759/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5760/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5761/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5762/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5763/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5764/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5765/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5766/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5767/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5768/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5769/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5770/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5771/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5772/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5773/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5774/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5775/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5776/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5777/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5778/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5779/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5780/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5781/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5782/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5783/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5784/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5785/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 5786/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5787/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5788/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5789/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5790/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5791/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5792/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5793/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5794/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5795/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5796/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5797/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5798/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5799/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5800/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5801/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5802/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5803/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5804/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5805/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5806/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5807/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5808/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5809/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5810/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5811/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5812/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5813/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5814/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5815/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5816/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5817/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5818/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5819/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5820/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5821/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5822/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5823/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5824/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5825/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5826/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5827/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5828/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5829/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5830/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5831/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5832/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5833/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5834/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5835/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5836/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5837/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5838/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5839/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5840/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5841/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5842/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5843/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5844/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5845/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5846/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5847/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5848/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5849/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5850/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 5851/10000 (58%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 5852/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 5853/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5854/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5855/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5856/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5857/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5858/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5859/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5860/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5861/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5862/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5863/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5864/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5865/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5866/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5867/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5868/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5869/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5870/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5871/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5872/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5873/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5874/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5875/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5876/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5877/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5878/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5879/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5880/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5881/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5882/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5883/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5884/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5885/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5886/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5887/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5888/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5889/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5890/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5891/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5892/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5893/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5894/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5895/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5896/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5897/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5898/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5899/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5900/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5901/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5902/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5903/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5904/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5905/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5906/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5907/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5908/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5909/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5910/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5911/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5912/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5913/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5914/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5915/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5916/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5917/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5918/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5919/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 5920/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5921/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5922/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5923/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5924/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 5925/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5926/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5927/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5928/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5929/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5930/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5931/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5932/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5933/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5934/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5935/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5936/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5937/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5938/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5939/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5940/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5941/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5942/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5943/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5944/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5945/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5946/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5947/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5948/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5949/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5950/10000 (59%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5951/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5952/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5953/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5954/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5955/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5956/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5957/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5958/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5959/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5960/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5961/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5962/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5963/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5964/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5965/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5966/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5967/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5968/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5969/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5970/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5971/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5972/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5973/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5974/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5975/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5976/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5977/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5978/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5979/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5980/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5981/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5982/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5983/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5984/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5985/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 5986/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 5987/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5988/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5989/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5990/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5991/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5992/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5993/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5994/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5995/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 5996/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5997/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5998/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 5999/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6000/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6001/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6002/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6003/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6004/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6005/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6006/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6007/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6008/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6009/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6010/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6011/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6012/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6013/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6014/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6015/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6016/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6017/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6018/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6019/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6020/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6021/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6022/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6023/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6024/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6025/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6026/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6027/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6028/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6029/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6030/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6031/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6032/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6033/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6034/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6035/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6036/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6037/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6038/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6039/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6040/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6041/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6042/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6043/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6044/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6045/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6046/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6047/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6048/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6049/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6050/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6051/10000 (60%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6052/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6053/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6054/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6055/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6056/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6057/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6058/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6059/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6060/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6061/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6062/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6063/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6064/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6065/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6066/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6067/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6068/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6069/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6070/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6071/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6072/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6073/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6074/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6075/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6076/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6077/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6078/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6079/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6080/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6081/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6082/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6083/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6084/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6085/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6086/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6087/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6088/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6089/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6090/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6091/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6092/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6093/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6094/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6095/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6096/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6097/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6098/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6099/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6100/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6101/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6102/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6103/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6104/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6105/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6106/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6107/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6108/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6109/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6110/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6111/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6112/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6113/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6114/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6115/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6116/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6117/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6118/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6119/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6120/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6121/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6122/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6123/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6124/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6125/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6126/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6127/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6128/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6129/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6130/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6131/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6132/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6133/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6134/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6135/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6136/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6137/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6138/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6139/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6140/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6141/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6142/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6143/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6144/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6145/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6146/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6147/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6148/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6149/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6150/10000 (61%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6151/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6152/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6153/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6154/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6155/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6156/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6157/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6158/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6159/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6160/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6161/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6162/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6163/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6164/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6165/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6166/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6167/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6168/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6169/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6170/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6171/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6172/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6173/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6174/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6175/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6176/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6177/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6178/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6179/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6180/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6181/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6182/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6183/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6184/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6185/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6186/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6187/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6188/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6189/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6190/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6191/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6192/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6193/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6194/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6195/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6196/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6197/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6198/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6199/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6200/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6201/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6202/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6203/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6204/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6205/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6206/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6207/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6208/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6209/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6210/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6211/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6212/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6213/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6214/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6215/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6216/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6217/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6218/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6219/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6220/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6221/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6222/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6223/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6224/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6225/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6226/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6227/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6228/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6229/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6230/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6231/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6232/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6233/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6234/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6235/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6236/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6237/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6238/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6239/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6240/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6241/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6242/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6243/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6244/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6245/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6246/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6247/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6248/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6249/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6250/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6251/10000 (62%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6252/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6253/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6254/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6255/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6256/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6257/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6258/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6259/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6260/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6261/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6262/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6263/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6264/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6265/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6266/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6267/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6268/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6269/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6270/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6271/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6272/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6273/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6274/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6275/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6276/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6277/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6278/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6279/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6280/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6281/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6282/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6283/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6284/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6285/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6286/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6287/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6288/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6289/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6290/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6291/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6292/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6293/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6294/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6295/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6296/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6297/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6298/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6299/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6300/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6301/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6302/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6303/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6304/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6305/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6306/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6307/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6308/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6309/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6310/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6311/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6312/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6313/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6314/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6315/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6316/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6317/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6318/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6319/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6320/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6321/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6322/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6323/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6324/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6325/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6326/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6327/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6328/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6329/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6330/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6331/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6332/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6333/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6334/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6335/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6336/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6337/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6338/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6339/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6340/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6341/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6342/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6343/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6344/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6345/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6346/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6347/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6348/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6349/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6350/10000 (63%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6351/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6352/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6353/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6354/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6355/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6356/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6357/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6358/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6359/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6360/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6361/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6362/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6363/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6364/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6365/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6366/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6367/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6368/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6369/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6370/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6371/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6372/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6373/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6374/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6375/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6376/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6377/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6378/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6379/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6380/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6381/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6382/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6383/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6384/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6385/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6386/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6387/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6388/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6389/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6390/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6391/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6392/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6393/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6394/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6395/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6396/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6397/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6398/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6399/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6400/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6401/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6402/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6403/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6404/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6405/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6406/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6407/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6408/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6409/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6410/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6411/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6412/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6413/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6414/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6415/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6416/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6417/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6418/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6419/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6420/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6421/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6422/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6423/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6424/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6425/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6426/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6427/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6428/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6429/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6430/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6431/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6432/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6433/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6434/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6435/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6436/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6437/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6438/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6439/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6440/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6441/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6442/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6443/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6444/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6445/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6446/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6447/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6448/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6449/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6450/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6451/10000 (64%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6452/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6453/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6454/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6455/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6456/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6457/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6458/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6459/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6460/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6461/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6462/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6463/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6464/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6465/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6466/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6467/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6468/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6469/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6470/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6471/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6472/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6473/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6474/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6475/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6476/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6477/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6478/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6479/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6480/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6481/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6482/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6483/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6484/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6485/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6486/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6487/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6488/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6489/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6490/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6491/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6492/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6493/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6494/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6495/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6496/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6497/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6498/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6499/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6500/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6501/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6502/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6503/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6504/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6505/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6506/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6507/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6508/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6509/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6510/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6511/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6512/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6513/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6514/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6515/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6516/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6517/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6518/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6519/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6520/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6521/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6522/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6523/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6524/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6525/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6526/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6527/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6528/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6529/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6530/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6531/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6532/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6533/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6534/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6535/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6536/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6537/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6538/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6539/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6540/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6541/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6542/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6543/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6544/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6545/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6546/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6547/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6548/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6549/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6550/10000 (65%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6551/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6552/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6553/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6554/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6555/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6556/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6557/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6558/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6559/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6560/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6561/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6562/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6563/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6564/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6565/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6566/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6567/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6568/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6569/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6570/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6571/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6572/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6573/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6574/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6575/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6576/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6577/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6578/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6579/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6580/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6581/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6582/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6583/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6584/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6585/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6586/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6587/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6588/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6589/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6590/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6591/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6592/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6593/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6594/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6595/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6596/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6597/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6598/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6599/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6600/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6601/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6602/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6603/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6604/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6605/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6606/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6607/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6608/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6609/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6610/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6611/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6612/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6613/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6614/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6615/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6616/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6617/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6618/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6619/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6620/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6621/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6622/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6623/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6624/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6625/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6626/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6627/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6628/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6629/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6630/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6631/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6632/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6633/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6634/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6635/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6636/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6637/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6638/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6639/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6640/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6641/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6642/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6643/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6644/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6645/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6646/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6647/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6648/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6649/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6650/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6651/10000 (66%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6652/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6653/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6654/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6655/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6656/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6657/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6658/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6659/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6660/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6661/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6662/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6663/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6664/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6665/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6666/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6667/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6668/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6669/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6670/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6671/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6672/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6673/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6674/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6675/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6676/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6677/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6678/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6679/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6680/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6681/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6682/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6683/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6684/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 6685/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6686/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6687/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 6688/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6689/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6690/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6691/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6692/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6693/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6694/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6695/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6696/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6697/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6698/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6699/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6700/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6701/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6702/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6703/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6704/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6705/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6706/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 6707/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6708/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6709/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6710/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6711/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6712/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6713/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6714/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6715/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6716/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6717/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6718/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6719/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6720/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6721/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6722/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6723/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6724/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6725/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6726/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6727/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6728/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6729/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6730/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6731/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6732/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6733/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6734/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6735/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6736/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6737/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6738/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6739/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 6740/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6741/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6742/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 6743/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6744/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 6745/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6746/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6747/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 6748/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6749/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 6750/10000 (67%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6751/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6752/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6753/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6754/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6755/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6756/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6757/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6758/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6759/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6760/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6761/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6762/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6763/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6764/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6765/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6766/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6767/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6768/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6769/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6770/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 6771/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 6772/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6773/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 6774/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004630\n",
      "Train Epoch: 6775/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 6776/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004629\n",
      "Train Epoch: 6777/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004636\n",
      "Train Epoch: 6778/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 6779/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 6780/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 6781/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 6782/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6783/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 6784/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6785/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6786/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6787/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6788/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6789/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6790/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6791/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6792/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6793/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6794/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 6795/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6796/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6797/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6798/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6799/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6800/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6801/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6802/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 6803/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6804/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 6805/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 6806/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6807/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 6808/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6809/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6810/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6811/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6812/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 6813/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6814/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 6815/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6816/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6817/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 6818/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6819/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 6820/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 6821/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 6822/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004636\n",
      "Train Epoch: 6823/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 6824/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 6825/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 6826/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004639\n",
      "Train Epoch: 6827/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 6828/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004640\n",
      "Train Epoch: 6829/10000 (68%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 6830/10000 (68%)\ttrain_Loss: 0.004294\tval_Loss: 0.004640\n",
      "Train Epoch: 6831/10000 (68%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 6832/10000 (68%)\ttrain_Loss: 0.004294\tval_Loss: 0.004640\n",
      "Train Epoch: 6833/10000 (68%)\ttrain_Loss: 0.004294\tval_Loss: 0.004628\n",
      "Train Epoch: 6834/10000 (68%)\ttrain_Loss: 0.004294\tval_Loss: 0.004639\n",
      "Train Epoch: 6835/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 6836/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 6837/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 6838/10000 (68%)\ttrain_Loss: 0.004293\tval_Loss: 0.004636\n",
      "Train Epoch: 6839/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6840/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6841/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6842/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6843/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6844/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6845/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6846/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6847/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6848/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6849/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6850/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6851/10000 (68%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6852/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6853/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6854/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6855/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6856/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6857/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6858/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6859/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6860/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6861/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6862/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 6863/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6864/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 6865/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6866/10000 (69%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n",
      "Train Epoch: 6867/10000 (69%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 6868/10000 (69%)\ttrain_Loss: 0.004293\tval_Loss: 0.004639\n",
      "Train Epoch: 6869/10000 (69%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 6870/10000 (69%)\ttrain_Loss: 0.004294\tval_Loss: 0.004641\n",
      "Train Epoch: 6871/10000 (69%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 6872/10000 (69%)\ttrain_Loss: 0.004295\tval_Loss: 0.004643\n",
      "Train Epoch: 6873/10000 (69%)\ttrain_Loss: 0.004295\tval_Loss: 0.004627\n",
      "Train Epoch: 6874/10000 (69%)\ttrain_Loss: 0.004296\tval_Loss: 0.004645\n",
      "Train Epoch: 6875/10000 (69%)\ttrain_Loss: 0.004296\tval_Loss: 0.004627\n",
      "Train Epoch: 6876/10000 (69%)\ttrain_Loss: 0.004296\tval_Loss: 0.004646\n",
      "Train Epoch: 6877/10000 (69%)\ttrain_Loss: 0.004296\tval_Loss: 0.004627\n",
      "Train Epoch: 6878/10000 (69%)\ttrain_Loss: 0.004296\tval_Loss: 0.004645\n",
      "Train Epoch: 6879/10000 (69%)\ttrain_Loss: 0.004296\tval_Loss: 0.004627\n",
      "Train Epoch: 6880/10000 (69%)\ttrain_Loss: 0.004296\tval_Loss: 0.004642\n",
      "Train Epoch: 6881/10000 (69%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 6882/10000 (69%)\ttrain_Loss: 0.004294\tval_Loss: 0.004637\n",
      "Train Epoch: 6883/10000 (69%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 6884/10000 (69%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 6885/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6886/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6887/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6888/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6889/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 6890/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6891/10000 (69%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n",
      "Train Epoch: 6892/10000 (69%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 6893/10000 (69%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n",
      "Train Epoch: 6894/10000 (69%)\ttrain_Loss: 0.004293\tval_Loss: 0.004626\n",
      "Train Epoch: 6895/10000 (69%)\ttrain_Loss: 0.004293\tval_Loss: 0.004636\n",
      "Train Epoch: 6896/10000 (69%)\ttrain_Loss: 0.004293\tval_Loss: 0.004626\n",
      "Train Epoch: 6897/10000 (69%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 6898/10000 (69%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 6899/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 6900/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6901/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6902/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6903/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6904/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6905/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6906/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6907/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6908/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6909/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6910/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6911/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6912/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6913/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6914/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6915/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6916/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6917/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6918/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6919/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6920/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6921/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6922/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6923/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6924/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6925/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6926/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6927/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6928/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6929/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6930/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6931/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6932/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6933/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6934/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6935/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6936/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6937/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6938/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6939/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 6940/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6941/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 6942/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6943/10000 (69%)\ttrain_Loss: 0.004292\tval_Loss: 0.004638\n",
      "Train Epoch: 6944/10000 (69%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 6945/10000 (69%)\ttrain_Loss: 0.004293\tval_Loss: 0.004640\n",
      "Train Epoch: 6946/10000 (69%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 6947/10000 (69%)\ttrain_Loss: 0.004294\tval_Loss: 0.004642\n",
      "Train Epoch: 6948/10000 (69%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 6949/10000 (69%)\ttrain_Loss: 0.004296\tval_Loss: 0.004647\n",
      "Train Epoch: 6950/10000 (69%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 6951/10000 (70%)\ttrain_Loss: 0.004298\tval_Loss: 0.004652\n",
      "Train Epoch: 6952/10000 (70%)\ttrain_Loss: 0.004300\tval_Loss: 0.004628\n",
      "Train Epoch: 6953/10000 (70%)\ttrain_Loss: 0.004301\tval_Loss: 0.004657\n",
      "Train Epoch: 6954/10000 (70%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 6955/10000 (70%)\ttrain_Loss: 0.004302\tval_Loss: 0.004656\n",
      "Train Epoch: 6956/10000 (70%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 6957/10000 (70%)\ttrain_Loss: 0.004300\tval_Loss: 0.004648\n",
      "Train Epoch: 6958/10000 (70%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 6959/10000 (70%)\ttrain_Loss: 0.004296\tval_Loss: 0.004638\n",
      "Train Epoch: 6960/10000 (70%)\ttrain_Loss: 0.004293\tval_Loss: 0.004629\n",
      "Train Epoch: 6961/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6962/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 6963/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6964/10000 (70%)\ttrain_Loss: 0.004293\tval_Loss: 0.004640\n",
      "Train Epoch: 6965/10000 (70%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 6966/10000 (70%)\ttrain_Loss: 0.004294\tval_Loss: 0.004643\n",
      "Train Epoch: 6967/10000 (70%)\ttrain_Loss: 0.004295\tval_Loss: 0.004627\n",
      "Train Epoch: 6968/10000 (70%)\ttrain_Loss: 0.004295\tval_Loss: 0.004641\n",
      "Train Epoch: 6969/10000 (70%)\ttrain_Loss: 0.004294\tval_Loss: 0.004628\n",
      "Train Epoch: 6970/10000 (70%)\ttrain_Loss: 0.004293\tval_Loss: 0.004636\n",
      "Train Epoch: 6971/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6972/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6973/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6974/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6975/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 6976/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 6977/10000 (70%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 6978/10000 (70%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 6979/10000 (70%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 6980/10000 (70%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 6981/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 6982/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 6983/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 6984/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6985/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6986/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6987/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6988/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6989/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6990/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6991/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 6992/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6993/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 6994/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 6995/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6996/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 6997/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6998/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 6999/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7000/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7001/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7002/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7003/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7004/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7005/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7006/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7007/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7008/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7009/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7010/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7011/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7012/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7013/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7014/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7015/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7016/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7017/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7018/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7019/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7020/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7021/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7022/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7023/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7024/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7025/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7026/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7027/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7028/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7029/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7030/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7031/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7032/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7033/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7034/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7035/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7036/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7037/10000 (70%)\ttrain_Loss: 0.004292\tval_Loss: 0.004637\n",
      "Train Epoch: 7038/10000 (70%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7039/10000 (70%)\ttrain_Loss: 0.004293\tval_Loss: 0.004639\n",
      "Train Epoch: 7040/10000 (70%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 7041/10000 (70%)\ttrain_Loss: 0.004294\tval_Loss: 0.004641\n",
      "Train Epoch: 7042/10000 (70%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 7043/10000 (70%)\ttrain_Loss: 0.004295\tval_Loss: 0.004645\n",
      "Train Epoch: 7044/10000 (70%)\ttrain_Loss: 0.004296\tval_Loss: 0.004627\n",
      "Train Epoch: 7045/10000 (70%)\ttrain_Loss: 0.004297\tval_Loss: 0.004649\n",
      "Train Epoch: 7046/10000 (70%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 7047/10000 (70%)\ttrain_Loss: 0.004299\tval_Loss: 0.004653\n",
      "Train Epoch: 7048/10000 (70%)\ttrain_Loss: 0.004301\tval_Loss: 0.004627\n",
      "Train Epoch: 7049/10000 (70%)\ttrain_Loss: 0.004302\tval_Loss: 0.004657\n",
      "Train Epoch: 7050/10000 (70%)\ttrain_Loss: 0.004303\tval_Loss: 0.004628\n",
      "Train Epoch: 7051/10000 (70%)\ttrain_Loss: 0.004303\tval_Loss: 0.004656\n",
      "Train Epoch: 7052/10000 (71%)\ttrain_Loss: 0.004302\tval_Loss: 0.004626\n",
      "Train Epoch: 7053/10000 (71%)\ttrain_Loss: 0.004300\tval_Loss: 0.004648\n",
      "Train Epoch: 7054/10000 (71%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 7055/10000 (71%)\ttrain_Loss: 0.004295\tval_Loss: 0.004639\n",
      "Train Epoch: 7056/10000 (71%)\ttrain_Loss: 0.004293\tval_Loss: 0.004629\n",
      "Train Epoch: 7057/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7058/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7059/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7060/10000 (71%)\ttrain_Loss: 0.004293\tval_Loss: 0.004640\n",
      "Train Epoch: 7061/10000 (71%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 7062/10000 (71%)\ttrain_Loss: 0.004294\tval_Loss: 0.004642\n",
      "Train Epoch: 7063/10000 (71%)\ttrain_Loss: 0.004294\tval_Loss: 0.004628\n",
      "Train Epoch: 7064/10000 (71%)\ttrain_Loss: 0.004294\tval_Loss: 0.004640\n",
      "Train Epoch: 7065/10000 (71%)\ttrain_Loss: 0.004294\tval_Loss: 0.004628\n",
      "Train Epoch: 7066/10000 (71%)\ttrain_Loss: 0.004293\tval_Loss: 0.004636\n",
      "Train Epoch: 7067/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7068/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7069/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7070/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7071/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7072/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7073/10000 (71%)\ttrain_Loss: 0.004293\tval_Loss: 0.004636\n",
      "Train Epoch: 7074/10000 (71%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 7075/10000 (71%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 7076/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7077/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7078/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7079/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7080/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7081/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7082/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7083/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7084/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7085/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7086/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7087/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7088/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7089/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7090/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7091/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7092/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7093/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7094/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7095/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7096/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7097/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7098/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7099/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7100/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7101/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7102/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7103/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7104/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7105/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7106/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7107/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7108/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7109/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7110/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7111/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7112/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7113/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7114/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7115/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7116/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7117/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7118/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7119/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 7120/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7121/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7122/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7123/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7124/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7125/10000 (71%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 7126/10000 (71%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 7127/10000 (71%)\ttrain_Loss: 0.004293\tval_Loss: 0.004639\n",
      "Train Epoch: 7128/10000 (71%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 7129/10000 (71%)\ttrain_Loss: 0.004293\tval_Loss: 0.004640\n",
      "Train Epoch: 7130/10000 (71%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 7131/10000 (71%)\ttrain_Loss: 0.004294\tval_Loss: 0.004642\n",
      "Train Epoch: 7132/10000 (71%)\ttrain_Loss: 0.004295\tval_Loss: 0.004627\n",
      "Train Epoch: 7133/10000 (71%)\ttrain_Loss: 0.004295\tval_Loss: 0.004645\n",
      "Train Epoch: 7134/10000 (71%)\ttrain_Loss: 0.004296\tval_Loss: 0.004628\n",
      "Train Epoch: 7135/10000 (71%)\ttrain_Loss: 0.004296\tval_Loss: 0.004648\n",
      "Train Epoch: 7136/10000 (71%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 7137/10000 (71%)\ttrain_Loss: 0.004298\tval_Loss: 0.004649\n",
      "Train Epoch: 7138/10000 (71%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 7139/10000 (71%)\ttrain_Loss: 0.004299\tval_Loss: 0.004650\n",
      "Train Epoch: 7140/10000 (71%)\ttrain_Loss: 0.004299\tval_Loss: 0.004626\n",
      "Train Epoch: 7141/10000 (71%)\ttrain_Loss: 0.004299\tval_Loss: 0.004649\n",
      "Train Epoch: 7142/10000 (71%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 7143/10000 (71%)\ttrain_Loss: 0.004297\tval_Loss: 0.004645\n",
      "Train Epoch: 7144/10000 (71%)\ttrain_Loss: 0.004296\tval_Loss: 0.004626\n",
      "Train Epoch: 7145/10000 (71%)\ttrain_Loss: 0.004295\tval_Loss: 0.004639\n",
      "Train Epoch: 7146/10000 (71%)\ttrain_Loss: 0.004294\tval_Loss: 0.004628\n",
      "Train Epoch: 7147/10000 (71%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 7148/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7149/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7150/10000 (71%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7151/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7152/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004638\n",
      "Train Epoch: 7153/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 7154/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004639\n",
      "Train Epoch: 7155/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 7156/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004639\n",
      "Train Epoch: 7157/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 7158/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 7159/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 7160/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7161/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7162/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7163/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7164/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7165/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7166/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7167/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7168/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7169/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7170/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7171/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7172/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7173/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7174/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7175/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7176/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7177/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7178/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7179/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7180/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7181/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7182/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7183/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7184/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7185/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7186/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7187/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7188/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7189/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7190/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7191/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7192/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7193/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7194/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7195/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7196/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7197/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7198/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7199/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7200/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7201/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7202/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7203/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 7204/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 7205/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n",
      "Train Epoch: 7206/10000 (72%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 7207/10000 (72%)\ttrain_Loss: 0.004294\tval_Loss: 0.004642\n",
      "Train Epoch: 7208/10000 (72%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 7209/10000 (72%)\ttrain_Loss: 0.004296\tval_Loss: 0.004648\n",
      "Train Epoch: 7210/10000 (72%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 7211/10000 (72%)\ttrain_Loss: 0.004299\tval_Loss: 0.004655\n",
      "Train Epoch: 7212/10000 (72%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 7213/10000 (72%)\ttrain_Loss: 0.004303\tval_Loss: 0.004661\n",
      "Train Epoch: 7214/10000 (72%)\ttrain_Loss: 0.004305\tval_Loss: 0.004629\n",
      "Train Epoch: 7215/10000 (72%)\ttrain_Loss: 0.004306\tval_Loss: 0.004663\n",
      "Train Epoch: 7216/10000 (72%)\ttrain_Loss: 0.004307\tval_Loss: 0.004628\n",
      "Train Epoch: 7217/10000 (72%)\ttrain_Loss: 0.004306\tval_Loss: 0.004658\n",
      "Train Epoch: 7218/10000 (72%)\ttrain_Loss: 0.004303\tval_Loss: 0.004626\n",
      "Train Epoch: 7219/10000 (72%)\ttrain_Loss: 0.004300\tval_Loss: 0.004645\n",
      "Train Epoch: 7220/10000 (72%)\ttrain_Loss: 0.004296\tval_Loss: 0.004627\n",
      "Train Epoch: 7221/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 7222/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7223/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7224/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004641\n",
      "Train Epoch: 7225/10000 (72%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 7226/10000 (72%)\ttrain_Loss: 0.004295\tval_Loss: 0.004645\n",
      "Train Epoch: 7227/10000 (72%)\ttrain_Loss: 0.004296\tval_Loss: 0.004625\n",
      "Train Epoch: 7228/10000 (72%)\ttrain_Loss: 0.004296\tval_Loss: 0.004642\n",
      "Train Epoch: 7229/10000 (72%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 7230/10000 (72%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 7231/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 7232/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7233/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7234/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7235/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004638\n",
      "Train Epoch: 7236/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 7237/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004639\n",
      "Train Epoch: 7238/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 7239/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 7240/10000 (72%)\ttrain_Loss: 0.004293\tval_Loss: 0.004629\n",
      "Train Epoch: 7241/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7242/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7243/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7244/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7245/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7246/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7247/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7248/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 7249/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7250/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7251/10000 (72%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7252/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7253/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7254/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7255/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7256/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7257/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7258/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7259/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7260/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7261/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7262/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7263/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7264/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7265/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7266/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7267/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7268/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7269/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7270/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7271/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7272/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7273/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7274/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7275/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7276/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7277/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7278/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7279/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7280/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7281/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7282/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7283/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7284/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7285/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7286/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7287/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7288/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7289/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7290/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7291/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7292/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7293/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7294/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7295/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7296/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7297/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7298/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7299/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7300/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7301/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7302/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 7303/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7304/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 7305/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7306/10000 (73%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n",
      "Train Epoch: 7307/10000 (73%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 7308/10000 (73%)\ttrain_Loss: 0.004293\tval_Loss: 0.004640\n",
      "Train Epoch: 7309/10000 (73%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 7310/10000 (73%)\ttrain_Loss: 0.004295\tval_Loss: 0.004644\n",
      "Train Epoch: 7311/10000 (73%)\ttrain_Loss: 0.004295\tval_Loss: 0.004627\n",
      "Train Epoch: 7312/10000 (73%)\ttrain_Loss: 0.004296\tval_Loss: 0.004649\n",
      "Train Epoch: 7313/10000 (73%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 7314/10000 (73%)\ttrain_Loss: 0.004299\tval_Loss: 0.004654\n",
      "Train Epoch: 7315/10000 (73%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 7316/10000 (73%)\ttrain_Loss: 0.004302\tval_Loss: 0.004659\n",
      "Train Epoch: 7317/10000 (73%)\ttrain_Loss: 0.004304\tval_Loss: 0.004628\n",
      "Train Epoch: 7318/10000 (73%)\ttrain_Loss: 0.004305\tval_Loss: 0.004660\n",
      "Train Epoch: 7319/10000 (73%)\ttrain_Loss: 0.004305\tval_Loss: 0.004627\n",
      "Train Epoch: 7320/10000 (73%)\ttrain_Loss: 0.004304\tval_Loss: 0.004654\n",
      "Train Epoch: 7321/10000 (73%)\ttrain_Loss: 0.004302\tval_Loss: 0.004626\n",
      "Train Epoch: 7322/10000 (73%)\ttrain_Loss: 0.004299\tval_Loss: 0.004644\n",
      "Train Epoch: 7323/10000 (73%)\ttrain_Loss: 0.004296\tval_Loss: 0.004627\n",
      "Train Epoch: 7324/10000 (73%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 7325/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7326/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7327/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004639\n",
      "Train Epoch: 7328/10000 (73%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 7329/10000 (73%)\ttrain_Loss: 0.004295\tval_Loss: 0.004644\n",
      "Train Epoch: 7330/10000 (73%)\ttrain_Loss: 0.004296\tval_Loss: 0.004627\n",
      "Train Epoch: 7331/10000 (73%)\ttrain_Loss: 0.004296\tval_Loss: 0.004644\n",
      "Train Epoch: 7332/10000 (73%)\ttrain_Loss: 0.004295\tval_Loss: 0.004627\n",
      "Train Epoch: 7333/10000 (73%)\ttrain_Loss: 0.004294\tval_Loss: 0.004639\n",
      "Train Epoch: 7334/10000 (73%)\ttrain_Loss: 0.004293\tval_Loss: 0.004629\n",
      "Train Epoch: 7335/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7336/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7337/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7338/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7339/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7340/10000 (73%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n",
      "Train Epoch: 7341/10000 (73%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 7342/10000 (73%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n",
      "Train Epoch: 7343/10000 (73%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 7344/10000 (73%)\ttrain_Loss: 0.004293\tval_Loss: 0.004636\n",
      "Train Epoch: 7345/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7346/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7347/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7348/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7349/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7350/10000 (73%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7351/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7352/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7353/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7354/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7355/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7356/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7357/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7358/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7359/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7360/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7361/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7362/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7363/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7364/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7365/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7366/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7367/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7368/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7369/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7370/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7371/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7372/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7373/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7374/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7375/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7376/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7377/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7378/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7379/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7380/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7381/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7382/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7383/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7384/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7385/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7386/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7387/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7388/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7389/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7390/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7391/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7392/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7393/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7394/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7395/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7396/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7397/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7398/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7399/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7400/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7401/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7402/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7403/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7404/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7405/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 7406/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7407/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004638\n",
      "Train Epoch: 7408/10000 (74%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 7409/10000 (74%)\ttrain_Loss: 0.004293\tval_Loss: 0.004640\n",
      "Train Epoch: 7410/10000 (74%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 7411/10000 (74%)\ttrain_Loss: 0.004294\tval_Loss: 0.004644\n",
      "Train Epoch: 7412/10000 (74%)\ttrain_Loss: 0.004296\tval_Loss: 0.004626\n",
      "Train Epoch: 7413/10000 (74%)\ttrain_Loss: 0.004297\tval_Loss: 0.004651\n",
      "Train Epoch: 7414/10000 (74%)\ttrain_Loss: 0.004299\tval_Loss: 0.004627\n",
      "Train Epoch: 7415/10000 (74%)\ttrain_Loss: 0.004302\tval_Loss: 0.004660\n",
      "Train Epoch: 7416/10000 (74%)\ttrain_Loss: 0.004305\tval_Loss: 0.004629\n",
      "Train Epoch: 7417/10000 (74%)\ttrain_Loss: 0.004308\tval_Loss: 0.004670\n",
      "Train Epoch: 7418/10000 (74%)\ttrain_Loss: 0.004311\tval_Loss: 0.004632\n",
      "Train Epoch: 7419/10000 (74%)\ttrain_Loss: 0.004312\tval_Loss: 0.004672\n",
      "Train Epoch: 7420/10000 (74%)\ttrain_Loss: 0.004312\tval_Loss: 0.004630\n",
      "Train Epoch: 7421/10000 (74%)\ttrain_Loss: 0.004309\tval_Loss: 0.004660\n",
      "Train Epoch: 7422/10000 (74%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 7423/10000 (74%)\ttrain_Loss: 0.004299\tval_Loss: 0.004641\n",
      "Train Epoch: 7424/10000 (74%)\ttrain_Loss: 0.004294\tval_Loss: 0.004630\n",
      "Train Epoch: 7425/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7426/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004641\n",
      "Train Epoch: 7427/10000 (74%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 7428/10000 (74%)\ttrain_Loss: 0.004297\tval_Loss: 0.004650\n",
      "Train Epoch: 7429/10000 (74%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 7430/10000 (74%)\ttrain_Loss: 0.004299\tval_Loss: 0.004648\n",
      "Train Epoch: 7431/10000 (74%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 7432/10000 (74%)\ttrain_Loss: 0.004295\tval_Loss: 0.004637\n",
      "Train Epoch: 7433/10000 (74%)\ttrain_Loss: 0.004293\tval_Loss: 0.004629\n",
      "Train Epoch: 7434/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7435/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7436/10000 (74%)\ttrain_Loss: 0.004293\tval_Loss: 0.004626\n",
      "Train Epoch: 7437/10000 (74%)\ttrain_Loss: 0.004294\tval_Loss: 0.004641\n",
      "Train Epoch: 7438/10000 (74%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 7439/10000 (74%)\ttrain_Loss: 0.004294\tval_Loss: 0.004640\n",
      "Train Epoch: 7440/10000 (74%)\ttrain_Loss: 0.004294\tval_Loss: 0.004628\n",
      "Train Epoch: 7441/10000 (74%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 7442/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7443/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7444/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7445/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7446/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004637\n",
      "Train Epoch: 7447/10000 (74%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 7448/10000 (74%)\ttrain_Loss: 0.004293\tval_Loss: 0.004636\n",
      "Train Epoch: 7449/10000 (74%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 7450/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7451/10000 (74%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7452/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7453/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7454/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7455/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7456/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7457/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7458/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7459/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7460/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7461/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7462/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7463/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7464/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7465/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7466/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7467/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7468/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7469/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7470/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7471/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7472/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7473/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7474/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7475/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7476/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7477/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7478/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7479/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7480/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7481/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7482/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7483/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7484/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7485/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7486/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7487/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7488/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7489/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7490/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7491/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7492/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7493/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7494/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7495/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7496/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7497/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7498/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7499/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7500/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7501/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7502/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7503/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7504/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7505/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7506/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7507/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7508/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7509/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7510/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7511/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7512/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7513/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7514/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7515/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7516/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7517/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7518/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7519/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7520/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7521/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7522/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7523/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7524/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7525/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7526/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7527/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7528/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7529/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7530/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004637\n",
      "Train Epoch: 7531/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7532/10000 (75%)\ttrain_Loss: 0.004293\tval_Loss: 0.004639\n",
      "Train Epoch: 7533/10000 (75%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 7534/10000 (75%)\ttrain_Loss: 0.004294\tval_Loss: 0.004642\n",
      "Train Epoch: 7535/10000 (75%)\ttrain_Loss: 0.004295\tval_Loss: 0.004627\n",
      "Train Epoch: 7536/10000 (75%)\ttrain_Loss: 0.004296\tval_Loss: 0.004647\n",
      "Train Epoch: 7537/10000 (75%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 7538/10000 (75%)\ttrain_Loss: 0.004299\tval_Loss: 0.004655\n",
      "Train Epoch: 7539/10000 (75%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 7540/10000 (75%)\ttrain_Loss: 0.004304\tval_Loss: 0.004663\n",
      "Train Epoch: 7541/10000 (75%)\ttrain_Loss: 0.004307\tval_Loss: 0.004630\n",
      "Train Epoch: 7542/10000 (75%)\ttrain_Loss: 0.004309\tval_Loss: 0.004669\n",
      "Train Epoch: 7543/10000 (75%)\ttrain_Loss: 0.004311\tval_Loss: 0.004631\n",
      "Train Epoch: 7544/10000 (75%)\ttrain_Loss: 0.004311\tval_Loss: 0.004666\n",
      "Train Epoch: 7545/10000 (75%)\ttrain_Loss: 0.004308\tval_Loss: 0.004628\n",
      "Train Epoch: 7546/10000 (75%)\ttrain_Loss: 0.004304\tval_Loss: 0.004652\n",
      "Train Epoch: 7547/10000 (75%)\ttrain_Loss: 0.004299\tval_Loss: 0.004627\n",
      "Train Epoch: 7548/10000 (75%)\ttrain_Loss: 0.004295\tval_Loss: 0.004635\n",
      "Train Epoch: 7549/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7550/10000 (75%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 7551/10000 (76%)\ttrain_Loss: 0.004293\tval_Loss: 0.004642\n",
      "Train Epoch: 7552/10000 (76%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 7553/10000 (76%)\ttrain_Loss: 0.004297\tval_Loss: 0.004648\n",
      "Train Epoch: 7554/10000 (76%)\ttrain_Loss: 0.004298\tval_Loss: 0.004627\n",
      "Train Epoch: 7555/10000 (76%)\ttrain_Loss: 0.004297\tval_Loss: 0.004645\n",
      "Train Epoch: 7556/10000 (76%)\ttrain_Loss: 0.004296\tval_Loss: 0.004627\n",
      "Train Epoch: 7557/10000 (76%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 7558/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7559/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7560/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 7561/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 7562/10000 (76%)\ttrain_Loss: 0.004293\tval_Loss: 0.004640\n",
      "Train Epoch: 7563/10000 (76%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 7564/10000 (76%)\ttrain_Loss: 0.004294\tval_Loss: 0.004640\n",
      "Train Epoch: 7565/10000 (76%)\ttrain_Loss: 0.004294\tval_Loss: 0.004628\n",
      "Train Epoch: 7566/10000 (76%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 7567/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7568/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7569/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7570/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7571/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 7572/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7573/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004637\n",
      "Train Epoch: 7574/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7575/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7576/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7577/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7578/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7579/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7580/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7581/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7582/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7583/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7584/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7585/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7586/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7587/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7588/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7589/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7590/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7591/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7592/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7593/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7594/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7595/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7596/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7597/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7598/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7599/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7600/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7601/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7602/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7603/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7604/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7605/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7606/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7607/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7608/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7609/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7610/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7611/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7612/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7613/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7614/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7615/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7616/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7617/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7618/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7619/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7620/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7621/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7622/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7623/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7624/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7625/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7626/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7627/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7628/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7629/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7630/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7631/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7632/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7633/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7634/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7635/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7636/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7637/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7638/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7639/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7640/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7641/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7642/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7643/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7644/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7645/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7646/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7647/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7648/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7649/10000 (76%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 7650/10000 (76%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 7651/10000 (76%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 7652/10000 (77%)\ttrain_Loss: 0.004293\tval_Loss: 0.004642\n",
      "Train Epoch: 7653/10000 (77%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 7654/10000 (77%)\ttrain_Loss: 0.004295\tval_Loss: 0.004647\n",
      "Train Epoch: 7655/10000 (77%)\ttrain_Loss: 0.004296\tval_Loss: 0.004626\n",
      "Train Epoch: 7656/10000 (77%)\ttrain_Loss: 0.004298\tval_Loss: 0.004653\n",
      "Train Epoch: 7657/10000 (77%)\ttrain_Loss: 0.004300\tval_Loss: 0.004627\n",
      "Train Epoch: 7658/10000 (77%)\ttrain_Loss: 0.004303\tval_Loss: 0.004662\n",
      "Train Epoch: 7659/10000 (77%)\ttrain_Loss: 0.004306\tval_Loss: 0.004630\n",
      "Train Epoch: 7660/10000 (77%)\ttrain_Loss: 0.004309\tval_Loss: 0.004671\n",
      "Train Epoch: 7661/10000 (77%)\ttrain_Loss: 0.004312\tval_Loss: 0.004632\n",
      "Train Epoch: 7662/10000 (77%)\ttrain_Loss: 0.004313\tval_Loss: 0.004671\n",
      "Train Epoch: 7663/10000 (77%)\ttrain_Loss: 0.004312\tval_Loss: 0.004629\n",
      "Train Epoch: 7664/10000 (77%)\ttrain_Loss: 0.004308\tval_Loss: 0.004657\n",
      "Train Epoch: 7665/10000 (77%)\ttrain_Loss: 0.004303\tval_Loss: 0.004626\n",
      "Train Epoch: 7666/10000 (77%)\ttrain_Loss: 0.004297\tval_Loss: 0.004639\n",
      "Train Epoch: 7667/10000 (77%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 7668/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7669/10000 (77%)\ttrain_Loss: 0.004293\tval_Loss: 0.004643\n",
      "Train Epoch: 7670/10000 (77%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 7671/10000 (77%)\ttrain_Loss: 0.004297\tval_Loss: 0.004650\n",
      "Train Epoch: 7672/10000 (77%)\ttrain_Loss: 0.004299\tval_Loss: 0.004626\n",
      "Train Epoch: 7673/10000 (77%)\ttrain_Loss: 0.004299\tval_Loss: 0.004647\n",
      "Train Epoch: 7674/10000 (77%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 7675/10000 (77%)\ttrain_Loss: 0.004295\tval_Loss: 0.004637\n",
      "Train Epoch: 7676/10000 (77%)\ttrain_Loss: 0.004293\tval_Loss: 0.004631\n",
      "Train Epoch: 7677/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7678/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004637\n",
      "Train Epoch: 7679/10000 (77%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 7680/10000 (77%)\ttrain_Loss: 0.004294\tval_Loss: 0.004641\n",
      "Train Epoch: 7681/10000 (77%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 7682/10000 (77%)\ttrain_Loss: 0.004294\tval_Loss: 0.004639\n",
      "Train Epoch: 7683/10000 (77%)\ttrain_Loss: 0.004294\tval_Loss: 0.004628\n",
      "Train Epoch: 7684/10000 (77%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 7685/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7686/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7687/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7688/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7689/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004637\n",
      "Train Epoch: 7690/10000 (77%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 7691/10000 (77%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 7692/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7693/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7694/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7695/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7696/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7697/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7698/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7699/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7700/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7701/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7702/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7703/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7704/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7705/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7706/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7707/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7708/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7709/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7710/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7711/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7712/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7713/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7714/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7715/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7716/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7717/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7718/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7719/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7720/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7721/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7722/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7723/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7724/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7725/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7726/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7727/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7728/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7729/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7730/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7731/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7732/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7733/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7734/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7735/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7736/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7737/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7738/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7739/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7740/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7741/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7742/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7743/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7744/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7745/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7746/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7747/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7748/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7749/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7750/10000 (77%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7751/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7752/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7753/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7754/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7755/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7756/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7757/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7758/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7759/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7760/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7761/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7762/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7763/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7764/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7765/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7766/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7767/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7768/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7769/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7770/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7771/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7772/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7773/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 7774/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7775/10000 (78%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n",
      "Train Epoch: 7776/10000 (78%)\ttrain_Loss: 0.004293\tval_Loss: 0.004626\n",
      "Train Epoch: 7777/10000 (78%)\ttrain_Loss: 0.004294\tval_Loss: 0.004641\n",
      "Train Epoch: 7778/10000 (78%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 7779/10000 (78%)\ttrain_Loss: 0.004296\tval_Loss: 0.004648\n",
      "Train Epoch: 7780/10000 (78%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 7781/10000 (78%)\ttrain_Loss: 0.004299\tval_Loss: 0.004657\n",
      "Train Epoch: 7782/10000 (78%)\ttrain_Loss: 0.004302\tval_Loss: 0.004629\n",
      "Train Epoch: 7783/10000 (78%)\ttrain_Loss: 0.004305\tval_Loss: 0.004667\n",
      "Train Epoch: 7784/10000 (78%)\ttrain_Loss: 0.004309\tval_Loss: 0.004631\n",
      "Train Epoch: 7785/10000 (78%)\ttrain_Loss: 0.004312\tval_Loss: 0.004675\n",
      "Train Epoch: 7786/10000 (78%)\ttrain_Loss: 0.004315\tval_Loss: 0.004633\n",
      "Train Epoch: 7787/10000 (78%)\ttrain_Loss: 0.004315\tval_Loss: 0.004671\n",
      "Train Epoch: 7788/10000 (78%)\ttrain_Loss: 0.004312\tval_Loss: 0.004629\n",
      "Train Epoch: 7789/10000 (78%)\ttrain_Loss: 0.004306\tval_Loss: 0.004652\n",
      "Train Epoch: 7790/10000 (78%)\ttrain_Loss: 0.004300\tval_Loss: 0.004627\n",
      "Train Epoch: 7791/10000 (78%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 7792/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7793/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 7794/10000 (78%)\ttrain_Loss: 0.004295\tval_Loss: 0.004648\n",
      "Train Epoch: 7795/10000 (78%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 7796/10000 (78%)\ttrain_Loss: 0.004299\tval_Loss: 0.004651\n",
      "Train Epoch: 7797/10000 (78%)\ttrain_Loss: 0.004299\tval_Loss: 0.004626\n",
      "Train Epoch: 7798/10000 (78%)\ttrain_Loss: 0.004297\tval_Loss: 0.004642\n",
      "Train Epoch: 7799/10000 (78%)\ttrain_Loss: 0.004295\tval_Loss: 0.004628\n",
      "Train Epoch: 7800/10000 (78%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 7801/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7802/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 7803/10000 (78%)\ttrain_Loss: 0.004293\tval_Loss: 0.004641\n",
      "Train Epoch: 7804/10000 (78%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 7805/10000 (78%)\ttrain_Loss: 0.004295\tval_Loss: 0.004642\n",
      "Train Epoch: 7806/10000 (78%)\ttrain_Loss: 0.004295\tval_Loss: 0.004627\n",
      "Train Epoch: 7807/10000 (78%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 7808/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7809/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7810/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7811/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7812/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004638\n",
      "Train Epoch: 7813/10000 (78%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 7814/10000 (78%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 7815/10000 (78%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 7816/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7817/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7818/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7819/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7820/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7821/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7822/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7823/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7824/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7825/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7826/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7827/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7828/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7829/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7830/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7831/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7832/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7833/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7834/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7835/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7836/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7837/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7838/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7839/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7840/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7841/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7842/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7843/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7844/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7845/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7846/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7847/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7848/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7849/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7850/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7851/10000 (78%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7852/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7853/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7854/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7855/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7856/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7857/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7858/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7859/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7860/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7861/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7862/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7863/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7864/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7865/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7866/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7867/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7868/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7869/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7870/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7871/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7872/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7873/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7874/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7875/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7876/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7877/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7878/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7879/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7880/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7881/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7882/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7883/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7884/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7885/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7886/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7887/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7888/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7889/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7890/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7891/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7892/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7893/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7894/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7895/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7896/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7897/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7898/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7899/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7900/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7901/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7902/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7903/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7904/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7905/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 7906/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7907/10000 (79%)\ttrain_Loss: 0.004293\tval_Loss: 0.004639\n",
      "Train Epoch: 7908/10000 (79%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 7909/10000 (79%)\ttrain_Loss: 0.004294\tval_Loss: 0.004643\n",
      "Train Epoch: 7910/10000 (79%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 7911/10000 (79%)\ttrain_Loss: 0.004296\tval_Loss: 0.004647\n",
      "Train Epoch: 7912/10000 (79%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 7913/10000 (79%)\ttrain_Loss: 0.004300\tval_Loss: 0.004656\n",
      "Train Epoch: 7914/10000 (79%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 7915/10000 (79%)\ttrain_Loss: 0.004306\tval_Loss: 0.004667\n",
      "Train Epoch: 7916/10000 (79%)\ttrain_Loss: 0.004309\tval_Loss: 0.004632\n",
      "Train Epoch: 7917/10000 (79%)\ttrain_Loss: 0.004312\tval_Loss: 0.004675\n",
      "Train Epoch: 7918/10000 (79%)\ttrain_Loss: 0.004314\tval_Loss: 0.004633\n",
      "Train Epoch: 7919/10000 (79%)\ttrain_Loss: 0.004314\tval_Loss: 0.004670\n",
      "Train Epoch: 7920/10000 (79%)\ttrain_Loss: 0.004311\tval_Loss: 0.004628\n",
      "Train Epoch: 7921/10000 (79%)\ttrain_Loss: 0.004306\tval_Loss: 0.004651\n",
      "Train Epoch: 7922/10000 (79%)\ttrain_Loss: 0.004299\tval_Loss: 0.004626\n",
      "Train Epoch: 7923/10000 (79%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 7924/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7925/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 7926/10000 (79%)\ttrain_Loss: 0.004294\tval_Loss: 0.004648\n",
      "Train Epoch: 7927/10000 (79%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 7928/10000 (79%)\ttrain_Loss: 0.004299\tval_Loss: 0.004651\n",
      "Train Epoch: 7929/10000 (79%)\ttrain_Loss: 0.004299\tval_Loss: 0.004626\n",
      "Train Epoch: 7930/10000 (79%)\ttrain_Loss: 0.004297\tval_Loss: 0.004642\n",
      "Train Epoch: 7931/10000 (79%)\ttrain_Loss: 0.004295\tval_Loss: 0.004627\n",
      "Train Epoch: 7932/10000 (79%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 7933/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7934/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 7935/10000 (79%)\ttrain_Loss: 0.004293\tval_Loss: 0.004641\n",
      "Train Epoch: 7936/10000 (79%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 7937/10000 (79%)\ttrain_Loss: 0.004295\tval_Loss: 0.004641\n",
      "Train Epoch: 7938/10000 (79%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 7939/10000 (79%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 7940/10000 (79%)\ttrain_Loss: 0.004293\tval_Loss: 0.004629\n",
      "Train Epoch: 7941/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7942/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7943/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7944/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004637\n",
      "Train Epoch: 7945/10000 (79%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 7946/10000 (79%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 7947/10000 (79%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 7948/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7949/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7950/10000 (79%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7951/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7952/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7953/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7954/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 7955/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 7956/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7957/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 7958/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7959/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7960/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7961/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7962/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7963/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 7964/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7965/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7966/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7967/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7968/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7969/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7970/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7971/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7972/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7973/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7974/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7975/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7976/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7977/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 7978/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7979/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7980/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7981/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7982/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7983/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7984/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7985/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7986/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7987/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7988/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7989/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7990/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7991/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7992/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7993/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7994/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7995/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7996/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 7997/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 7998/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 7999/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8000/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8001/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8002/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8003/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8004/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8005/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8006/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8007/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8008/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8009/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8010/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8011/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8012/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8013/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8014/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8015/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8016/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8017/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8018/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8019/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8020/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8021/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8022/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8023/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8024/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8025/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8026/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8027/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8028/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8029/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8030/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8031/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8032/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8033/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8034/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8035/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 8036/10000 (80%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 8037/10000 (80%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n",
      "Train Epoch: 8038/10000 (80%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 8039/10000 (80%)\ttrain_Loss: 0.004294\tval_Loss: 0.004642\n",
      "Train Epoch: 8040/10000 (80%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 8041/10000 (80%)\ttrain_Loss: 0.004295\tval_Loss: 0.004647\n",
      "Train Epoch: 8042/10000 (80%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 8043/10000 (80%)\ttrain_Loss: 0.004299\tval_Loss: 0.004655\n",
      "Train Epoch: 8044/10000 (80%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 8045/10000 (80%)\ttrain_Loss: 0.004305\tval_Loss: 0.004666\n",
      "Train Epoch: 8046/10000 (80%)\ttrain_Loss: 0.004309\tval_Loss: 0.004631\n",
      "Train Epoch: 8047/10000 (80%)\ttrain_Loss: 0.004312\tval_Loss: 0.004676\n",
      "Train Epoch: 8048/10000 (80%)\ttrain_Loss: 0.004315\tval_Loss: 0.004633\n",
      "Train Epoch: 8049/10000 (80%)\ttrain_Loss: 0.004316\tval_Loss: 0.004674\n",
      "Train Epoch: 8050/10000 (80%)\ttrain_Loss: 0.004314\tval_Loss: 0.004629\n",
      "Train Epoch: 8051/10000 (80%)\ttrain_Loss: 0.004308\tval_Loss: 0.004655\n",
      "Train Epoch: 8052/10000 (81%)\ttrain_Loss: 0.004302\tval_Loss: 0.004626\n",
      "Train Epoch: 8053/10000 (81%)\ttrain_Loss: 0.004296\tval_Loss: 0.004635\n",
      "Train Epoch: 8054/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8055/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 8056/10000 (81%)\ttrain_Loss: 0.004294\tval_Loss: 0.004648\n",
      "Train Epoch: 8057/10000 (81%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 8058/10000 (81%)\ttrain_Loss: 0.004300\tval_Loss: 0.004652\n",
      "Train Epoch: 8059/10000 (81%)\ttrain_Loss: 0.004300\tval_Loss: 0.004626\n",
      "Train Epoch: 8060/10000 (81%)\ttrain_Loss: 0.004298\tval_Loss: 0.004644\n",
      "Train Epoch: 8061/10000 (81%)\ttrain_Loss: 0.004295\tval_Loss: 0.004627\n",
      "Train Epoch: 8062/10000 (81%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 8063/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8064/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 8065/10000 (81%)\ttrain_Loss: 0.004293\tval_Loss: 0.004641\n",
      "Train Epoch: 8066/10000 (81%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 8067/10000 (81%)\ttrain_Loss: 0.004295\tval_Loss: 0.004642\n",
      "Train Epoch: 8068/10000 (81%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 8069/10000 (81%)\ttrain_Loss: 0.004294\tval_Loss: 0.004636\n",
      "Train Epoch: 8070/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8071/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8072/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8073/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 8074/10000 (81%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n",
      "Train Epoch: 8075/10000 (81%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 8076/10000 (81%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 8077/10000 (81%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 8078/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8079/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8080/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8081/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8082/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8083/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 8084/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8085/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8086/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8087/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8088/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8089/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8090/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8091/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8092/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8093/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8094/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8095/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8096/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8097/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8098/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8099/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8100/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8101/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8102/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8103/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8104/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8105/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8106/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8107/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8108/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8109/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8110/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8111/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8112/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8113/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8114/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8115/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8116/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8117/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8118/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8119/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8120/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8121/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8122/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8123/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8124/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8125/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8126/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8127/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8128/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8129/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8130/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8131/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8132/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8133/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8134/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8135/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8136/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8137/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8138/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8139/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8140/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8141/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8142/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8143/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8144/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8145/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8146/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8147/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8148/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8149/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8150/10000 (81%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8151/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8152/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8153/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8154/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8155/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8156/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8157/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8158/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8159/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8160/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8161/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8162/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8163/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8164/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8165/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8166/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8167/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8168/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8169/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8170/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8171/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8172/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8173/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8174/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8175/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8176/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8177/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8178/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8179/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8180/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8181/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8182/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8183/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8184/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8185/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8186/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 8187/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 8188/10000 (82%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n",
      "Train Epoch: 8189/10000 (82%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 8190/10000 (82%)\ttrain_Loss: 0.004294\tval_Loss: 0.004644\n",
      "Train Epoch: 8191/10000 (82%)\ttrain_Loss: 0.004296\tval_Loss: 0.004626\n",
      "Train Epoch: 8192/10000 (82%)\ttrain_Loss: 0.004298\tval_Loss: 0.004656\n",
      "Train Epoch: 8193/10000 (82%)\ttrain_Loss: 0.004302\tval_Loss: 0.004629\n",
      "Train Epoch: 8194/10000 (82%)\ttrain_Loss: 0.004307\tval_Loss: 0.004676\n",
      "Train Epoch: 8195/10000 (82%)\ttrain_Loss: 0.004315\tval_Loss: 0.004639\n",
      "Train Epoch: 8196/10000 (82%)\ttrain_Loss: 0.004325\tval_Loss: 0.004704\n",
      "Train Epoch: 8197/10000 (82%)\ttrain_Loss: 0.004335\tval_Loss: 0.004649\n",
      "Train Epoch: 8198/10000 (82%)\ttrain_Loss: 0.004341\tval_Loss: 0.004710\n",
      "Train Epoch: 8199/10000 (82%)\ttrain_Loss: 0.004339\tval_Loss: 0.004639\n",
      "Train Epoch: 8200/10000 (82%)\ttrain_Loss: 0.004326\tval_Loss: 0.004665\n",
      "Train Epoch: 8201/10000 (82%)\ttrain_Loss: 0.004308\tval_Loss: 0.004626\n",
      "Train Epoch: 8202/10000 (82%)\ttrain_Loss: 0.004294\tval_Loss: 0.004628\n",
      "Train Epoch: 8203/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004652\n",
      "Train Epoch: 8204/10000 (82%)\ttrain_Loss: 0.004300\tval_Loss: 0.004630\n",
      "Train Epoch: 8205/10000 (82%)\ttrain_Loss: 0.004309\tval_Loss: 0.004672\n",
      "Train Epoch: 8206/10000 (82%)\ttrain_Loss: 0.004312\tval_Loss: 0.004628\n",
      "Train Epoch: 8207/10000 (82%)\ttrain_Loss: 0.004306\tval_Loss: 0.004646\n",
      "Train Epoch: 8208/10000 (82%)\ttrain_Loss: 0.004297\tval_Loss: 0.004629\n",
      "Train Epoch: 8209/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004626\n",
      "Train Epoch: 8210/10000 (82%)\ttrain_Loss: 0.004294\tval_Loss: 0.004651\n",
      "Train Epoch: 8211/10000 (82%)\ttrain_Loss: 0.004299\tval_Loss: 0.004627\n",
      "Train Epoch: 8212/10000 (82%)\ttrain_Loss: 0.004302\tval_Loss: 0.004653\n",
      "Train Epoch: 8213/10000 (82%)\ttrain_Loss: 0.004300\tval_Loss: 0.004626\n",
      "Train Epoch: 8214/10000 (82%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 8215/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 8216/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004626\n",
      "Train Epoch: 8217/10000 (82%)\ttrain_Loss: 0.004295\tval_Loss: 0.004646\n",
      "Train Epoch: 8218/10000 (82%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 8219/10000 (82%)\ttrain_Loss: 0.004296\tval_Loss: 0.004639\n",
      "Train Epoch: 8220/10000 (82%)\ttrain_Loss: 0.004293\tval_Loss: 0.004629\n",
      "Train Epoch: 8221/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8222/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004639\n",
      "Train Epoch: 8223/10000 (82%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 8224/10000 (82%)\ttrain_Loss: 0.004295\tval_Loss: 0.004640\n",
      "Train Epoch: 8225/10000 (82%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 8226/10000 (82%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 8227/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8228/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8229/10000 (82%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n",
      "Train Epoch: 8230/10000 (82%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 8231/10000 (82%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 8232/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8233/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8234/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8235/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8236/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 8237/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8238/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8239/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8240/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8241/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8242/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8243/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8244/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8245/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8246/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8247/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8248/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8249/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8250/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8251/10000 (82%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8252/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8253/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8254/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8255/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8256/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8257/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8258/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8259/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8260/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8261/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8262/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8263/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8264/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8265/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8266/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8267/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8268/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8269/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8270/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8271/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8272/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8273/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8274/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8275/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8276/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8277/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8278/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8279/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8280/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8281/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8282/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8283/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8284/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8285/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8286/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8287/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8288/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8289/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8290/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8291/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8292/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8293/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8294/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8295/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8296/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8297/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8298/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8299/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8300/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8301/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8302/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8303/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8304/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8305/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8306/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8307/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8308/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8309/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8310/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8311/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8312/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8313/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8314/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8315/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8316/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8317/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8318/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8319/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8320/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8321/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8322/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8323/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8324/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8325/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8326/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8327/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8328/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8329/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8330/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8331/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8332/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8333/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8334/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8335/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8336/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8337/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8338/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8339/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8340/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8341/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8342/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8343/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8344/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8345/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8346/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8347/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8348/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8349/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8350/10000 (83%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8351/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8352/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8353/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8354/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8355/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8356/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8357/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8358/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8359/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8360/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8361/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8362/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8363/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8364/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8365/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8366/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8367/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8368/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8369/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8370/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8371/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8372/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8373/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8374/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8375/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8376/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8377/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8378/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8379/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8380/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8381/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8382/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8383/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8384/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8385/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8386/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8387/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8388/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8389/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8390/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8391/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8392/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8393/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8394/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8395/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8396/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8397/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8398/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8399/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8400/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8401/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8402/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8403/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8404/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8405/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8406/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8407/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8408/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8409/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 8410/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8411/10000 (84%)\ttrain_Loss: 0.004293\tval_Loss: 0.004639\n",
      "Train Epoch: 8412/10000 (84%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 8413/10000 (84%)\ttrain_Loss: 0.004295\tval_Loss: 0.004646\n",
      "Train Epoch: 8414/10000 (84%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 8415/10000 (84%)\ttrain_Loss: 0.004299\tval_Loss: 0.004658\n",
      "Train Epoch: 8416/10000 (84%)\ttrain_Loss: 0.004303\tval_Loss: 0.004630\n",
      "Train Epoch: 8417/10000 (84%)\ttrain_Loss: 0.004309\tval_Loss: 0.004679\n",
      "Train Epoch: 8418/10000 (84%)\ttrain_Loss: 0.004317\tval_Loss: 0.004640\n",
      "Train Epoch: 8419/10000 (84%)\ttrain_Loss: 0.004327\tval_Loss: 0.004705\n",
      "Train Epoch: 8420/10000 (84%)\ttrain_Loss: 0.004336\tval_Loss: 0.004649\n",
      "Train Epoch: 8421/10000 (84%)\ttrain_Loss: 0.004340\tval_Loss: 0.004705\n",
      "Train Epoch: 8422/10000 (84%)\ttrain_Loss: 0.004335\tval_Loss: 0.004636\n",
      "Train Epoch: 8423/10000 (84%)\ttrain_Loss: 0.004321\tval_Loss: 0.004658\n",
      "Train Epoch: 8424/10000 (84%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 8425/10000 (84%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 8426/10000 (84%)\ttrain_Loss: 0.004293\tval_Loss: 0.004654\n",
      "Train Epoch: 8427/10000 (84%)\ttrain_Loss: 0.004301\tval_Loss: 0.004630\n",
      "Train Epoch: 8428/10000 (84%)\ttrain_Loss: 0.004309\tval_Loss: 0.004670\n",
      "Train Epoch: 8429/10000 (84%)\ttrain_Loss: 0.004311\tval_Loss: 0.004628\n",
      "Train Epoch: 8430/10000 (84%)\ttrain_Loss: 0.004304\tval_Loss: 0.004644\n",
      "Train Epoch: 8431/10000 (84%)\ttrain_Loss: 0.004296\tval_Loss: 0.004630\n",
      "Train Epoch: 8432/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004626\n",
      "Train Epoch: 8433/10000 (84%)\ttrain_Loss: 0.004294\tval_Loss: 0.004650\n",
      "Train Epoch: 8434/10000 (84%)\ttrain_Loss: 0.004299\tval_Loss: 0.004627\n",
      "Train Epoch: 8435/10000 (84%)\ttrain_Loss: 0.004301\tval_Loss: 0.004651\n",
      "Train Epoch: 8436/10000 (84%)\ttrain_Loss: 0.004299\tval_Loss: 0.004626\n",
      "Train Epoch: 8437/10000 (84%)\ttrain_Loss: 0.004295\tval_Loss: 0.004633\n",
      "Train Epoch: 8438/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 8439/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004626\n",
      "Train Epoch: 8440/10000 (84%)\ttrain_Loss: 0.004295\tval_Loss: 0.004646\n",
      "Train Epoch: 8441/10000 (84%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 8442/10000 (84%)\ttrain_Loss: 0.004296\tval_Loss: 0.004638\n",
      "Train Epoch: 8443/10000 (84%)\ttrain_Loss: 0.004293\tval_Loss: 0.004629\n",
      "Train Epoch: 8444/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8445/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004639\n",
      "Train Epoch: 8446/10000 (84%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 8447/10000 (84%)\ttrain_Loss: 0.004294\tval_Loss: 0.004640\n",
      "Train Epoch: 8448/10000 (84%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 8449/10000 (84%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 8450/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8451/10000 (84%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 8452/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004637\n",
      "Train Epoch: 8453/10000 (85%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 8454/10000 (85%)\ttrain_Loss: 0.004293\tval_Loss: 0.004636\n",
      "Train Epoch: 8455/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8456/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8457/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8458/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 8459/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 8460/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8461/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8462/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8463/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8464/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8465/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8466/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8467/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8468/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8469/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8470/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8471/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8472/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8473/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8474/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8475/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8476/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8477/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8478/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8479/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8480/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8481/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8482/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8483/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8484/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8485/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8486/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8487/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8488/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8489/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8490/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8491/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8492/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8493/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8494/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8495/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8496/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8497/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8498/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8499/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8500/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8501/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8502/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8503/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8504/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8505/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8506/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8507/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8508/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8509/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8510/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8511/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8512/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8513/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8514/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8515/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8516/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8517/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8518/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8519/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8520/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8521/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8522/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8523/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8524/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8525/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8526/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8527/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8528/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8529/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8530/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8531/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8532/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8533/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8534/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8535/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8536/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8537/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8538/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8539/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8540/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8541/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8542/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8543/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8544/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8545/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8546/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8547/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8548/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8549/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8550/10000 (85%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8551/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8552/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8553/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8554/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8555/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8556/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8557/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8558/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8559/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8560/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8561/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8562/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8563/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8564/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8565/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8566/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8567/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8568/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8569/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8570/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8571/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8572/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8573/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8574/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8575/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8576/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8577/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8578/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8579/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8580/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8581/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8582/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8583/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8584/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8585/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8586/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8587/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8588/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8589/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8590/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8591/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8592/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8593/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8594/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8595/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8596/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8597/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8598/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8599/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8600/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8601/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8602/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8603/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8604/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8605/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8606/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8607/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8608/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8609/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8610/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8611/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8612/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8613/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 8614/10000 (86%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 8615/10000 (86%)\ttrain_Loss: 0.004293\tval_Loss: 0.004640\n",
      "Train Epoch: 8616/10000 (86%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 8617/10000 (86%)\ttrain_Loss: 0.004295\tval_Loss: 0.004645\n",
      "Train Epoch: 8618/10000 (86%)\ttrain_Loss: 0.004296\tval_Loss: 0.004626\n",
      "Train Epoch: 8619/10000 (86%)\ttrain_Loss: 0.004298\tval_Loss: 0.004652\n",
      "Train Epoch: 8620/10000 (86%)\ttrain_Loss: 0.004300\tval_Loss: 0.004627\n",
      "Train Epoch: 8621/10000 (86%)\ttrain_Loss: 0.004303\tval_Loss: 0.004663\n",
      "Train Epoch: 8622/10000 (86%)\ttrain_Loss: 0.004307\tval_Loss: 0.004630\n",
      "Train Epoch: 8623/10000 (86%)\ttrain_Loss: 0.004311\tval_Loss: 0.004675\n",
      "Train Epoch: 8624/10000 (86%)\ttrain_Loss: 0.004315\tval_Loss: 0.004633\n",
      "Train Epoch: 8625/10000 (86%)\ttrain_Loss: 0.004317\tval_Loss: 0.004679\n",
      "Train Epoch: 8626/10000 (86%)\ttrain_Loss: 0.004317\tval_Loss: 0.004632\n",
      "Train Epoch: 8627/10000 (86%)\ttrain_Loss: 0.004314\tval_Loss: 0.004664\n",
      "Train Epoch: 8628/10000 (86%)\ttrain_Loss: 0.004307\tval_Loss: 0.004627\n",
      "Train Epoch: 8629/10000 (86%)\ttrain_Loss: 0.004299\tval_Loss: 0.004640\n",
      "Train Epoch: 8630/10000 (86%)\ttrain_Loss: 0.004294\tval_Loss: 0.004631\n",
      "Train Epoch: 8631/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 8632/10000 (86%)\ttrain_Loss: 0.004293\tval_Loss: 0.004644\n",
      "Train Epoch: 8633/10000 (86%)\ttrain_Loss: 0.004296\tval_Loss: 0.004626\n",
      "Train Epoch: 8634/10000 (86%)\ttrain_Loss: 0.004299\tval_Loss: 0.004652\n",
      "Train Epoch: 8635/10000 (86%)\ttrain_Loss: 0.004300\tval_Loss: 0.004626\n",
      "Train Epoch: 8636/10000 (86%)\ttrain_Loss: 0.004299\tval_Loss: 0.004646\n",
      "Train Epoch: 8637/10000 (86%)\ttrain_Loss: 0.004297\tval_Loss: 0.004627\n",
      "Train Epoch: 8638/10000 (86%)\ttrain_Loss: 0.004294\tval_Loss: 0.004634\n",
      "Train Epoch: 8639/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8640/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 8641/10000 (86%)\ttrain_Loss: 0.004293\tval_Loss: 0.004640\n",
      "Train Epoch: 8642/10000 (86%)\ttrain_Loss: 0.004294\tval_Loss: 0.004625\n",
      "Train Epoch: 8643/10000 (86%)\ttrain_Loss: 0.004295\tval_Loss: 0.004642\n",
      "Train Epoch: 8644/10000 (86%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 8645/10000 (86%)\ttrain_Loss: 0.004294\tval_Loss: 0.004637\n",
      "Train Epoch: 8646/10000 (86%)\ttrain_Loss: 0.004293\tval_Loss: 0.004630\n",
      "Train Epoch: 8647/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8648/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8649/10000 (86%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 8650/10000 (86%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 8651/10000 (86%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 8652/10000 (87%)\ttrain_Loss: 0.004293\tval_Loss: 0.004636\n",
      "Train Epoch: 8653/10000 (87%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 8654/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8655/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8656/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8657/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8658/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8659/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 8660/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8661/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8662/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8663/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8664/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8665/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8666/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8667/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8668/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8669/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8670/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8671/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8672/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8673/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8674/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8675/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8676/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8677/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8678/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8679/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8680/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8681/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8682/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8683/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8684/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8685/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8686/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8687/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8688/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8689/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8690/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8691/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8692/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8693/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8694/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8695/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8696/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8697/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8698/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8699/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8700/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8701/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8702/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8703/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8704/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8705/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8706/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8707/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8708/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8709/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8710/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8711/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8712/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8713/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8714/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8715/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8716/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8717/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8718/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8719/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8720/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8721/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8722/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8723/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8724/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8725/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8726/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8727/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8728/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8729/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8730/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8731/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8732/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8733/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8734/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8735/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8736/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8737/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8738/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8739/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8740/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8741/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8742/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8743/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8744/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8745/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8746/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8747/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8748/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8749/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8750/10000 (87%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8751/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8752/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8753/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8754/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8755/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 8756/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8757/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004637\n",
      "Train Epoch: 8758/10000 (88%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 8759/10000 (88%)\ttrain_Loss: 0.004293\tval_Loss: 0.004640\n",
      "Train Epoch: 8760/10000 (88%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 8761/10000 (88%)\ttrain_Loss: 0.004295\tval_Loss: 0.004647\n",
      "Train Epoch: 8762/10000 (88%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 8763/10000 (88%)\ttrain_Loss: 0.004300\tval_Loss: 0.004658\n",
      "Train Epoch: 8764/10000 (88%)\ttrain_Loss: 0.004303\tval_Loss: 0.004629\n",
      "Train Epoch: 8765/10000 (88%)\ttrain_Loss: 0.004308\tval_Loss: 0.004674\n",
      "Train Epoch: 8766/10000 (88%)\ttrain_Loss: 0.004314\tval_Loss: 0.004635\n",
      "Train Epoch: 8767/10000 (88%)\ttrain_Loss: 0.004320\tval_Loss: 0.004690\n",
      "Train Epoch: 8768/10000 (88%)\ttrain_Loss: 0.004325\tval_Loss: 0.004639\n",
      "Train Epoch: 8769/10000 (88%)\ttrain_Loss: 0.004326\tval_Loss: 0.004685\n",
      "Train Epoch: 8770/10000 (88%)\ttrain_Loss: 0.004322\tval_Loss: 0.004631\n",
      "Train Epoch: 8771/10000 (88%)\ttrain_Loss: 0.004312\tval_Loss: 0.004654\n",
      "Train Epoch: 8772/10000 (88%)\ttrain_Loss: 0.004301\tval_Loss: 0.004627\n",
      "Train Epoch: 8773/10000 (88%)\ttrain_Loss: 0.004293\tval_Loss: 0.004629\n",
      "Train Epoch: 8774/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004643\n",
      "Train Epoch: 8775/10000 (88%)\ttrain_Loss: 0.004295\tval_Loss: 0.004627\n",
      "Train Epoch: 8776/10000 (88%)\ttrain_Loss: 0.004301\tval_Loss: 0.004660\n",
      "Train Epoch: 8777/10000 (88%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 8778/10000 (88%)\ttrain_Loss: 0.004304\tval_Loss: 0.004651\n",
      "Train Epoch: 8779/10000 (88%)\ttrain_Loss: 0.004299\tval_Loss: 0.004626\n",
      "Train Epoch: 8780/10000 (88%)\ttrain_Loss: 0.004294\tval_Loss: 0.004632\n",
      "Train Epoch: 8781/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 8782/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004626\n",
      "Train Epoch: 8783/10000 (88%)\ttrain_Loss: 0.004295\tval_Loss: 0.004647\n",
      "Train Epoch: 8784/10000 (88%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 8785/10000 (88%)\ttrain_Loss: 0.004297\tval_Loss: 0.004644\n",
      "Train Epoch: 8786/10000 (88%)\ttrain_Loss: 0.004296\tval_Loss: 0.004626\n",
      "Train Epoch: 8787/10000 (88%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 8788/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8789/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 8790/10000 (88%)\ttrain_Loss: 0.004293\tval_Loss: 0.004640\n",
      "Train Epoch: 8791/10000 (88%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 8792/10000 (88%)\ttrain_Loss: 0.004294\tval_Loss: 0.004639\n",
      "Train Epoch: 8793/10000 (88%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 8794/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8795/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8796/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8797/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004637\n",
      "Train Epoch: 8798/10000 (88%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 8799/10000 (88%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 8800/10000 (88%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 8801/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8802/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8803/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8804/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 8805/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8806/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 8807/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8808/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8809/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8810/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8811/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8812/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8813/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8814/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8815/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8816/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8817/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8818/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8819/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8820/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8821/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8822/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8823/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8824/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8825/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8826/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8827/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8828/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8829/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8830/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8831/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8832/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8833/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8834/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8835/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8836/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8837/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8838/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8839/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8840/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8841/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8842/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8843/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8844/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8845/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8846/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8847/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8848/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8849/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8850/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8851/10000 (88%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8852/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8853/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8854/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8855/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8856/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8857/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8858/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8859/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8860/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8861/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8862/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8863/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8864/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8865/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8866/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8867/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8868/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8869/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8870/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8871/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8872/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8873/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8874/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8875/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8876/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8877/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8878/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8879/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8880/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8881/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8882/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8883/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8884/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8885/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8886/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8887/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8888/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8889/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8890/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8891/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8892/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8893/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8894/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8895/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8896/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8897/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8898/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8899/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8900/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8901/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8902/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8903/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8904/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8905/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8906/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8907/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8908/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8909/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8910/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8911/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8912/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8913/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8914/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8915/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8916/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8917/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8918/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8919/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8920/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8921/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8922/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8923/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8924/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8925/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8926/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8927/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 8928/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 8929/10000 (89%)\ttrain_Loss: 0.004293\tval_Loss: 0.004639\n",
      "Train Epoch: 8930/10000 (89%)\ttrain_Loss: 0.004293\tval_Loss: 0.004626\n",
      "Train Epoch: 8931/10000 (89%)\ttrain_Loss: 0.004294\tval_Loss: 0.004644\n",
      "Train Epoch: 8932/10000 (89%)\ttrain_Loss: 0.004296\tval_Loss: 0.004626\n",
      "Train Epoch: 8933/10000 (89%)\ttrain_Loss: 0.004298\tval_Loss: 0.004653\n",
      "Train Epoch: 8934/10000 (89%)\ttrain_Loss: 0.004300\tval_Loss: 0.004627\n",
      "Train Epoch: 8935/10000 (89%)\ttrain_Loss: 0.004304\tval_Loss: 0.004667\n",
      "Train Epoch: 8936/10000 (89%)\ttrain_Loss: 0.004309\tval_Loss: 0.004633\n",
      "Train Epoch: 8937/10000 (89%)\ttrain_Loss: 0.004315\tval_Loss: 0.004684\n",
      "Train Epoch: 8938/10000 (89%)\ttrain_Loss: 0.004321\tval_Loss: 0.004638\n",
      "Train Epoch: 8939/10000 (89%)\ttrain_Loss: 0.004324\tval_Loss: 0.004689\n",
      "Train Epoch: 8940/10000 (89%)\ttrain_Loss: 0.004325\tval_Loss: 0.004635\n",
      "Train Epoch: 8941/10000 (89%)\ttrain_Loss: 0.004319\tval_Loss: 0.004667\n",
      "Train Epoch: 8942/10000 (89%)\ttrain_Loss: 0.004309\tval_Loss: 0.004626\n",
      "Train Epoch: 8943/10000 (89%)\ttrain_Loss: 0.004299\tval_Loss: 0.004636\n",
      "Train Epoch: 8944/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8945/10000 (89%)\ttrain_Loss: 0.004292\tval_Loss: 0.004626\n",
      "Train Epoch: 8946/10000 (89%)\ttrain_Loss: 0.004296\tval_Loss: 0.004654\n",
      "Train Epoch: 8947/10000 (89%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 8948/10000 (89%)\ttrain_Loss: 0.004304\tval_Loss: 0.004657\n",
      "Train Epoch: 8949/10000 (89%)\ttrain_Loss: 0.004303\tval_Loss: 0.004626\n",
      "Train Epoch: 8950/10000 (89%)\ttrain_Loss: 0.004298\tval_Loss: 0.004640\n",
      "Train Epoch: 8951/10000 (90%)\ttrain_Loss: 0.004294\tval_Loss: 0.004630\n",
      "Train Epoch: 8952/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8953/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004642\n",
      "Train Epoch: 8954/10000 (90%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 8955/10000 (90%)\ttrain_Loss: 0.004297\tval_Loss: 0.004646\n",
      "Train Epoch: 8956/10000 (90%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 8957/10000 (90%)\ttrain_Loss: 0.004295\tval_Loss: 0.004637\n",
      "Train Epoch: 8958/10000 (90%)\ttrain_Loss: 0.004293\tval_Loss: 0.004629\n",
      "Train Epoch: 8959/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8960/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004637\n",
      "Train Epoch: 8961/10000 (90%)\ttrain_Loss: 0.004293\tval_Loss: 0.004626\n",
      "Train Epoch: 8962/10000 (90%)\ttrain_Loss: 0.004294\tval_Loss: 0.004641\n",
      "Train Epoch: 8963/10000 (90%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 8964/10000 (90%)\ttrain_Loss: 0.004294\tval_Loss: 0.004637\n",
      "Train Epoch: 8965/10000 (90%)\ttrain_Loss: 0.004293\tval_Loss: 0.004629\n",
      "Train Epoch: 8966/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8967/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8968/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 8969/10000 (90%)\ttrain_Loss: 0.004293\tval_Loss: 0.004636\n",
      "Train Epoch: 8970/10000 (90%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 8971/10000 (90%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 8972/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8973/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8974/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8975/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8976/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8977/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 8978/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 8979/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8980/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8981/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8982/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8983/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8984/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8985/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 8986/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8987/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8988/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8989/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8990/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8991/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 8992/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 8993/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8994/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8995/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 8996/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8997/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8998/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 8999/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9000/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9001/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9002/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9003/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9004/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9005/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9006/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9007/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9008/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9009/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9010/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9011/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9012/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9013/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9014/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9015/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9016/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9017/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9018/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9019/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9020/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9021/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9022/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9023/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9024/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9025/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9026/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9027/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9028/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9029/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9030/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9031/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9032/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9033/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9034/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9035/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9036/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9037/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9038/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9039/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9040/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9041/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9042/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9043/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9044/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9045/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9046/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9047/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9048/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9049/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9050/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9051/10000 (90%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9052/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9053/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9054/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9055/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9056/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9057/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9058/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9059/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9060/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9061/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9062/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9063/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9064/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9065/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9066/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9067/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9068/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9069/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9070/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9071/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9072/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9073/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9074/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9075/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9076/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9077/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9078/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9079/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9080/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9081/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 9082/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9083/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 9084/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 9085/10000 (91%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 9086/10000 (91%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 9087/10000 (91%)\ttrain_Loss: 0.004293\tval_Loss: 0.004641\n",
      "Train Epoch: 9088/10000 (91%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 9089/10000 (91%)\ttrain_Loss: 0.004295\tval_Loss: 0.004645\n",
      "Train Epoch: 9090/10000 (91%)\ttrain_Loss: 0.004296\tval_Loss: 0.004626\n",
      "Train Epoch: 9091/10000 (91%)\ttrain_Loss: 0.004297\tval_Loss: 0.004651\n",
      "Train Epoch: 9092/10000 (91%)\ttrain_Loss: 0.004299\tval_Loss: 0.004626\n",
      "Train Epoch: 9093/10000 (91%)\ttrain_Loss: 0.004301\tval_Loss: 0.004657\n",
      "Train Epoch: 9094/10000 (91%)\ttrain_Loss: 0.004304\tval_Loss: 0.004628\n",
      "Train Epoch: 9095/10000 (91%)\ttrain_Loss: 0.004306\tval_Loss: 0.004664\n",
      "Train Epoch: 9096/10000 (91%)\ttrain_Loss: 0.004308\tval_Loss: 0.004629\n",
      "Train Epoch: 9097/10000 (91%)\ttrain_Loss: 0.004309\tval_Loss: 0.004666\n",
      "Train Epoch: 9098/10000 (91%)\ttrain_Loss: 0.004309\tval_Loss: 0.004629\n",
      "Train Epoch: 9099/10000 (91%)\ttrain_Loss: 0.004307\tval_Loss: 0.004658\n",
      "Train Epoch: 9100/10000 (91%)\ttrain_Loss: 0.004303\tval_Loss: 0.004627\n",
      "Train Epoch: 9101/10000 (91%)\ttrain_Loss: 0.004299\tval_Loss: 0.004643\n",
      "Train Epoch: 9102/10000 (91%)\ttrain_Loss: 0.004295\tval_Loss: 0.004628\n",
      "Train Epoch: 9103/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9104/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 9105/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004626\n",
      "Train Epoch: 9106/10000 (91%)\ttrain_Loss: 0.004294\tval_Loss: 0.004644\n",
      "Train Epoch: 9107/10000 (91%)\ttrain_Loss: 0.004296\tval_Loss: 0.004626\n",
      "Train Epoch: 9108/10000 (91%)\ttrain_Loss: 0.004297\tval_Loss: 0.004646\n",
      "Train Epoch: 9109/10000 (91%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 9110/10000 (91%)\ttrain_Loss: 0.004296\tval_Loss: 0.004641\n",
      "Train Epoch: 9111/10000 (91%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 9112/10000 (91%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 9113/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9114/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9115/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 9116/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004626\n",
      "Train Epoch: 9117/10000 (91%)\ttrain_Loss: 0.004293\tval_Loss: 0.004639\n",
      "Train Epoch: 9118/10000 (91%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 9119/10000 (91%)\ttrain_Loss: 0.004294\tval_Loss: 0.004639\n",
      "Train Epoch: 9120/10000 (91%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 9121/10000 (91%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 9122/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9123/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9124/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9125/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9126/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 9127/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9128/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 9129/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9130/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9131/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9132/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9133/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9134/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9135/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9136/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9137/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9138/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9139/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9140/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9141/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9142/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9143/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9144/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9145/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9146/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9147/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9148/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9149/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9150/10000 (91%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9151/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9152/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9153/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9154/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9155/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9156/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9157/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9158/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9159/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9160/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9161/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9162/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9163/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9164/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9165/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9166/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9167/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9168/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9169/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9170/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9171/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9172/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9173/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9174/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9175/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9176/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9177/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9178/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9179/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9180/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9181/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9182/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9183/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9184/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9185/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9186/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9187/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9188/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9189/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9190/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9191/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9192/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9193/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9194/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9195/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9196/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 9197/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 9198/10000 (92%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9199/10000 (92%)\ttrain_Loss: 0.004293\tval_Loss: 0.004626\n",
      "Train Epoch: 9200/10000 (92%)\ttrain_Loss: 0.004294\tval_Loss: 0.004642\n",
      "Train Epoch: 9201/10000 (92%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 9202/10000 (92%)\ttrain_Loss: 0.004296\tval_Loss: 0.004647\n",
      "Train Epoch: 9203/10000 (92%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 9204/10000 (92%)\ttrain_Loss: 0.004299\tval_Loss: 0.004654\n",
      "Train Epoch: 9205/10000 (92%)\ttrain_Loss: 0.004302\tval_Loss: 0.004627\n",
      "Train Epoch: 9206/10000 (92%)\ttrain_Loss: 0.004305\tval_Loss: 0.004665\n",
      "Train Epoch: 9207/10000 (92%)\ttrain_Loss: 0.004308\tval_Loss: 0.004631\n",
      "Train Epoch: 9208/10000 (92%)\ttrain_Loss: 0.004311\tval_Loss: 0.004674\n",
      "Train Epoch: 9209/10000 (92%)\ttrain_Loss: 0.004314\tval_Loss: 0.004632\n",
      "Train Epoch: 9210/10000 (92%)\ttrain_Loss: 0.004314\tval_Loss: 0.004671\n",
      "Train Epoch: 9211/10000 (92%)\ttrain_Loss: 0.004312\tval_Loss: 0.004628\n",
      "Train Epoch: 9212/10000 (92%)\ttrain_Loss: 0.004306\tval_Loss: 0.004653\n",
      "Train Epoch: 9213/10000 (92%)\ttrain_Loss: 0.004300\tval_Loss: 0.004626\n",
      "Train Epoch: 9214/10000 (92%)\ttrain_Loss: 0.004295\tval_Loss: 0.004634\n",
      "Train Epoch: 9215/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9216/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 9217/10000 (92%)\ttrain_Loss: 0.004294\tval_Loss: 0.004646\n",
      "Train Epoch: 9218/10000 (92%)\ttrain_Loss: 0.004296\tval_Loss: 0.004626\n",
      "Train Epoch: 9219/10000 (92%)\ttrain_Loss: 0.004299\tval_Loss: 0.004650\n",
      "Train Epoch: 9220/10000 (92%)\ttrain_Loss: 0.004299\tval_Loss: 0.004626\n",
      "Train Epoch: 9221/10000 (92%)\ttrain_Loss: 0.004298\tval_Loss: 0.004643\n",
      "Train Epoch: 9222/10000 (92%)\ttrain_Loss: 0.004295\tval_Loss: 0.004627\n",
      "Train Epoch: 9223/10000 (92%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 9224/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9225/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 9226/10000 (92%)\ttrain_Loss: 0.004293\tval_Loss: 0.004639\n",
      "Train Epoch: 9227/10000 (92%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 9228/10000 (92%)\ttrain_Loss: 0.004295\tval_Loss: 0.004641\n",
      "Train Epoch: 9229/10000 (92%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 9230/10000 (92%)\ttrain_Loss: 0.004294\tval_Loss: 0.004637\n",
      "Train Epoch: 9231/10000 (92%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 9232/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9233/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9234/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9235/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 9236/10000 (92%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 9237/10000 (92%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 9238/10000 (92%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 9239/10000 (92%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 9240/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9241/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9242/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9243/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9244/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9245/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9246/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 9247/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9248/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9249/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9250/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9251/10000 (92%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9252/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9253/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9254/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9255/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9256/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9257/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9258/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9259/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9260/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9261/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9262/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9263/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9264/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9265/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9266/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9267/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9268/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9269/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9270/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9271/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9272/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9273/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9274/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9275/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9276/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9277/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9278/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9279/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9280/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9281/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9282/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9283/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9284/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9285/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9286/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9287/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9288/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9289/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9290/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9291/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9292/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9293/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9294/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9295/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9296/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9297/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9298/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9299/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9300/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9301/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9302/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9303/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9304/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9305/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9306/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9307/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9308/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9309/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9310/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9311/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9312/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9313/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9314/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9315/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9316/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9317/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9318/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9319/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9320/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9321/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9322/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 9323/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 9324/10000 (93%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n",
      "Train Epoch: 9325/10000 (93%)\ttrain_Loss: 0.004293\tval_Loss: 0.004626\n",
      "Train Epoch: 9326/10000 (93%)\ttrain_Loss: 0.004294\tval_Loss: 0.004641\n",
      "Train Epoch: 9327/10000 (93%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 9328/10000 (93%)\ttrain_Loss: 0.004295\tval_Loss: 0.004645\n",
      "Train Epoch: 9329/10000 (93%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 9330/10000 (93%)\ttrain_Loss: 0.004298\tval_Loss: 0.004653\n",
      "Train Epoch: 9331/10000 (93%)\ttrain_Loss: 0.004300\tval_Loss: 0.004627\n",
      "Train Epoch: 9332/10000 (93%)\ttrain_Loss: 0.004302\tval_Loss: 0.004661\n",
      "Train Epoch: 9333/10000 (93%)\ttrain_Loss: 0.004305\tval_Loss: 0.004629\n",
      "Train Epoch: 9334/10000 (93%)\ttrain_Loss: 0.004307\tval_Loss: 0.004667\n",
      "Train Epoch: 9335/10000 (93%)\ttrain_Loss: 0.004309\tval_Loss: 0.004629\n",
      "Train Epoch: 9336/10000 (93%)\ttrain_Loss: 0.004310\tval_Loss: 0.004666\n",
      "Train Epoch: 9337/10000 (93%)\ttrain_Loss: 0.004309\tval_Loss: 0.004627\n",
      "Train Epoch: 9338/10000 (93%)\ttrain_Loss: 0.004306\tval_Loss: 0.004654\n",
      "Train Epoch: 9339/10000 (93%)\ttrain_Loss: 0.004301\tval_Loss: 0.004626\n",
      "Train Epoch: 9340/10000 (93%)\ttrain_Loss: 0.004297\tval_Loss: 0.004639\n",
      "Train Epoch: 9341/10000 (93%)\ttrain_Loss: 0.004293\tval_Loss: 0.004630\n",
      "Train Epoch: 9342/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9343/10000 (93%)\ttrain_Loss: 0.004292\tval_Loss: 0.004639\n",
      "Train Epoch: 9344/10000 (93%)\ttrain_Loss: 0.004293\tval_Loss: 0.004626\n",
      "Train Epoch: 9345/10000 (93%)\ttrain_Loss: 0.004295\tval_Loss: 0.004646\n",
      "Train Epoch: 9346/10000 (93%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 9347/10000 (93%)\ttrain_Loss: 0.004297\tval_Loss: 0.004646\n",
      "Train Epoch: 9348/10000 (93%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 9349/10000 (93%)\ttrain_Loss: 0.004295\tval_Loss: 0.004639\n",
      "Train Epoch: 9350/10000 (93%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 9351/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9352/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9353/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9354/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004638\n",
      "Train Epoch: 9355/10000 (94%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 9356/10000 (94%)\ttrain_Loss: 0.004294\tval_Loss: 0.004639\n",
      "Train Epoch: 9357/10000 (94%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 9358/10000 (94%)\ttrain_Loss: 0.004293\tval_Loss: 0.004636\n",
      "Train Epoch: 9359/10000 (94%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 9360/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9361/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9362/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9363/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9364/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9365/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 9366/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9367/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 9368/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9369/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9370/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9371/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9372/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9373/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9374/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9375/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9376/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9377/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9378/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9379/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9380/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9381/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9382/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9383/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9384/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9385/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9386/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9387/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9388/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9389/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9390/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9391/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9392/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9393/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9394/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9395/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9396/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9397/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9398/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9399/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9400/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9401/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9402/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9403/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9404/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9405/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9406/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9407/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9408/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9409/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9410/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9411/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9412/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9413/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9414/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9415/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9416/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9417/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9418/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9419/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9420/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9421/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9422/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9423/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9424/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9425/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9426/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9427/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9428/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9429/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9430/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9431/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9432/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 9433/10000 (94%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 9434/10000 (94%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 9435/10000 (94%)\ttrain_Loss: 0.004293\tval_Loss: 0.004626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9436/10000 (94%)\ttrain_Loss: 0.004293\tval_Loss: 0.004639\n",
      "Train Epoch: 9437/10000 (94%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 9438/10000 (94%)\ttrain_Loss: 0.004294\tval_Loss: 0.004643\n",
      "Train Epoch: 9439/10000 (94%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 9440/10000 (94%)\ttrain_Loss: 0.004296\tval_Loss: 0.004648\n",
      "Train Epoch: 9441/10000 (94%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 9442/10000 (94%)\ttrain_Loss: 0.004299\tval_Loss: 0.004653\n",
      "Train Epoch: 9443/10000 (94%)\ttrain_Loss: 0.004301\tval_Loss: 0.004626\n",
      "Train Epoch: 9444/10000 (94%)\ttrain_Loss: 0.004303\tval_Loss: 0.004659\n",
      "Train Epoch: 9445/10000 (94%)\ttrain_Loss: 0.004305\tval_Loss: 0.004628\n",
      "Train Epoch: 9446/10000 (94%)\ttrain_Loss: 0.004306\tval_Loss: 0.004662\n",
      "Train Epoch: 9447/10000 (94%)\ttrain_Loss: 0.004306\tval_Loss: 0.004628\n",
      "Train Epoch: 9448/10000 (94%)\ttrain_Loss: 0.004305\tval_Loss: 0.004659\n",
      "Train Epoch: 9449/10000 (94%)\ttrain_Loss: 0.004304\tval_Loss: 0.004627\n",
      "Train Epoch: 9450/10000 (94%)\ttrain_Loss: 0.004301\tval_Loss: 0.004647\n",
      "Train Epoch: 9451/10000 (94%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 9452/10000 (95%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 9453/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9454/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9455/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004637\n",
      "Train Epoch: 9456/10000 (95%)\ttrain_Loss: 0.004293\tval_Loss: 0.004626\n",
      "Train Epoch: 9457/10000 (95%)\ttrain_Loss: 0.004294\tval_Loss: 0.004643\n",
      "Train Epoch: 9458/10000 (95%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 9459/10000 (95%)\ttrain_Loss: 0.004296\tval_Loss: 0.004643\n",
      "Train Epoch: 9460/10000 (95%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 9461/10000 (95%)\ttrain_Loss: 0.004295\tval_Loss: 0.004639\n",
      "Train Epoch: 9462/10000 (95%)\ttrain_Loss: 0.004294\tval_Loss: 0.004627\n",
      "Train Epoch: 9463/10000 (95%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 9464/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9465/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9466/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9467/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9468/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004637\n",
      "Train Epoch: 9469/10000 (95%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 9470/10000 (95%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 9471/10000 (95%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 9472/10000 (95%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 9473/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9474/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9475/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9476/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9477/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9478/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9479/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9480/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9481/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9482/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9483/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9484/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9485/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9486/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9487/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9488/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9489/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9490/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9491/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9492/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9493/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9494/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9495/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9496/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9497/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9498/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9499/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9500/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9501/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9502/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9503/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9504/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9505/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9506/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9507/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9508/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9509/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9510/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9511/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9512/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9513/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9514/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9515/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9516/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9517/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9518/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9519/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9520/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9521/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9522/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9523/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9524/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9525/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9526/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9527/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9528/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9529/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9530/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9531/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9532/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9533/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9534/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9535/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 9536/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 9537/10000 (95%)\ttrain_Loss: 0.004292\tval_Loss: 0.004637\n",
      "Train Epoch: 9538/10000 (95%)\ttrain_Loss: 0.004293\tval_Loss: 0.004626\n",
      "Train Epoch: 9539/10000 (95%)\ttrain_Loss: 0.004293\tval_Loss: 0.004640\n",
      "Train Epoch: 9540/10000 (95%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 9541/10000 (95%)\ttrain_Loss: 0.004295\tval_Loss: 0.004646\n",
      "Train Epoch: 9542/10000 (95%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 9543/10000 (95%)\ttrain_Loss: 0.004299\tval_Loss: 0.004655\n",
      "Train Epoch: 9544/10000 (95%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 9545/10000 (95%)\ttrain_Loss: 0.004305\tval_Loss: 0.004666\n",
      "Train Epoch: 9546/10000 (95%)\ttrain_Loss: 0.004309\tval_Loss: 0.004631\n",
      "Train Epoch: 9547/10000 (95%)\ttrain_Loss: 0.004313\tval_Loss: 0.004676\n",
      "Train Epoch: 9548/10000 (95%)\ttrain_Loss: 0.004316\tval_Loss: 0.004633\n",
      "Train Epoch: 9549/10000 (95%)\ttrain_Loss: 0.004317\tval_Loss: 0.004675\n",
      "Train Epoch: 9550/10000 (95%)\ttrain_Loss: 0.004315\tval_Loss: 0.004629\n",
      "Train Epoch: 9551/10000 (96%)\ttrain_Loss: 0.004309\tval_Loss: 0.004656\n",
      "Train Epoch: 9552/10000 (96%)\ttrain_Loss: 0.004302\tval_Loss: 0.004626\n",
      "Train Epoch: 9553/10000 (96%)\ttrain_Loss: 0.004296\tval_Loss: 0.004634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9554/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9555/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004626\n",
      "Train Epoch: 9556/10000 (96%)\ttrain_Loss: 0.004294\tval_Loss: 0.004648\n",
      "Train Epoch: 9557/10000 (96%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 9558/10000 (96%)\ttrain_Loss: 0.004300\tval_Loss: 0.004652\n",
      "Train Epoch: 9559/10000 (96%)\ttrain_Loss: 0.004300\tval_Loss: 0.004626\n",
      "Train Epoch: 9560/10000 (96%)\ttrain_Loss: 0.004298\tval_Loss: 0.004642\n",
      "Train Epoch: 9561/10000 (96%)\ttrain_Loss: 0.004295\tval_Loss: 0.004627\n",
      "Train Epoch: 9562/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9563/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9564/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004626\n",
      "Train Epoch: 9565/10000 (96%)\ttrain_Loss: 0.004294\tval_Loss: 0.004642\n",
      "Train Epoch: 9566/10000 (96%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 9567/10000 (96%)\ttrain_Loss: 0.004295\tval_Loss: 0.004641\n",
      "Train Epoch: 9568/10000 (96%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 9569/10000 (96%)\ttrain_Loss: 0.004293\tval_Loss: 0.004634\n",
      "Train Epoch: 9570/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9571/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9572/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 9573/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 9574/10000 (96%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n",
      "Train Epoch: 9575/10000 (96%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 9576/10000 (96%)\ttrain_Loss: 0.004293\tval_Loss: 0.004636\n",
      "Train Epoch: 9577/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9578/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9579/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9580/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9581/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9582/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9583/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 9584/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9585/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9586/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9587/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9588/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9589/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9590/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9591/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9592/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9593/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9594/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9595/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9596/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9597/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9598/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9599/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9600/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9601/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9602/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9603/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9604/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9605/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9606/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9607/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9608/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9609/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9610/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9611/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9612/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9613/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9614/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9615/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9616/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9617/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9618/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9619/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9620/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9621/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9622/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9623/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9624/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9625/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9626/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9627/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9628/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9629/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9630/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9631/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9632/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9633/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9634/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9635/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9636/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9637/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9638/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9639/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9640/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9641/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9642/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9643/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9644/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9645/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9646/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9647/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9648/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9649/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9650/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9651/10000 (96%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9652/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9653/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9654/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9655/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9656/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9657/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9658/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9659/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9660/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9661/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9662/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9663/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9664/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9665/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9666/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9667/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9668/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9669/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9670/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9671/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9672/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9673/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 9674/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9675/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004637\n",
      "Train Epoch: 9676/10000 (97%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 9677/10000 (97%)\ttrain_Loss: 0.004293\tval_Loss: 0.004640\n",
      "Train Epoch: 9678/10000 (97%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 9679/10000 (97%)\ttrain_Loss: 0.004295\tval_Loss: 0.004644\n",
      "Train Epoch: 9680/10000 (97%)\ttrain_Loss: 0.004296\tval_Loss: 0.004625\n",
      "Train Epoch: 9681/10000 (97%)\ttrain_Loss: 0.004298\tval_Loss: 0.004652\n",
      "Train Epoch: 9682/10000 (97%)\ttrain_Loss: 0.004300\tval_Loss: 0.004627\n",
      "Train Epoch: 9683/10000 (97%)\ttrain_Loss: 0.004303\tval_Loss: 0.004664\n",
      "Train Epoch: 9684/10000 (97%)\ttrain_Loss: 0.004307\tval_Loss: 0.004631\n",
      "Train Epoch: 9685/10000 (97%)\ttrain_Loss: 0.004311\tval_Loss: 0.004676\n",
      "Train Epoch: 9686/10000 (97%)\ttrain_Loss: 0.004315\tval_Loss: 0.004634\n",
      "Train Epoch: 9687/10000 (97%)\ttrain_Loss: 0.004317\tval_Loss: 0.004678\n",
      "Train Epoch: 9688/10000 (97%)\ttrain_Loss: 0.004317\tval_Loss: 0.004631\n",
      "Train Epoch: 9689/10000 (97%)\ttrain_Loss: 0.004313\tval_Loss: 0.004661\n",
      "Train Epoch: 9690/10000 (97%)\ttrain_Loss: 0.004306\tval_Loss: 0.004625\n",
      "Train Epoch: 9691/10000 (97%)\ttrain_Loss: 0.004298\tval_Loss: 0.004637\n",
      "Train Epoch: 9692/10000 (97%)\ttrain_Loss: 0.004293\tval_Loss: 0.004631\n",
      "Train Epoch: 9693/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 9694/10000 (97%)\ttrain_Loss: 0.004293\tval_Loss: 0.004646\n",
      "Train Epoch: 9695/10000 (97%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 9696/10000 (97%)\ttrain_Loss: 0.004300\tval_Loss: 0.004653\n",
      "Train Epoch: 9697/10000 (97%)\ttrain_Loss: 0.004300\tval_Loss: 0.004626\n",
      "Train Epoch: 9698/10000 (97%)\ttrain_Loss: 0.004299\tval_Loss: 0.004644\n",
      "Train Epoch: 9699/10000 (97%)\ttrain_Loss: 0.004296\tval_Loss: 0.004627\n",
      "Train Epoch: 9700/10000 (97%)\ttrain_Loss: 0.004293\tval_Loss: 0.004632\n",
      "Train Epoch: 9701/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9702/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 9703/10000 (97%)\ttrain_Loss: 0.004293\tval_Loss: 0.004642\n",
      "Train Epoch: 9704/10000 (97%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 9705/10000 (97%)\ttrain_Loss: 0.004295\tval_Loss: 0.004642\n",
      "Train Epoch: 9706/10000 (97%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 9707/10000 (97%)\ttrain_Loss: 0.004294\tval_Loss: 0.004635\n",
      "Train Epoch: 9708/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9709/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9710/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 9711/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 9712/10000 (97%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n",
      "Train Epoch: 9713/10000 (97%)\ttrain_Loss: 0.004293\tval_Loss: 0.004626\n",
      "Train Epoch: 9714/10000 (97%)\ttrain_Loss: 0.004293\tval_Loss: 0.004636\n",
      "Train Epoch: 9715/10000 (97%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 9716/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9717/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9718/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9719/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9720/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9721/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 9722/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9723/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9724/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9725/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9726/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9727/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9728/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9729/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9730/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9731/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9732/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9733/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9734/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9735/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9736/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9737/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9738/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9739/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9740/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9741/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9742/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9743/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9744/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9745/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9746/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9747/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9748/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9749/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9750/10000 (97%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9751/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9752/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9753/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9754/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9755/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9756/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9757/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9758/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9759/10000 (98%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9760/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9761/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9762/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9763/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9764/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9765/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9766/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9767/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9768/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9769/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9770/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9771/10000 (98%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9772/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9773/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9774/10000 (98%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9775/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9776/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9777/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9778/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9779/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9780/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9781/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9782/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9783/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9784/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9785/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9786/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9787/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9788/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9789/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9790/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9791/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9792/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9793/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9794/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9795/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9796/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9797/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9798/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9799/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9800/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9801/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9802/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9803/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9804/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9805/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9806/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9807/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9808/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9809/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9810/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9811/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 9812/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 9813/10000 (98%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n",
      "Train Epoch: 9814/10000 (98%)\ttrain_Loss: 0.004293\tval_Loss: 0.004626\n",
      "Train Epoch: 9815/10000 (98%)\ttrain_Loss: 0.004294\tval_Loss: 0.004641\n",
      "Train Epoch: 9816/10000 (98%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 9817/10000 (98%)\ttrain_Loss: 0.004296\tval_Loss: 0.004647\n",
      "Train Epoch: 9818/10000 (98%)\ttrain_Loss: 0.004297\tval_Loss: 0.004626\n",
      "Train Epoch: 9819/10000 (98%)\ttrain_Loss: 0.004299\tval_Loss: 0.004655\n",
      "Train Epoch: 9820/10000 (98%)\ttrain_Loss: 0.004302\tval_Loss: 0.004628\n",
      "Train Epoch: 9821/10000 (98%)\ttrain_Loss: 0.004305\tval_Loss: 0.004666\n",
      "Train Epoch: 9822/10000 (98%)\ttrain_Loss: 0.004308\tval_Loss: 0.004631\n",
      "Train Epoch: 9823/10000 (98%)\ttrain_Loss: 0.004311\tval_Loss: 0.004673\n",
      "Train Epoch: 9824/10000 (98%)\ttrain_Loss: 0.004313\tval_Loss: 0.004632\n",
      "Train Epoch: 9825/10000 (98%)\ttrain_Loss: 0.004313\tval_Loss: 0.004669\n",
      "Train Epoch: 9826/10000 (98%)\ttrain_Loss: 0.004310\tval_Loss: 0.004628\n",
      "Train Epoch: 9827/10000 (98%)\ttrain_Loss: 0.004305\tval_Loss: 0.004651\n",
      "Train Epoch: 9828/10000 (98%)\ttrain_Loss: 0.004299\tval_Loss: 0.004626\n",
      "Train Epoch: 9829/10000 (98%)\ttrain_Loss: 0.004294\tval_Loss: 0.004633\n",
      "Train Epoch: 9830/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9831/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004626\n",
      "Train Epoch: 9832/10000 (98%)\ttrain_Loss: 0.004294\tval_Loss: 0.004646\n",
      "Train Epoch: 9833/10000 (98%)\ttrain_Loss: 0.004296\tval_Loss: 0.004626\n",
      "Train Epoch: 9834/10000 (98%)\ttrain_Loss: 0.004298\tval_Loss: 0.004650\n",
      "Train Epoch: 9835/10000 (98%)\ttrain_Loss: 0.004299\tval_Loss: 0.004626\n",
      "Train Epoch: 9836/10000 (98%)\ttrain_Loss: 0.004298\tval_Loss: 0.004643\n",
      "Train Epoch: 9837/10000 (98%)\ttrain_Loss: 0.004295\tval_Loss: 0.004627\n",
      "Train Epoch: 9838/10000 (98%)\ttrain_Loss: 0.004293\tval_Loss: 0.004633\n",
      "Train Epoch: 9839/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9840/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 9841/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004639\n",
      "Train Epoch: 9842/10000 (98%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 9843/10000 (98%)\ttrain_Loss: 0.004294\tval_Loss: 0.004641\n",
      "Train Epoch: 9844/10000 (98%)\ttrain_Loss: 0.004294\tval_Loss: 0.004626\n",
      "Train Epoch: 9845/10000 (98%)\ttrain_Loss: 0.004294\tval_Loss: 0.004637\n",
      "Train Epoch: 9846/10000 (98%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 9847/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9848/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9849/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9850/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 9851/10000 (98%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 9852/10000 (99%)\ttrain_Loss: 0.004293\tval_Loss: 0.004637\n",
      "Train Epoch: 9853/10000 (99%)\ttrain_Loss: 0.004293\tval_Loss: 0.004627\n",
      "Train Epoch: 9854/10000 (99%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 9855/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9856/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9857/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9858/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9859/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9860/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9861/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9862/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9863/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9864/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9865/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9866/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9867/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9868/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9869/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9870/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9871/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9872/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004633\n",
      "Train Epoch: 9873/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9874/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9875/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9876/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9877/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9878/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9879/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9880/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9881/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9882/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9883/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9884/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9885/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9886/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9887/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9888/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9889/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9890/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9891/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9892/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9893/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9894/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9895/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9896/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9897/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9898/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9899/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9900/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9901/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9902/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9903/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9904/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9905/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9906/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9907/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9908/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9909/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9910/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9911/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9912/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004630\n",
      "Train Epoch: 9913/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004630\n",
      "Train Epoch: 9914/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9915/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9916/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9917/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9918/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9919/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9920/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9921/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9922/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9923/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9924/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9925/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9926/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9927/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9928/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9929/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9930/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9931/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004631\n",
      "Train Epoch: 9932/10000 (99%)\ttrain_Loss: 0.004291\tval_Loss: 0.004630\n",
      "Train Epoch: 9933/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9934/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9935/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9936/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9937/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9938/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9939/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9940/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9941/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004631\n",
      "Train Epoch: 9942/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9943/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9944/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9945/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9946/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9947/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 9948/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 9949/10000 (99%)\ttrain_Loss: 0.004292\tval_Loss: 0.004637\n",
      "Train Epoch: 9950/10000 (99%)\ttrain_Loss: 0.004293\tval_Loss: 0.004626\n",
      "Train Epoch: 9951/10000 (100%)\ttrain_Loss: 0.004294\tval_Loss: 0.004642\n",
      "Train Epoch: 9952/10000 (100%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 9953/10000 (100%)\ttrain_Loss: 0.004296\tval_Loss: 0.004650\n",
      "Train Epoch: 9954/10000 (100%)\ttrain_Loss: 0.004299\tval_Loss: 0.004627\n",
      "Train Epoch: 9955/10000 (100%)\ttrain_Loss: 0.004302\tval_Loss: 0.004663\n",
      "Train Epoch: 9956/10000 (100%)\ttrain_Loss: 0.004307\tval_Loss: 0.004631\n",
      "Train Epoch: 9957/10000 (100%)\ttrain_Loss: 0.004313\tval_Loss: 0.004681\n",
      "Train Epoch: 9958/10000 (100%)\ttrain_Loss: 0.004319\tval_Loss: 0.004638\n",
      "Train Epoch: 9959/10000 (100%)\ttrain_Loss: 0.004325\tval_Loss: 0.004694\n",
      "Train Epoch: 9960/10000 (100%)\ttrain_Loss: 0.004328\tval_Loss: 0.004638\n",
      "Train Epoch: 9961/10000 (100%)\ttrain_Loss: 0.004325\tval_Loss: 0.004677\n",
      "Train Epoch: 9962/10000 (100%)\ttrain_Loss: 0.004316\tval_Loss: 0.004627\n",
      "Train Epoch: 9963/10000 (100%)\ttrain_Loss: 0.004304\tval_Loss: 0.004642\n",
      "Train Epoch: 9964/10000 (100%)\ttrain_Loss: 0.004295\tval_Loss: 0.004631\n",
      "Train Epoch: 9965/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004626\n",
      "Train Epoch: 9966/10000 (100%)\ttrain_Loss: 0.004295\tval_Loss: 0.004653\n",
      "Train Epoch: 9967/10000 (100%)\ttrain_Loss: 0.004301\tval_Loss: 0.004628\n",
      "Train Epoch: 9968/10000 (100%)\ttrain_Loss: 0.004305\tval_Loss: 0.004660\n",
      "Train Epoch: 9969/10000 (100%)\ttrain_Loss: 0.004305\tval_Loss: 0.004626\n",
      "Train Epoch: 9970/10000 (100%)\ttrain_Loss: 0.004300\tval_Loss: 0.004642\n",
      "Train Epoch: 9971/10000 (100%)\ttrain_Loss: 0.004295\tval_Loss: 0.004629\n",
      "Train Epoch: 9972/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9973/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004643\n",
      "Train Epoch: 9974/10000 (100%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 9975/10000 (100%)\ttrain_Loss: 0.004297\tval_Loss: 0.004648\n",
      "Train Epoch: 9976/10000 (100%)\ttrain_Loss: 0.004298\tval_Loss: 0.004626\n",
      "Train Epoch: 9977/10000 (100%)\ttrain_Loss: 0.004296\tval_Loss: 0.004637\n",
      "Train Epoch: 9978/10000 (100%)\ttrain_Loss: 0.004293\tval_Loss: 0.004629\n",
      "Train Epoch: 9979/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9980/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004639\n",
      "Train Epoch: 9981/10000 (100%)\ttrain_Loss: 0.004293\tval_Loss: 0.004626\n",
      "Train Epoch: 9982/10000 (100%)\ttrain_Loss: 0.004295\tval_Loss: 0.004641\n",
      "Train Epoch: 9983/10000 (100%)\ttrain_Loss: 0.004295\tval_Loss: 0.004626\n",
      "Train Epoch: 9984/10000 (100%)\ttrain_Loss: 0.004293\tval_Loss: 0.004635\n",
      "Train Epoch: 9985/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9986/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9987/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004636\n",
      "Train Epoch: 9988/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 9989/10000 (100%)\ttrain_Loss: 0.004293\tval_Loss: 0.004638\n",
      "Train Epoch: 9990/10000 (100%)\ttrain_Loss: 0.004293\tval_Loss: 0.004628\n",
      "Train Epoch: 9991/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9992/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 9993/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004629\n",
      "Train Epoch: 9994/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004634\n",
      "Train Epoch: 9995/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004627\n",
      "Train Epoch: 9996/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004635\n",
      "Train Epoch: 9997/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004628\n",
      "Train Epoch: 9998/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004632\n",
      "Train Epoch: 9999/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train Epoch: 10000/10000 (100%)\ttrain_Loss: 0.004292\tval_Loss: 0.004630\n",
      "Train loss before training was: 0.7687274217605591\n",
      "Train loss after training is: 0.00429152138531208\n",
      "Val loss before training was: 0.7687631249427795\n",
      "Val loss after training is: 0.004630263429135084\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%% Training\n",
    "plt.figure() # monitor loss curve during training\n",
    "# for loop over epochs\n",
    "for epoch in range(num_epoch):\n",
    "    # classical forward pass -> predict new output from train data\n",
    "    Y_pred_train = net(X_train)\n",
    "    # compute loss    \n",
    "    loss_train = loss_func(Y_pred_train, Y_train)\n",
    "    \n",
    "    # Compute gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Calling .backward() mutiple times accumulates the gradient (by addition) for each parameter. This is why you should call optimizer.zero_grad() after each .step() call\n",
    "    # Note that following the first .backward call, a second call is only possible after you have performed another forward pass.\n",
    "    loss_train.backward()\n",
    "    # perform a parameter update based on the current gradient (stored in .grad attribute of a parameter)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # TODO**\n",
    "    # forward pass for validation\n",
    "    Y_pred_val = net(X_val)\n",
    "    loss_val = loss_func(Y_pred_val, Y_val)\n",
    "    # TODO**\n",
    "    \n",
    "    # plot train and val loss\n",
    "    plt.scatter(epoch, loss_train.data.item(), color='b', s=10, marker='o')    \n",
    "    plt.scatter(epoch, loss_val.data.item(), color='r', s=10, marker='o')\n",
    "    \n",
    "    # print message with actual losses\n",
    "    print('Train Epoch: {}/{} ({:.0f}%)\\ttrain_Loss: {:.6f}\\tval_Loss: {:.6f}'.format(\n",
    "    epoch+1, num_epoch, epoch/num_epoch*100, loss_train.item(), loss_val.item()))\n",
    "\n",
    "\n",
    "# show training and validation loss    \n",
    "plt.legend(['train-loss','val-loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig(os.path.join(path, 'results/who_loss.png'))\n",
    "#plt.show()\n",
    "\n",
    "print('Train loss before training was:', loss_train_before.item())\n",
    "print('Train loss after training is:', loss_train.item())\n",
    "print('Val loss before training was:', loss_val_before.item())\n",
    "print('Val loss after training is:', loss_val.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eytU3EgRpowe"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%% Pred vs. Ref Figure Train/Val set\n",
    "# plot the prediction against the reference for the train/val points\n",
    "# if the prediction equals the reference the dots will appear at the 'perfect model' line\n",
    "plt.figure()\n",
    "plt.title('pred vs. ref: train/val points')\n",
    "plt.scatter(Y_train.cpu().numpy(), Y_pred_train.cpu().detach().numpy(), color='b', s=5, marker='o')\n",
    "plt.scatter(Y_val.cpu().numpy(), Y_pred_val.cpu().detach().numpy(), color='r', s=5, marker='o')\n",
    "plt.scatter(Y_val.cpu().numpy(), Y_pred_val_before.cpu().detach().numpy(), color='m', s=5, marker='^')\n",
    "plt.plot((0,1),(0,1), color='k')\n",
    "plt.xlabel('reference')\n",
    "plt.ylabel('prediction')\n",
    "plt.legend(['perfect model', 'train-sample after tr','val-sample after tr', 'val-sample before tr'])\n",
    "plt.xlim((0,1))\n",
    "plt.ylim((0,1))\n",
    "plt.savefig(os.path.join(path, 'results/who_pred_vs_ref_val.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "SKwwQdL7powg"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1376436366.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[17], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    Y_pred_test =\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#%% Test results\n",
    "# TODO**\n",
    "# forward pass \n",
    "# Y_pred_test_oh is on the GPU, because net and X_test are on the GPU, but we want it on the CPU from now on.\n",
    "Y_pred_test = \n",
    "loss_test = \n",
    "# TODO**\n",
    "print('Test loss before training was:', loss_test_before.item())\n",
    "print('Test loss after training is:', loss_test.item())\n",
    "\n",
    "# Plot mean abs difference between prediction and reference\n",
    "print('Mean abs difference:', np.mean(abs(Y_pred_test.cpu().detach().numpy()-Y_test.cpu().numpy()), axis=0)*scale_y, 'years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BoADQD3ipowk"
   },
   "outputs": [],
   "source": [
    "#%% Pred vs. Ref Figure Test set\n",
    "# plot the prediction against the reference for the test points\n",
    "# if the prediction equals the reference the dots will appear at the 'perfect model' line\n",
    "plt.figure()\n",
    "plt.title('pred vs. ref: test points')\n",
    "plt.scatter(Y_test.cpu().numpy(), Y_pred_test.cpu().detach().numpy(), color='g', s=5, marker='o')\n",
    "plt.scatter(Y_test.cpu().numpy(), Y_pred_test_before.cpu().detach().numpy(), color='m', s=5, marker='^')\n",
    "plt.plot((0,1),(0,1), color='k')\n",
    "plt.xlabel('reference')\n",
    "plt.ylabel('prediction')\n",
    "plt.legend(['perfect model','test-sample after tr', 'test-sample before tr'])\n",
    "plt.xlim((0,1))\n",
    "plt.ylim((0,1))\n",
    "plt.savefig(os.path.join(path, 'results/who_pred_vs_ref_test.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
